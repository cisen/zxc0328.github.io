<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Zindex&#39;s blog</title>
  <subtitle>Frontend Rocks</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-02-12T03:17:52.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zindex</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Headless Chrome long image capture issue</title>
    <link href="http://yoursite.com/2018/02/12/hdchrome-long-capture/"/>
    <id>http://yoursite.com/2018/02/12/hdchrome-long-capture/</id>
    <published>2018-02-12T03:16:21.000Z</published>
    <updated>2018-02-12T03:17:52.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;The-problem&quot;&gt;&lt;a href=&quot;#The-problem&quot; class=&quot;headerlink&quot; title=&quot;The problem&quot;&gt;&lt;/a&gt;The problem&lt;/h3&gt;&lt;p&gt;Recently I had received complaint about my capture service not export complete image. It seems that this problem only occurs when the page’s is extremely long.&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;The broken image is like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zxc0328/huihuihui-h5/master/Screen%20Shot%202017-12-19%20at%2010.30.21%20AM.png&quot; alt=&quot;broken&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Chromium’s-limit&quot;&gt;&lt;a href=&quot;#Chromium’s-limit&quot; class=&quot;headerlink&quot; title=&quot;Chromium’s limit&quot;&gt;&lt;/a&gt;Chromium’s limit&lt;/h3&gt;&lt;p&gt;So I Googled for the problem and I found &lt;a href=&quot;https://github.com/GoogleChrome/puppeteer/issues/477&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;a lot issues&lt;/a&gt; on Github that target the same problem. When reading throught &lt;a href=&quot;https://github.com/GoogleChrome/puppeteer/pull/937&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;this issue&lt;/a&gt;, I got the fact that this problem is caused by Chromium’s limit.&lt;/p&gt;
&lt;p&gt;Since normal server don’t have a GPU inside, Headless Chrome had to use software renderer, that is, using CPU to calculate the pixels. &lt;/p&gt;
&lt;p&gt;Chromium’s compositor has a maximum texture size when using software GL backend, this limit is 16384px. So large image will not be renderer completely.&lt;/p&gt;
&lt;h3 id=&quot;How-to-solve-it&quot;&gt;&lt;a href=&quot;#How-to-solve-it&quot; class=&quot;headerlink&quot; title=&quot;How to solve it&quot;&gt;&lt;/a&gt;How to solve it&lt;/h3&gt;&lt;p&gt;The solve for this problem is simple. Cut the page into pieces, capture these fragments in order, and composite those pieces into a whole image.&lt;/p&gt;
&lt;p&gt;The code below use Puppeteer’s API, it’s fine to replace it with other library like CDP.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;await page.setViewport({ width: 1440, height: 1024});
const {contentSize} = await page._client.send(&amp;#39;Page.getLayoutMetrics&amp;#39;);
// MAGIC NUMBER, DO NOT MODIFIY THIS OR YOU WILL BE FIRED
const maxScreenshotHeight = 7000;
          if (contentSize.height &amp;gt;= maxScreenshotHeight) {

            let image;
            let lastBuffer;

            for (let ypos = 0; ypos &amp;lt; contentSize.height; ypos += maxScreenshotHeight) {
              const height = Math.min(contentSize.height - ypos, maxScreenshotHeight);
              let buffer = await page.screenshot({
                clip: {
                  x: 0,
                  y: ypos,
                  width: contentSize.width,
                  height
                }
              });
              if (ypos === 0) {
                image = sharp(buffer);
                lastBuffer = await image.toBuffer();
              }else {
                image = sharp(lastBuffer);
                image = image.extend({top: 0, bottom: height, left: 0, right: 0})
                image = image.overlayWith(buffer, {top: ypos, left:0})
                lastBuffer = await image.toBuffer();
              }
            }
            fileData = lastBuffer;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I use &lt;a href=&quot;https://github.com/lovell/sharp&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;sharp&lt;/a&gt; for image processing, bacause it’s recommended on Github issue.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The magic number here should be around 16000 by default, but I had noticed that the height for each piece should be reduced when the width increased. The width I use for my capture is 1440px, you should start from 16000 and reduce this number if the image exported is still incomplete.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;Future&quot;&gt;&lt;a href=&quot;#Future&quot; class=&quot;headerlink&quot; title=&quot;Future&quot;&gt;&lt;/a&gt;Future&lt;/h3&gt;&lt;p&gt;The approach may not be necessary accroding to this &lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=770769&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Chromium issue&lt;/a&gt;.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;The-problem&quot;&gt;&lt;a href=&quot;#The-problem&quot; class=&quot;headerlink&quot; title=&quot;The problem&quot;&gt;&lt;/a&gt;The problem&lt;/h3&gt;&lt;p&gt;Recently I had received complaint about my capture service not export complete image. It seems that this problem only occurs when the page’s is extremely long.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Liso源码阅读笔记</title>
    <link href="http://yoursite.com/2018/02/12/liso/"/>
    <id>http://yoursite.com/2018/02/12/liso/</id>
    <published>2018-02-12T03:16:05.000Z</published>
    <updated>2018-02-12T03:19:59.000Z</updated>
    
    <content type="html">&lt;p&gt;本文介绍了CMU 15-441的课程项目&lt;a href=&quot;https://www.cs.cmu.edu/~prs/15-441-F16/project1/project1.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Liso&lt;/a&gt;的一个实现。主要介绍了请求流程、Client状态机模型、Dynamic Buffer数据结构等等。SSL相关的部分没有涉及。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;实现&quot;&gt;&lt;a href=&quot;#实现&quot; class=&quot;headerlink&quot; title=&quot;实现&quot;&gt;&lt;/a&gt;实现&lt;/h3&gt;&lt;p&gt;我看的是这位同学的&lt;a href=&quot;https://github.com/zhuansunxt/Liso&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;实现&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&quot;一个HTTP静态文件请求的流程&quot;&gt;&lt;a href=&quot;#一个HTTP静态文件请求的流程&quot; class=&quot;headerlink&quot; title=&quot;一个HTTP静态文件请求的流程&quot;&gt;&lt;/a&gt;一个HTTP静态文件请求的流程&lt;/h3&gt;&lt;p&gt;首先我们拿一个简单的静态文件请求来梳理一下Liso的流程。在&lt;code&gt;liso.c&lt;/code&gt;的&lt;code&gt;main&lt;/code&gt;函数中，有这个服务器的主循环，这个循环每次做的事情就是用&lt;code&gt;select&lt;/code&gt;来查询I/O事件。&lt;code&gt;select&lt;/code&gt;之后，我们首先做的是查看&lt;code&gt;listenfd&lt;/code&gt;是不是有read事件，如果有就&lt;code&gt;accept&lt;/code&gt;这个连接。然后把连接加入到连接池里。一个连接的初始状态是&lt;code&gt;READY_FOR_READ&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;listenfd&lt;/code&gt;是连接池中的第一个item，也是一直存在于连接池中的一个描述符。&lt;/p&gt;
&lt;p&gt;在循环的最后，我们会调用&lt;code&gt;handle_clients&lt;/code&gt;对连接池中可读和可写的描述符依次进行处理。具体的方式就是遍历连接池，如果一个连接是可读的，并且状态是&lt;code&gt;READY_FOR_READ&lt;/code&gt;，我们就读取这个连接中的数据。&lt;/p&gt;
&lt;p&gt;每次从每个连接读取的数据是固定的长度，比如4KB。这是为了控制I/O的粒度，不让server在一个连接上花太多时间，使得新的连接请求被阻塞。&lt;/p&gt;
&lt;p&gt;我们把收到的数据，放到&lt;code&gt;client_buffer&lt;/code&gt;里面。然后看一下HTTP的Header是不是已经读取完全了（调用&lt;code&gt;handle_recv_header&lt;/code&gt;判断读取到的数据中是否有&lt;code&gt;&amp;quot;\r\n\r\n&amp;quot;&lt;/code&gt;）。如果HTTP的header还没有读取完全，那就继续留在&lt;code&gt;READY_FOR_READ&lt;/code&gt;状态，等待下一次循环。&lt;/p&gt;
&lt;p&gt;如果Header已经读取完全了，我们就调用&lt;code&gt;handle_http_request&lt;/code&gt;处理请求，在处理请求时，我们把要返回的数据写在&lt;code&gt;client_buffer&lt;/code&gt;里，然后调整这个client的state到&lt;code&gt;READY_FOR_WRITE&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;handle_clients&lt;/code&gt;的循环中，如果我们发现一个client的状态是&lt;code&gt;READY_FOR_WRITE&lt;/code&gt;，我们就会把&lt;code&gt;client_buffer&lt;/code&gt;里相关的数据写到客户端，然后根据这个连接的&lt;code&gt;Connection&lt;/code&gt;Header选择关闭或者保留这个连接。&lt;/p&gt;
&lt;p&gt;这就是一个简单的HTTP静态文件请求的流程。&lt;/p&gt;
&lt;h3 id=&quot;连接池的数据结构&quot;&gt;&lt;a href=&quot;#连接池的数据结构&quot; class=&quot;headerlink&quot; title=&quot;连接池的数据结构&quot;&gt;&lt;/a&gt;连接池的数据结构&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;typedef struct {
  /* Client pool global data */
  fd_set master;              /* all descritors */
  fd_set read_fds;            /* all ready-to-read descriptors */
  fd_set write_fds;           /* all ready-to_write descriptors */
  int maxfd;                  /* maximum value of all descriptors */
  int nready;                 /* number of ready descriptors */
  int maxi;                   /* maximum index of available slot */

  /* Client specific data */
  int client_fd[FD_SETSIZE];  /* client slots */
  dynamic_buffer * client_buffer[FD_SETSIZE];   /* client&amp;#39;s dynamic-size buffer */
  dynamic_buffer * back_up_buffer[FD_SETSIZE];  /* store historical pending request */
  size_t received_header[FD_SETSIZE];           /* store header ending&amp;#39;s offset */
  char should_be_close[FD_SETSIZE];             /* whether client should be closed when checked */
  client_state state[FD_SETSIZE];               /* client&amp;#39;s state */
  char *remote_addr[FD_SETSIZE];                /* client&amp;#39;s remote address */

  /* SSL related */
  client_type type[FD_SETSIZE];                 /* client&amp;#39;s type: HTTP or HTTPS */
  SSL * context[FD_SETSIZE];                    /* set if client&amp;#39;s type is HTTPS */

  /* CGI related */
  int cgi_client[FD_SETSIZE];
} client_pool;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个socket连接在建立之后都会被放到&lt;code&gt;client_pool&lt;/code&gt;里面。连接池在概念上就是一个大的数组。实现的时候，我们把每个连接相关的属性各自设置为一个相同大小的数组。每个item的属性就是属性数组中相应index的值。比如我们可以通过&lt;code&gt;client_pool-&amp;gt;client_fd[i]&lt;/code&gt;拿到第i个请求的fd。其他属性也是类似的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;FD_SETSIZE&lt;/code&gt;这个常量是这个server并发连接的最大值，这个常量的大小一般是1024。这个值是操作系统设置的。这个连接池里除了各个连接相关信息的数组之外，还有几个&lt;code&gt;fd_set&lt;/code&gt;类型的全局属性，其中&lt;code&gt;master&lt;/code&gt;里保存了整个连接池的描述符。这也就是我们&lt;code&gt;select&lt;/code&gt;循环时监听的目标。需要注意的是CGI连接在建立之后，也会被放到这个连接池中（&lt;code&gt;client_fd&lt;/code&gt;指向发起CGI请求的客户端，&lt;code&gt;cgi_client&lt;/code&gt;指向CGI连接，这个连接在CGI处理完后会被我们从连接池中清除）。这样我们就可以利用&lt;code&gt;select&lt;/code&gt;对CGI请求进行事件驱动的异步处理。&lt;/p&gt;
&lt;h3 id=&quot;client的状态机模型&quot;&gt;&lt;a href=&quot;#client的状态机模型&quot; class=&quot;headerlink&quot; title=&quot;client的状态机模型&quot;&gt;&lt;/a&gt;client的状态机模型&lt;/h3&gt;&lt;p&gt;我们知道有限状态机由一组状态和一组转移组成，在Liso里，一个client的状态有以下几种：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef enum client_state {
    INVALID,
    READY_FOR_READ,
    READY_FOR_WRITE,
    WAITING_FOR_CGI,
    CGI_FOR_READ,
    CGI_FOR_WRITE
} client_state;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在讲具体的状态模型之前，我们要把连接池中的连接分为两种，一种是客户端的连接描述符，一种是CGI连接。这两种连接的在连接池中的数据结构是相同的。&lt;/p&gt;
&lt;p&gt;在处理HTTP请求时，如果一个请求是CGI请求，我们就会fork一个进程，获取CGI的文件描述符，然后调用&lt;code&gt;add_cgi_fd_to_pool&lt;/code&gt;函数将这个描述符加入到连接池中。加入操作的核心代码是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/* Update client data */
p-&amp;gt;client_fd[i] = cgi_fd;
p-&amp;gt;state[i] = state;

/* CGI */
p-&amp;gt;cgi_client[i] = clientfd;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以这个连接和普通的连接一样，都有&lt;code&gt;client_fd&lt;/code&gt;属性，不同的是这个连接有一个&lt;code&gt;cgi_client&lt;/code&gt;属性，指向CGI连接的文件描述符。所以在处理CGI请求的时候，一个连接在连接池中有客户端连接和CGI连接两个item。CGI连接的状态仅仅只是在&lt;code&gt;CGI_FOR_READ&lt;/code&gt;和&lt;code&gt;CGI_FOR_WRITE&lt;/code&gt;之间转换。在CGI连接可读，并被写到客户端之后，我们会从连接池中清除这个CGI的item。所以客户端连接和CGI连接的状态机模型应该分开讲述。&lt;/p&gt;
&lt;h4 id=&quot;客户端连接状态机模型&quot;&gt;&lt;a href=&quot;#客户端连接状态机模型&quot; class=&quot;headerlink&quot; title=&quot;客户端连接状态机模型&quot;&gt;&lt;/a&gt;客户端连接状态机模型&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;https://wx1.sinaimg.cn/mw1024/64c45edcgy1flgj3kbvxjj20vu0g0adc.jpg&quot; alt=&quot;static fsm&quot;&gt;&lt;/p&gt;
&lt;p&gt;客户端连接，如果是CGI连接，会比静态资源请求多一个&lt;code&gt;WAITING_FOR_CGI&lt;/code&gt;的状态。这里我们需要注意的是，我们在读取一个连接的数据时，如果是一个POST请求，一般会分很多次。如果读取之后数据不够，这个连接的状态就会停留在&lt;code&gt;READY_FOR_READ&lt;/code&gt;，等待下一次&lt;code&gt;select&lt;/code&gt;循环。直到读取到足够的数据（根据Header里的&lt;code&gt;content-length&lt;/code&gt;）之后，才把这个请求的状态转移到&lt;code&gt;READY_FOR_WRITE&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&quot;CGI连接状态机模型&quot;&gt;&lt;a href=&quot;#CGI连接状态机模型&quot; class=&quot;headerlink&quot; title=&quot;CGI连接状态机模型&quot;&gt;&lt;/a&gt;CGI连接状态机模型&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;https://wx2.sinaimg.cn/mw1024/64c45edcgy1flgj3k7yopj20uc0dwacw.jpg&quot; alt=&quot;cgi fsm&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;长连接&quot;&gt;&lt;a href=&quot;#长连接&quot; class=&quot;headerlink&quot; title=&quot;长连接&quot;&gt;&lt;/a&gt;长连接&lt;/h3&gt;&lt;p&gt;我们知道HTTP的Header中有一个Connection字段。如果这个字段的值为close，在&lt;code&gt;READY_FOR_WRITE&lt;/code&gt;状态时，如果我们写完了当前请求所请求的数据，我们就关闭连接。如果这个字段的值为&lt;code&gt;keep-alive&lt;/code&gt;，连接会经过&lt;code&gt;Persist&lt;/code&gt;转移，重新进入&lt;code&gt;READY_FOR_WRITE&lt;/code&gt;状态。&lt;/p&gt;
&lt;p&gt;在写完数据之后依然保持&lt;code&gt;READY_FOR_WRITE&lt;/code&gt;状态，不关闭连接，这就是我们常说的HTTP&lt;code&gt;keep-alive&lt;/code&gt;长连接。在这种情况下，server假定的是在未来的某个时间节点，这个客户端上还有数据可以读取，所以我们暂时不关闭连接。&lt;/p&gt;
&lt;p&gt;举例说一下HTTP长连接的用途：如果一个域下有多个资源需要请求，浏览器会复用同一个TCP连接。也就是说服务器可以在一个TCP连接上进行多次HTTP请求。这样有利于减少网络延迟和服务器的并发压力。&lt;/p&gt;
&lt;h3 id=&quot;Dynamic-Buffer数据结构&quot;&gt;&lt;a href=&quot;#Dynamic-Buffer数据结构&quot; class=&quot;headerlink&quot; title=&quot;Dynamic Buffer数据结构&quot;&gt;&lt;/a&gt;Dynamic Buffer数据结构&lt;/h3&gt;&lt;p&gt;Dynamic Buffer数据结构是对普通buffer的封装。为了应对HTTP请求中长度不一定的二进制数据，我们需要一个封装良好的buffer结构，让我们方向的使用，不用担心内存管理问题。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct dynamic_buffer{
  char *buffer;
  size_t offset;
  size_t capacity;
  size_t send_offset;
} dynamic_buffer;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;dynamic_buffer&lt;/code&gt;类型用struct封装了一个新的类型，&lt;code&gt;buffer&lt;/code&gt;指向实际存储数据的buffer。另外还有&lt;code&gt;offset&lt;/code&gt;、&lt;code&gt;capacity&lt;/code&gt;和&lt;code&gt;send_offset&lt;/code&gt;这些属性来辅助内存管理。&lt;code&gt;offset&lt;/code&gt;让我们掌握目前buffer的实际容量是多少。&lt;code&gt;capacity&lt;/code&gt;让我们可以掌握buffer占用的内存大小，方便动态的扩容。作者说这个设计是模仿的C++ vector STL。&lt;/p&gt;
&lt;h3 id=&quot;CGI相关&quot;&gt;&lt;a href=&quot;#CGI相关&quot; class=&quot;headerlink&quot; title=&quot;CGI相关&quot;&gt;&lt;/a&gt;CGI相关&lt;/h3&gt;&lt;p&gt;Liso中用来描述一个CGI执行进程的数据结构是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct CGI_executor {
  int clientfd;
  int stdin_pipe[2];    /* { write data --&amp;gt; stdin_pipe[1] } -&amp;gt; { stdin_pipe[0] --&amp;gt; stdin } */
  int stdout_pipe[2];   /* { read data &amp;lt;--  stdout_pipe[0] } &amp;lt;-- {stdout_pipe[1] &amp;lt;-- stdout } */
  dynamic_buffer* cgi_buffer;
  CGI_param* cgi_parameter;
} CGI_executor;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;里面主要的成员除了&lt;code&gt;cgi_buffer&lt;/code&gt;和用于传入环境变量的&lt;code&gt;cgi_parameter&lt;/code&gt;之外，&lt;code&gt;stdin_pipe&lt;/code&gt;和&lt;code&gt;stdout_pipe&lt;/code&gt;两个成员值得注意。&lt;/p&gt;
&lt;h4 id=&quot;pipe&quot;&gt;&lt;a href=&quot;#pipe&quot; class=&quot;headerlink&quot; title=&quot;pipe&quot;&gt;&lt;/a&gt;pipe&lt;/h4&gt;&lt;p&gt;&lt;code&gt;stdin_pipe&lt;/code&gt;和&lt;code&gt;stdout_pipe&lt;/code&gt;两个成员代表了两个pipe。pipe是Linux中的一种通信机制。一个pipe有两个fd组成，第一个代表read端，第二个代表write端。写入的数据会缓存在内核中，在读取时被取出。我们可以用pipe函数来创建一个pipe，pipe中的两个文件描述符在fork时也会被复制。所以pipe可以被作为一种进程间通信的手段。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;关于pipe的更多信息请参考&lt;em&gt;The Linux Programming Interface&lt;/em&gt; Chapter 44&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们的server主进程要和CGI进程通信，就是通过pipe做到的。&lt;/p&gt;
&lt;p&gt;在CGI进程中的代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;close(cgi_pool-&amp;gt;executors[slot]-&amp;gt;stdout_pipe[0]);
close(cgi_pool-&amp;gt;executors[slot]-&amp;gt;stdin_pipe[1]);
dup2(cgi_pool-&amp;gt;executors[slot]-&amp;gt;stdout_pipe[1], fileno(stdout));
dup2(cgi_pool-&amp;gt;executors[slot]-&amp;gt;stdin_pipe[0], fileno(stdin));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们关闭了CGI进程中&lt;code&gt;stdout_pipe&lt;/code&gt;的read端，把write端重定向到CGI进程的stdout，因为主进程要从这个pipe读取CGI进程的输出。&lt;/p&gt;
&lt;p&gt;我们关闭了CGI进程中&lt;code&gt;stdin_pipe&lt;/code&gt;的write端，把read端重定向到CGI进程的stdin，因为主进程要向CGI进程中写入一些信息，比如POST请求的body。&lt;/p&gt;
&lt;p&gt;在主进程中，我们关闭用不到的两个fd，分别是&lt;code&gt;stdout_pipe&lt;/code&gt;的write端和&lt;code&gt;stdin_pipe&lt;/code&gt;的read端。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;close(cgi_pool-&amp;gt;executors[slot]-&amp;gt;stdout_pipe[1]);
close(cgi_pool-&amp;gt;executors[slot]-&amp;gt;stdin_pipe[0]);
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;select-CGI&quot;&gt;&lt;a href=&quot;#select-CGI&quot; class=&quot;headerlink&quot; title=&quot;select + CGI&quot;&gt;&lt;/a&gt;select + CGI&lt;/h4&gt;&lt;p&gt;在CGI进程被创建之后，我们调用&lt;code&gt;add_cgi_fd_to_pool&lt;/code&gt;函数把这个clientfd和CGI的fd一起加入到监听的连接池里面。CGI的fd是什么呢？没错，就是&lt;code&gt;stdin_pipe[1]&lt;/code&gt;和&lt;code&gt;stdout_pipe[0]&lt;/code&gt;，&lt;code&gt;stdin_pipe[1]&lt;/code&gt;代表着CGI进程的输入，当这个fd为可写时，我们可以向CGI进程写入数据。&lt;code&gt;stdout_pipe[0]&lt;/code&gt;代表着CGI进程的输出，当这个fd为可读时，我们可以从CGI进程中读取数据。加入到连接池中意味着我们可以通过select来监听CGI进程的I/O事件。所以在select的&lt;code&gt;handle_clients&lt;/code&gt;里，除了客户端可写和客户端可读之外，我们需要处理CGI可写和CGI可读两种情况。&lt;/p&gt;
&lt;p&gt;由此我们便可以在select中根据事件，来对客户端进行处理，转移它们的状态。一个非阻塞的事件驱动Server设计已经有了雏形。&lt;/p&gt;
&lt;h3 id=&quot;如何加强Liso&quot;&gt;&lt;a href=&quot;#如何加强Liso&quot; class=&quot;headerlink&quot; title=&quot;如何加强Liso&quot;&gt;&lt;/a&gt;如何加强Liso&lt;/h3&gt;&lt;p&gt;Liso距离一个工业级的Server还有很大的差距，我们可以做的改进有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将静态文件I/O改造为基于线程池的设计。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;epoll&lt;/code&gt;代替&lt;code&gt;select&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;支持使用DSL对服务器进行配置。&lt;/li&gt;
&lt;li&gt;支持Gzip。&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文介绍了CMU 15-441的课程项目&lt;a href=&quot;https://www.cs.cmu.edu/~prs/15-441-F16/project1/project1.pdf&quot;&gt;Liso&lt;/a&gt;的一个实现。主要介绍了请求流程、Client状态机模型、Dynamic Buffer数据结构等等。SSL相关的部分没有涉及。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Kubernete安装不完全指南</title>
    <link href="http://yoursite.com/2017/10/26/k8s-setup-1-7/"/>
    <id>http://yoursite.com/2017/10/26/k8s-setup-1-7/</id>
    <published>2017-10-26T11:21:26.000Z</published>
    <updated>2018-02-12T03:14:52.000Z</updated>
    
    <content type="html">&lt;p&gt;安装Kubernetes向来不是一件容易的事情。之前在集群上部署好的K8s突然出了问题，于是需要重新安装。这次没有之前那次那么顺利了，出现了很多奇怪的问题。但经过一番实践和总结，总算是得出了Kubernetes国内安装的一个不完全指南。这个指南理论上适用于任意版本的K8s。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;Master节点的安装过程主要可以参考&lt;a href=&quot;https://blog.jsjs.org/?p=414&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;strong&gt;《使用kubeadm安装kubernetes1.7》&lt;/strong&gt;&lt;/a&gt;。主要的流程是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;安装Docker&lt;/li&gt;
&lt;li&gt;安装Kubernetes相关组件&lt;/li&gt;
&lt;li&gt;Kubeadm init Master节点&lt;/li&gt;
&lt;li&gt;安装Overlay Network&lt;/li&gt;
&lt;li&gt;Join Node节点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面主要说一些关于如何确定软件版本、如何制作软件镜像源等等细微但是很要命的问题。&lt;/p&gt;
&lt;h3 id=&quot;关于Docker&quot;&gt;&lt;a href=&quot;#关于Docker&quot; class=&quot;headerlink&quot; title=&quot;关于Docker&quot;&gt;&lt;/a&gt;关于Docker&lt;/h3&gt;&lt;p&gt;目前使用&lt;strong&gt;Docker 1.12&lt;/strong&gt;版本是比较稳定的。Docker这种基础设施软件没有必要追最新的。在阿里云的CentOS只要直接&lt;code&gt;yum install docker&lt;/code&gt;就可以安装这个版本了。&lt;/p&gt;
&lt;h3 id=&quot;关于操作系统&quot;&gt;&lt;a href=&quot;#关于操作系统&quot; class=&quot;headerlink&quot; title=&quot;关于操作系统&quot;&gt;&lt;/a&gt;关于操作系统&lt;/h3&gt;&lt;p&gt;本文讲的是在&lt;strong&gt;CentOS 7&lt;/strong&gt;上安装Kubernetes。理由是Kubernetes对CentOS支持比较好，网上资料比较多。当然Ubuntu的支持应该也是没问题的。&lt;/p&gt;
&lt;h3 id=&quot;关于K8s源&quot;&gt;&lt;a href=&quot;#关于K8s源&quot; class=&quot;headerlink&quot; title=&quot;关于K8s源&quot;&gt;&lt;/a&gt;关于K8s源&lt;/h3&gt;&lt;p&gt;因为国内的网络环境，我们在服务上明显是不能直接访问国外的镜像源的。所以我们找掌握寻找镜像源，以及在必要的时候自己制作镜像源的技能（因为云服务商的镜像源不一定同步了最新的版本）。&lt;/p&gt;
&lt;p&gt;所以我们可以直接用阿里云的源，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt;&amp;gt; /etc/yum.repos.d/kubernetes.repo &amp;lt;&amp;lt;EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=0
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;目前阿里云的源是1.7.5的，Kubernetes目前的稳定版本是1.8.x，1.9.x马上要发布了。可见过国内的源虽然可以用，但版本上不会特别新。&lt;/p&gt;
&lt;p&gt;第二种办法是在国外服务器上下载镜像然后上传到国内服务器。&lt;strong&gt;这样的好处是可以任意选择自己想要的版本&lt;/strong&gt;。具体可以参考使用上文中的《kubeadm安装kubernetes1.7》。&lt;/p&gt;
&lt;h3 id=&quot;关于镜像&quot;&gt;&lt;a href=&quot;#关于镜像&quot; class=&quot;headerlink&quot; title=&quot;关于镜像&quot;&gt;&lt;/a&gt;关于镜像&lt;/h3&gt;&lt;p&gt;Kubernetes安装过程中一个很大的问题，在于相关组件的镜像都是托管在Google Container Registry上的。国内的镜像加速一般针对的是Dockerhub上的镜像。所以国内的服务器是没法直接安装GCR上的镜像的。&lt;/p&gt;
&lt;p&gt;这个问题其实很好解决，首先我们可以&lt;strong&gt;自己在本地翻墙拉到镜像，并把镜像push到阿里云的镜像仓库&lt;/strong&gt;。拉镜像上传的脚本如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
set -o errexit
set -o nounset
set -o pipefail

KUBE_VERSION=v1.7.5
KUBE_PAUSE_VERSION=3.0
ETCD_VERSION=3.0.17
DNS_VERSION=1.14.4

GCR_URL=gcr.io/google_containers
ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/muxi

images=(kube-proxy-amd64:${KUBE_VERSION}
kube-scheduler-amd64:${KUBE_VERSION}
kube-controller-manager-amd64:${KUBE_VERSION}
kube-apiserver-amd64:${KUBE_VERSION}
pause-amd64:${KUBE_PAUSE_VERSION}
etcd-amd64:${ETCD_VERSION}
k8s-dns-sidecar-amd64:${DNS_VERSION}
k8s-dns-kube-dns-amd64:${DNS_VERSION}
k8s-dns-dnsmasq-nanny-amd64:${DNS_VERSION})


for imageName in ${images[@]} ; do
  docker pull $GCR_URL/$imageName
  docker tag $GCR_URL/$imageName $ALIYUN_URL/$imageName
  docker login
  docker push $ALIYUN_URL/$imageName
  docker rmi $ALIYUN_URL/$imageName
done
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;K8s每个版本需要的镜像版本号在&lt;a href=&quot;https://kubernetes.io/docs/admin/kubeadm/#custom-images&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;kubeadm Setup Tool Reference Guide&lt;/a&gt;这个文档的的Running kubeadm without an internet connection一节里有写。所以可以根据安装的实际版本来跳帧这个脚本的参数。&lt;strong&gt;注意把上面的镜像地址换成自己的。muxi是你创建的一个namespace，而不是仓库名&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;而Kubernetes也提供了镜像地址相关的配置项，一共有三个：&lt;/p&gt;
&lt;p&gt;一个配置文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt; /etc/systemd/system/kubelet.service.d/20-pod-infra-image.conf &amp;lt;&amp;lt;EOF
[Service]
Environment=&amp;quot;KUBELET_EXTRA_ARGS=--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/muxi/pause-amd64:3.0&amp;quot;
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;两个环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export KUBE_REPO_PREFIX=&amp;quot;registry.cn-hangzhou.aliyuncs.com/muxi&amp;quot;
export KUBE_ETCD_IMAGE=&amp;quot;registry.cn-hangzhou.aliyuncs.com/muxi/etcd-amd64:3.0.17&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Trouble-Shooting&quot;&gt;&lt;a href=&quot;#Trouble-Shooting&quot; class=&quot;headerlink&quot; title=&quot;Trouble Shooting&quot;&gt;&lt;/a&gt;Trouble Shooting&lt;/h3&gt;&lt;p&gt;解决了获取镜像的问题之后，K8s集群的搭建应该就问题不大了。我们可以通过：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods --all-namepaces

kubectl get nodes 

kubectl get cs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这几个命令来看集群的运行情况。&lt;/p&gt;
&lt;p&gt;但有一些特殊的问题还是会存在，所以接下来我们就看看如何解决这些问题：&lt;/p&gt;
&lt;h4 id=&quot;Kubeadm-init卡住&quot;&gt;&lt;a href=&quot;#Kubeadm-init卡住&quot; class=&quot;headerlink&quot; title=&quot;Kubeadm init卡住&quot;&gt;&lt;/a&gt;Kubeadm init卡住&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;systemctl status kubelet
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;首先中断初始化，查看kubelet的状态。如果出现cgroupfs相关问题，那就需要同步Docker和kubelet的cgroupfs设置。将两者设置为一样的。具体可以看&lt;a href=&quot;https://github.com/kubernetes/kubernetes/issues/43805#issuecomment-320965626&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;。笔者用的Docker 1.12和Kubernetes 1.7的cgroupfs默认都是systemd，所以没有问题。&lt;/p&gt;
&lt;h4 id=&quot;Flannel下Pod不能访问网络问题&quot;&gt;&lt;a href=&quot;#Flannel下Pod不能访问网络问题&quot; class=&quot;headerlink&quot; title=&quot;Flannel下Pod不能访问网络问题&quot;&gt;&lt;/a&gt;Flannel下Pod不能访问网络问题&lt;/h4&gt;&lt;p&gt;之前遇到过k8s+flannel这个组合下Pod不能访问外网的问题。解决方案如下：&lt;/p&gt;
&lt;p&gt;在Master节点创建一个busybox Pod：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;busybox.yaml&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: default
spec:
  containers:
  - image: busybox
    command:
      - sleep
      - &amp;quot;3600&amp;quot;
    imagePullPolicy: IfNotPresent
    name: busybox
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后运行&lt;code&gt;kubectl create -f busybox.yaml&lt;/code&gt;创建这个Pod。&lt;/p&gt;
&lt;p&gt;在Master节点运行&lt;code&gt;ping 8.8.8.8&lt;/code&gt;，或者ping另外的公网IP。如果没有成功，则用&lt;code&gt;traceroute&lt;/code&gt;查看请求的路由列表。一般来说路由列表到容器的网关之后就断了。我们记下这个网关的IP。在镜像中运行&lt;code&gt;kubectl exec busybox -- ifconfig&lt;/code&gt;，查看eth0设备的IP，这个IP应该就是之前traceroute得到的IP。所以问题出在这个网卡上。&lt;/p&gt;
&lt;p&gt;在Master节点运行&lt;code&gt;ifconfig&lt;/code&gt;，我们看到cni0网卡的IP和之前Pod里的默认网卡的网段是重叠的。所以Pod中的请求就会走这个设备。&lt;/p&gt;
&lt;p&gt;Pod访问公网应该走的是节点上的Docker0设备。cni0是Flannel的虚拟网卡，这个网络自然是不通外网的。为了解决这个问题，我们运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/sbin/iptables -t nat -I POSTROUTING -s 10.24.1.0/24 -j MASQUERADE
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中10.24.1.0/24就是cni0设备的IP。&lt;/p&gt;
&lt;h3 id=&quot;Links&quot;&gt;&lt;a href=&quot;#Links&quot; class=&quot;headerlink&quot; title=&quot;Links&quot;&gt;&lt;/a&gt;Links&lt;/h3&gt;&lt;p&gt;几个不错的社区和博客。大家遇到问题的时候可以去浏览一下看看。说不定会有解决方案。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://tonybai.com/articles/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Tonybai的博客&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kubernetes.org.cn/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;K8s中文社区&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dockone.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Docker.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;安装Kubernetes向来不是一件容易的事情。之前在集群上部署好的K8s突然出了问题，于是需要重新安装。这次没有之前那次那么顺利了，出现了很多奇怪的问题。但经过一番实践和总结，总算是得出了Kubernetes国内安装的一个不完全指南。这个指南理论上适用于任意版本的K8s。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>React 16 Fiber源码速览</title>
    <link href="http://yoursite.com/2017/09/28/react-16-source/"/>
    <id>http://yoursite.com/2017/09/28/react-16-source/</id>
    <published>2017-09-28T14:50:36.000Z</published>
    <updated>2017-10-28T08:14:13.000Z</updated>
    
    <content type="html">&lt;p&gt;React 16在近期发布了。除了将备受争议的BSD+Patents协议改为MIT协议之外，React 16还带来了许多新特性，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;允许在render函数中返回节点数组和字符串。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;render() {
  // 再也不用在外面套一个父节点了
  return [
    // 别忘了加上key
    &amp;lt;li key=&amp;quot;A&amp;quot;&amp;gt;First item&amp;lt;/li&amp;gt;,
    &amp;lt;li key=&amp;quot;B&amp;quot;&amp;gt;Second item&amp;lt;/li&amp;gt;,
    &amp;lt;li key=&amp;quot;C&amp;quot;&amp;gt;Third item&amp;lt;/li&amp;gt;,
  ];
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;提供更好的错误处理。&lt;/li&gt;
&lt;li&gt;支持自定义DOM属性。&lt;/li&gt;
&lt;/ul&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;但最关键的一点还是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fjzoreufb4j20xm0kcjwa.jpg&quot; alt=&quot;twitter&quot;&gt;&lt;/p&gt;
&lt;p&gt;没错，React 16是一次&lt;strong&gt;重写&lt;/strong&gt;，在保持API不变的情况下，将核心架构改为了代号为Fiber的异步渲染架构。新架构带来了的变化有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;体积减小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcgy1fjzoretq6dj210q0bu776.jpg&quot; alt=&quot;file size&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/@aickin/whats-new-with-server-side-rendering-in-react-16-9b0d78585d67&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;服务端渲染速度大幅提升&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;更responsive的界面&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;一次预谋已久的重写&quot;&gt;&lt;a href=&quot;#一次预谋已久的重写&quot; class=&quot;headerlink&quot; title=&quot;一次预谋已久的重写&quot;&gt;&lt;/a&gt;一次预谋已久的重写&lt;/h3&gt;&lt;p&gt;Fiber这个架构并不是突然冒出来的。Facebook的工程师在设计React之初就设想未来的UI渲染会是异步的。从&lt;code&gt;setState()&lt;/code&gt;的设计和React内部的事务机制可以看出这点。&lt;/p&gt;
&lt;p&gt;在去年，React的开发者&lt;a href=&quot;https://github.com/acdlite&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Andrew Clark&lt;/a&gt;在社区中放出了Fiber架构的一个&lt;a href=&quot;https://github.com/acdlite/react-fiber-architecture&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文档&lt;/a&gt;。描述了Fiber架构的基本信息。同时表示Facebook的工程师正在实现这个新架构。今年3月的React Conf 2017上，Lin Clark做了&lt;a href=&quot;https://www.youtube.com/watch?v=ZCuYPiUIONs&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;A Cartoon Intro to Fiber&lt;/a&gt;这个分享，介绍了Fiber架构的工作原理。今年9月，Fiber架构随着React 16正式发布。Fiber架构的代码放在原来的React仓库之中，并且可以通过运行时的判断来切换新老架构，方便测试和部署。因此Fiber的开发是一个渐进的过程。&lt;a href=&quot;http://isfiberreadyyet.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这个网站&lt;/a&gt;实时展示了Fiber通过的测试用例，随着所有用例的通过，Fiber也正式发布了。有趣的是，在React 16发布之前，Fiber架构的React就已经运行在Facebook的产品中了。FB的工程师表示看到新架构在线上产品运行起来，是很激动人心的。具体的情况可以看这篇博客：&lt;a href=&quot;https://code.facebook.com/posts/1716776591680069/react-16-a-look-inside-an-api-compatible-rewrite-of-our-frontend-ui-library/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;React 16: A look inside an API-compatible rewrite of our frontend UI library&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&quot;Fiber概念简介&quot;&gt;&lt;a href=&quot;#Fiber概念简介&quot; class=&quot;headerlink&quot; title=&quot;Fiber概念简介&quot;&gt;&lt;/a&gt;Fiber概念简介&lt;/h3&gt;&lt;p&gt;本文的题目是React 16 Fiber源码速览，所以关注的主要是Fiber相关的代码。在分析源码之前，首先介绍一些基本概念。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;推荐看上文中提到的&lt;a href=&quot;https://www.youtube.com/watch?v=ZCuYPiUIONs&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;A Cartoon Intro to Fiber&lt;/a&gt;。这个分享比较系统和形象解释了Fiber架构的工程流程，并且使用了React源码中的术语。有助于理解Fiber的概念和源码。下文中的配图也来自这个分享。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;reconciler-VS-renderer&quot;&gt;&lt;a href=&quot;#reconciler-VS-renderer&quot; class=&quot;headerlink&quot; title=&quot;reconciler VS renderer&quot;&gt;&lt;/a&gt;reconciler VS renderer&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcgy1fk0jck2eo4j20gk09a76l.jpg&quot; alt=&quot;Reconciler VS Renderer&quot;&gt;&lt;/p&gt;
&lt;p&gt;Reconciler就是我们所说的Virtul DOM，用于计算新老View的差异。React 16之前的reconciler叫Stack reconciler。Fiber是React的新reconciler。Renderer则是和平台相关的代码，负责将View的变化渲染到不同的平台上，DOM、Canvas、Native、VR、WebGL等等平台都有自己的renderer。我们可以看出reconciler是React的核心代码，是各个平台共用的。因此这次React的reconciler更新到Fiber架构是一次重量级的核心架构的更换。&lt;/p&gt;
&lt;p&gt;由reconciler和renderer两个概念引出的是phase的概念。Phase指的是React组件渲染时的阶段。第一阶段是reconciliation，这一阶段做的是Fiber的update，然后产出的是effect list（可以想象成将老的View更新到新的状态所需要做的DOM操作的列表）。这一个阶段是没有副作用的，因此这个过程可以被打断，然后恢复执行。第二阶段是commit阶段。Reconciliation产生的effect list只有在commit之后才会生效，也就是真正应用到DOM中。这一阶段往往不会执行太长时间，因此是同步的，这样也避免了组件内视图层结构和DOM不一致。&lt;/p&gt;
&lt;h4 id=&quot;Fiber是什么&quot;&gt;&lt;a href=&quot;#Fiber是什么&quot; class=&quot;headerlink&quot; title=&quot;Fiber是什么&quot;&gt;&lt;/a&gt;Fiber是什么&lt;/h4&gt;&lt;p&gt;React源码中的注释说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Fiber is work on a Component that needs to be done or was done. There can be more than one per component.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单的说，一个Fiber就是一个POJO对象，代表了组件上需要做的工作。一个React Element可以对应一个或多个Fiber节点。&lt;/p&gt;
&lt;p&gt;在render函数中创建的React Element树在第一次渲染的时候会创建一颗结构一模一样的Fiber节点树。不同的React Element类型对应不同的Fiber节点类型。一个React Element的工作就由它对应的Fiber节点来负责。我们如果在console中打印React 16的组件实例，会发现有一个&lt;code&gt;_reactInternalFiber&lt;/code&gt;属性指向它对应的Fiber实例。&lt;/p&gt;
&lt;p&gt;虽然React的代码中其实没有明确的Virtul DOM概念，但Fiber和我们概念中的Virtul DOM树是等价的。&lt;/p&gt;
&lt;p&gt;Fiber带来了一个给React的渲染带来了重要的变化。React内部有事务的概念。之前React渲染相关的事务是连续的，一旦开始就会run to completion。现在React的事务则是由一系列Fiber的更新组成的，因此React可以在多个帧中断断续续的更新Fiber，最后commit变化。&lt;/p&gt;
&lt;p&gt;那为什么说一个React Element可以对应不止一个Fiber呢？因为Fiber在update的时候，会从原来的Fiber（我们称为current）clone出一个新的Fiber（我们称为alternate）。两个Fiber diff出的变化（side effect）记录在alternate上。所以一个组件在更新时最多会有两个Fiber与其对应，在更新结束后alternate会取代之前的current的成为新的current节点。&lt;/p&gt;
&lt;h4 id=&quot;Fiber节点的数据结构&quot;&gt;&lt;a href=&quot;#Fiber节点的数据结构&quot; class=&quot;headerlink&quot; title=&quot;Fiber节点的数据结构&quot;&gt;&lt;/a&gt;Fiber节点的数据结构&lt;/h4&gt;&lt;p&gt;下面介绍Fiber类型的重要属性：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    tag: TypeOfWork, // fiber的类型，下一节会介绍
    alternate: Fiber|null, // 在fiber更新时克隆出的镜像fiber，对fiber的修改会标记在这个fiber上

    return: Fiber|null, // 指向fiber树中的父节点

    child: Fiber|null, // 指向第一个子节点
    sibling: Fiber|null, // 指向兄弟节点

    effectTag: TypeOfSideEffect, // side effect类型，下文会介绍
    nextEffect: Fiber | null, // 单链表结构，方便遍历fiber树上有副作用的节点
    pendingWorkPriority: PriorityLevel, // 标记子树上待更新任务的优先级

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在实际的渲染过程中，Fiber节点构成了一颗树。这棵树在数据结构上是通过单链表的形式构成的，Fiber节点上的&lt;code&gt;chlid&lt;/code&gt;和&lt;code&gt;sibling&lt;/code&gt;属性分别指向了这个节点的第一个子节点和相邻的兄弟节点。这样就可以遍历整个Fiber树了。&lt;/p&gt;
&lt;p&gt;Fiber树的图示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fkc8x8n8x2j20fa0co428.jpg&quot; alt=&quot;fiber tree&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;TypeOfWork&quot;&gt;&lt;a href=&quot;#TypeOfWork&quot; class=&quot;headerlink&quot; title=&quot;TypeOfWork&quot;&gt;&lt;/a&gt;TypeOfWork&lt;/h4&gt;&lt;p&gt;这是源码中的typeOfWork，代表React中不同类型的fiber节点。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  IndeterminateComponent: 0, // Before we know whether it is functional or class
  FunctionalComponent: 1,
  ClassComponent: 2,
  HostRoot: 3, // Root of a host tree. Could be nested inside another node.
  HostPortal: 4, // A subtree. Could be an entry point to a different renderer.
  HostComponent: 5,
  HostText: 6,
  CoroutineComponent: 7,
  CoroutineHandlerPhase: 8,
  YieldComponent: 9,
  Fragment: 10,
}s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对几个常用的类型作一下解释：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ClassComponent&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;就是应用层面的React组件。ClassComponent是一个继承自React.Component的类的实例。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HostRoot&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ReactDOM.render()时的根节点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HostComponent&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;React中最常见的抽象节点，是ClassComponent的组成部分。具体的实现取决于React运行的平台。在浏览器环境下就代表DOM节点，可以理解为所谓的虚拟DOM节点。HostComponent中的Host就代码这种组件的具体操作逻辑是由Host环境注入的。&lt;/p&gt;
&lt;h4 id=&quot;TypeOfSideEffect&quot;&gt;&lt;a href=&quot;#TypeOfSideEffect&quot; class=&quot;headerlink&quot; title=&quot;TypeOfSideEffect&quot;&gt;&lt;/a&gt;TypeOfSideEffect&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;说一下这是以二进制位表示的。可以多个叠加。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;{
  NoEffect: 0,          
  PerformedWork: 1,   
  Placement: 2, // 插入         
  Update: 4, // 更新           
  PlacementAndUpdate: 6, 
  Deletion: 8, // 删除   
  ContentReset: 16,  
  Callback: 32,      
  Err: 64,         
  Ref: 128,          
};
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;Priority&quot;&gt;&lt;a href=&quot;#Priority&quot; class=&quot;headerlink&quot; title=&quot;Priority&quot;&gt;&lt;/a&gt;Priority&lt;/h4&gt;&lt;p&gt;Priority指的是Fiber中一个work的优先级。这是React源码中的对Priority类型的定义：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  NoWork: 0, // No work is pending.
  SynchronousPriority: 1, // For controlled text inputs. Synchronous side-effects.
  TaskPriority: 2, // Completes at the end of the current tick.
  HighPriority: 3, // Interaction that needs to complete pretty soon to feel responsive.
  LowPriority: 4, // Data fetching, or result from updating stores.
  OffscreenPriority: 5, // Won&amp;#39;t be visible but do the work in case it becomes visible.
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们可以把Priority分为同步和异步两个类别，同步优先级的任务会在当前帧完成，包括SynchronousPriority和TaskPriority。异步优先级的任务则可能在接下来的几个帧中被完成，包括HighPriority、LowPriority以及OffscreenPriority。&lt;/p&gt;
&lt;h3 id=&quot;React-16-Fiber源码目录结构&quot;&gt;&lt;a href=&quot;#React-16-Fiber源码目录结构&quot; class=&quot;headerlink&quot; title=&quot;React 16 Fiber源码目录结构&quot;&gt;&lt;/a&gt;React 16 Fiber源码目录结构&lt;/h3&gt;&lt;p&gt;React库的入口、组件的基类&lt;code&gt;ReactComponent&lt;/code&gt;、&lt;code&gt;ReactElement.createElement&lt;/code&gt;函数等等所有平台公用的代码位于&lt;code&gt;src/isomorphic&lt;/code&gt;下。&lt;/p&gt;
&lt;p&gt;我们关注的Fiber代码位于&lt;code&gt;src/renderers/shared/fiber&lt;/code&gt;下。我们先来看看&lt;code&gt;src/renderers&lt;/code&gt;下面有什么：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fk1ka90rh0j20s109xacl.jpg&quot; alt=&quot;renderers&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到&lt;code&gt;src/renderers&lt;/code&gt;下的代码就是上文介绍的renderer，分dom、native、art等等平台。那我们再看看&lt;code&gt;src/renderers/shared&lt;/code&gt;目录下有什么：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fk1kj1kekxj20s10ezq6q.jpg&quot; alt=&quot;renderers/shared&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;src/renderers/shared&lt;/code&gt;其实就是reconciler相关的代码了。可以看到里面有fiber和stack新老两大reconciler（在笔者发文时，Stack reconciler已经完成了它的使命，相关的代码已经被移除了）。&lt;/p&gt;
&lt;p&gt;最后让我们来看看&lt;code&gt;src/renderers/shared/fiber&lt;/code&gt;下的代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fk1m7cifluj20sh0pk10v.jpg&quot; alt=&quot;fiber&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些就是React fiber的核心代码了。Fiber节点的定义在&lt;code&gt;ReactFiber.js&lt;/code&gt;中，Fiber的reconciler构造函数在&lt;code&gt;ReactFiberReconciler.js&lt;/code&gt;中，Fiber节点的工作流程由&lt;code&gt;ReactFiberBeginWork.js&lt;/code&gt;、&lt;code&gt;ReactFiberCommitWork.js&lt;/code&gt;和&lt;code&gt;ReactFiberCompleteWork.js&lt;/code&gt;组成。Fiber的子节点reconcile逻辑在&lt;code&gt;ReactChildFiber.js&lt;/code&gt;中，&lt;code&gt;ReactFiberScheduler.js&lt;/code&gt;则是调度相关的逻辑。接下来就让我们通过具体的场景，来分析React 16的源码吧！&lt;/p&gt;
&lt;h3 id=&quot;阅读React源码须知&quot;&gt;&lt;a href=&quot;#阅读React源码须知&quot; class=&quot;headerlink&quot; title=&quot;阅读React源码须知&quot;&gt;&lt;/a&gt;阅读React源码须知&lt;/h3&gt;&lt;p&gt;下面简单介绍一下在React源码中，起辅助作用的代码。以免大家在看源码时被这些代码所迷惑。&lt;/p&gt;
&lt;h4 id=&quot;flow-type&quot;&gt;&lt;a href=&quot;#flow-type&quot; class=&quot;headerlink&quot; title=&quot;flow type&quot;&gt;&lt;/a&gt;flow type&lt;/h4&gt;&lt;p&gt;React使用了flow作为静态类型检查工具。所以React源码中都是带有类型声明的。这对熟悉Java或者C++这些静态类型语言的同学应该不陌生。&lt;strong&gt;类型声明对于快速理解源码也是有很大帮助的&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&quot;if-DEV&quot;&gt;&lt;a href=&quot;#if-DEV&quot; class=&quot;headerlink&quot; title=&quot;if (__DEV__)&quot;&gt;&lt;/a&gt;&lt;code&gt;if (__DEV__)&lt;/code&gt;&lt;/h4&gt;&lt;p&gt;React源码中常常有&lt;code&gt;if (__DEV__)&lt;/code&gt;这样的代码，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (__DEV__) {
    warning(
      shouldUpdate !== undefined,
      &amp;#39;%s.shouldComponentUpdate(): Returned undefined instead of a &amp;#39; +
        &amp;#39;boolean value. Make sure to return true or false.&amp;#39;,
      getComponentName(workInProgress) || &amp;#39;Unknown&amp;#39;,
    );
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这些代码是为了更好的开发者体验而编写的。React中的友好的报错，render性能测试等等代码都是写在&lt;code&gt;if (__DEV__)&lt;/code&gt;中的。在production build的时候，这些代码不会被打包。因此我们可以毫无顾虑的提供专为开发者服务的代码。React的最佳实践之一就是在开发时使用development build，在生产环境使用production build。&lt;/p&gt;
&lt;p&gt;大家在刚开始接触源码时可以跳过&lt;code&gt;if (__DEV__)&lt;/code&gt;中的代码，专注于理解核心的部分。&lt;/p&gt;
&lt;h4 id=&quot;源码阅读小技巧&quot;&gt;&lt;a href=&quot;#源码阅读小技巧&quot; class=&quot;headerlink&quot; title=&quot;源码阅读小技巧&quot;&gt;&lt;/a&gt;源码阅读小技巧&lt;/h4&gt;&lt;p&gt;如果读者想在阅读文本之后打算自己深入探索React源码，我可以给出一些阅读源码的小技巧。如果对于React中某个方法的调用过程感兴趣，可以在本地用create-react-app新建一下小demo项目，然后直接在node_modules中的react-dom.development.js和react.development.js两个文件里的对应方法&lt;strong&gt;打断点&lt;/strong&gt;。这样在中断的时候就可以看到整个&lt;strong&gt;调用栈&lt;/strong&gt;了，Chrome种可以通过点击调用栈切换到其中任何一帧的状态。如果发现调用过程中有自己感兴趣的函数，可以clone React的整个仓库，用编辑器对想要查看的函数进行&lt;strong&gt;全局搜索&lt;/strong&gt;，找到那个函数的源码进行阅读。此外还有一个小tip，如果对某个特性的实现感兴趣，可以去&lt;strong&gt;搜索React的pull request和issue列表&lt;/strong&gt;，说不定可以找到当初实现这个特性时候提的PR，PR中一般会写实现时的一些考虑。另外React源码的注释也是非常详尽的，有些已经等于简单的文档了，所以&lt;strong&gt;仔细的阅读注释&lt;/strong&gt;也是理解源码的捷径之一。&lt;/p&gt;
&lt;h4 id=&quot;本文源码的时效性&quot;&gt;&lt;a href=&quot;#本文源码的时效性&quot; class=&quot;headerlink&quot; title=&quot;本文源码的时效性&quot;&gt;&lt;/a&gt;本文源码的时效性&lt;/h4&gt;&lt;p&gt;React 16.0发布后，新架构的很多特性还没有完全开放，因此React这段时间还在一个积极的开发过程中，源码变动会比较大。本文是分析的源码是React v16.0的源码。大家在阅读时Github上的React源码时要注意，目前的master分支的React源码和本文中的源码会有一些差异。比如在本文发布时，React的目录结构就进行了调整，源码从src中转移到了packages目录下，按react、react-reconciler、react-dom等等NPM模块的方式划分。还有一些fiber的实现也在进行一些小的重构。比如在performWork相关的代码中加入performWorkOnRoot和renderRoot这几个函数，通过准确的命名让函数的作用更清晰。又比如Priority的概念直接被expirationTime取代了，workLoop中直接根据expirationTime来判断任务的执行时机。所以&lt;strong&gt;推荐大家阅读master分支下的最新代码&lt;/strong&gt;，因为React 16在代码质量上的确还处于一个未完成的状态，随着进一步的开发，源码的可读性会更高。&lt;/p&gt;
&lt;h3 id=&quot;确定源码分析的入口&quot;&gt;&lt;a href=&quot;#确定源码分析的入口&quot; class=&quot;headerlink&quot; title=&quot;确定源码分析的入口&quot;&gt;&lt;/a&gt;确定源码分析的入口&lt;/h3&gt;&lt;h3 id=&quot;React-16组件源码分析：用户触发的setState开启的一次渲染&quot;&gt;&lt;a href=&quot;#React-16组件源码分析：用户触发的setState开启的一次渲染&quot; class=&quot;headerlink&quot; title=&quot;React 16组件源码分析：用户触发的setState开启的一次渲染&quot;&gt;&lt;/a&gt;React 16组件源码分析：用户触发的&lt;code&gt;setState&lt;/code&gt;开启的一次渲染&lt;/h3&gt;&lt;p&gt;我们知道，React的渲染是由&lt;code&gt;setState&lt;/code&gt;触发的，所以就让我们从&lt;code&gt;setState&lt;/code&gt;入手，来分析React 16的组件渲染流程。&lt;/p&gt;
&lt;h4 id=&quot;setState&quot;&gt;&lt;a href=&quot;#setState&quot; class=&quot;headerlink&quot; title=&quot;setState&quot;&gt;&lt;/a&gt;setState&lt;/h4&gt;&lt;p&gt;&lt;code&gt;setState&lt;/code&gt;方法是React基类上的一个方法。因此位于&lt;code&gt;src/isomorphic&lt;/code&gt;下的&lt;code&gt;modern/class/ReactBaseClasses.js&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fk1m7bwt6vj20fd05pdgr.jpg&quot; alt=&quot;setState&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们看到&lt;code&gt;setState&lt;/code&gt;调用了&lt;code&gt;this.updater.enqueueSetState&lt;/code&gt;。updater是renderer在渲染的时候注入的对象，这个对象由reconciler提供。具体的逻辑可以看&lt;code&gt;ReactDOM.render&lt;/code&gt;相关的代码，这里就不展开了。&lt;/p&gt;
&lt;h4 id=&quot;enqueueSetState&quot;&gt;&lt;a href=&quot;#enqueueSetState&quot; class=&quot;headerlink&quot; title=&quot;enqueueSetState&quot;&gt;&lt;/a&gt;enqueueSetState&lt;/h4&gt;&lt;p&gt;既然updater是reconciler提供的，那我们就可以在fiber的代码中找到它。updater就位于&lt;code&gt;src/renderers/shared/fiberReactFiberCompleteWork.js&lt;/code&gt;中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fk1m7by675j20ch06tjsg.jpg&quot; alt=&quot;enqueueSetState&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里只截取了一部分的updater代码，可以看到updater提供了&lt;code&gt;enqueueSetState&lt;/code&gt;方法，这个方法首先从全局拿到React组件实例对应的fiber，然后拿到了fiber的优先级。最后调用了&lt;code&gt;addUpdate&lt;/code&gt;向队列中推入需要更新的fiber，并调用&lt;code&gt;scheduleUpdate&lt;/code&gt;触发调度器调度一次新的更新。&lt;/p&gt;
&lt;p&gt;熟悉React源码的朋友应该知道，&lt;code&gt;setState&lt;/code&gt;的流程到这里为止，和React 15的流程基本是一样的。从下面开始，我们就可以看到Fiber架构的不同之处了。&lt;/p&gt;
&lt;h4 id=&quot;addUpdate&quot;&gt;&lt;a href=&quot;#addUpdate&quot; class=&quot;headerlink&quot; title=&quot;addUpdate&quot;&gt;&lt;/a&gt;addUpdate&lt;/h4&gt;&lt;p&gt;我们首先来看&lt;code&gt;addUpdate&lt;/code&gt;函数，这个函数向Fiber的更新队列里加入一次更新：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function addUpdate(
  fiber: Fiber,
  partialState: PartialState&amp;lt;any, any&amp;gt; | null,
  callback: mixed,
  priorityLevel: PriorityLevel,
): void {
  const update = {
    priorityLevel,
    partialState,
    callback,
    isReplace: false,
    isForced: false,
    isTopLevelUnmount: false,
    next: null,
  };
  insertUpdate(fiber, update);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;addUpdate&lt;/code&gt;函数组装了一个update，然后将fiber和update传入了insertUpdate函数中。我们先来看一下这里用到的两个类型，Update和UpdateQueue：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;type UpdateQueue = {
  first: Update | null,
  last: Update | null,
  hasForceUpdate: boolean,
  callbackList: null | Array&amp;lt;Callback&amp;gt;,

  // Dev only
  isProcessing?: boolean,
};
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;type Update = {
  priorityLevel: PriorityLevel,
  partialState: PartialState&amp;lt;any, any&amp;gt;,
  callback: Callback | null,
  isReplace: boolean,
  isForced: boolean,
  isTopLevelUnmount: boolean,
  next: Update | null,
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们可以看到，UpdateQueue是一个单向链表，有first和last指针指向链表的头部和尾部。其中的每一个Update都有一个next属性指向下一个Update。这样的数据结构在React 16中是很常见的。&lt;/p&gt;
&lt;p&gt;之前说到，在更新时，一个React element会有一个current fiber和一个alternate fiber。我们又把alternate fiber叫working in progress fiber。这两个fiber都有一个Update Queue。这两个Queue里面的item的引用是相同的，也就是所谓的persistent structure。区别在于，working in progress fiber会在更新完一个队列项之后将其从队列中移除。所以working in progress update queue永远是current queue的一个子集。在更新完成之后，working in progress fiber取代current fiber成为新的current fiber。如果更新中断（有更高优先级的更新插入），current fiber的update queue就可以作为备份，使得之前中断的更新可以重新开始。&lt;/p&gt;
&lt;p&gt;再看&lt;code&gt;insertUpdate&lt;/code&gt;，这个函数处理了将一个update插入到current queue和work-in-progress queue两个队列中的逻辑：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcgy1fkbtqzlproj21eq210nik.jpg&quot; alt=&quot;insertUpdate&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;scheduleUpdate&quot;&gt;&lt;a href=&quot;#scheduleUpdate&quot; class=&quot;headerlink&quot; title=&quot;scheduleUpdate&quot;&gt;&lt;/a&gt;scheduleUpdate&lt;/h4&gt;&lt;p&gt;看完了&lt;code&gt;addUpdate&lt;/code&gt;相关的逻辑，我们再来看&lt;code&gt;scheduleUpdate&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcgy1fkbz4oej2tj21do3c91kx.jpg&quot; alt=&quot;scheduleUpdate&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;performWork&quot;&gt;&lt;a href=&quot;#performWork&quot; class=&quot;headerlink&quot; title=&quot;performWork&quot;&gt;&lt;/a&gt;performWork&lt;/h4&gt;&lt;p&gt;performWork的作用就是“刷新”待更新队列，执行待更新的事务：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fkc077e5vgj20g2244gun.jpg&quot; alt=&quot;performWork&quot;&gt;&lt;/p&gt;
&lt;p&gt;performWork的代码很长，其中很大一部分是错误处理代码，这些代码和React16中的新特性有关，官方博客的介绍如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Previously, runtime errors during rendering could put React in a broken state, producing cryptic error messages and requiring a page refresh to recover. To address this problem, React 16 uses a more resilient error-handling strategy. By default, if an error is thrown inside a component’s render or lifecycle methods, the whole component tree is unmounted from the root. This prevents the display of corrupted data. However, it’s probably not the ideal user experience.&lt;br&gt;Instead of unmounting the whole app every time there’s an error, you can use error boundaries. Error boundaries are special components that capture errors inside their subtree and display a fallback UI in its place. Think of error boundaries like try-catch statements, but for React components.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们需要关注的函数，一个是&lt;code&gt;workLoop&lt;/code&gt;，这个函数是React更新pendingWork队列的主循环。一个是&lt;code&gt;scheduleDeferredCallback&lt;/code&gt;，这个函数会在未来安排一次更新，来处理&lt;code&gt;workLoop&lt;/code&gt;中没有做完的事务。&lt;/p&gt;
&lt;h4 id=&quot;workLoop&quot;&gt;&lt;a href=&quot;#workLoop&quot; class=&quot;headerlink&quot; title=&quot;workLoop&quot;&gt;&lt;/a&gt;workLoop&lt;/h4&gt;&lt;p&gt;&lt;em&gt;图片注释还需要打磨&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们来看&lt;code&gt;workLoop&lt;/code&gt;的代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcgy1fkc0p3sx5fj21e93z97wh.jpg&quot; alt=&quot;workLoop&quot;&gt;&lt;/p&gt;
&lt;p&gt;除了图中所注释的，&lt;code&gt;workLoop&lt;/code&gt;中有一个值得注意的细节。我们看到，loop中首先判断nextUnitOfWork的优先级是不是高于或等于TaskPriority。如果不是，则进入另一个分支，这个分支和前一个在对nextUnitOfWork的处理上有着微妙的区别。之前在介绍Priority的时候我们说到过，TaskPriority以及更高的优先级属于同步优先级，这些更新会在nextTick之前完成。所以loop中的两个分支其实就是对同步和异步的任务做了不同的处理。两个分支的区别主要是第二个分支使用了deadline.timeRemaining()来判断是否还有时间继续处理任务。&lt;/p&gt;
&lt;p&gt;在之前的分析中，我们没有关注deadline这个参数，workLoop中的这个参数是从performWork中传入的，而performWork中的deadline参数是由scheduleUpdateImpl传入的。scheduleUpdateImpl给同步优先级的任务的deadline参数传入的是null。这是符合常理的，因为同步优先级的任务会一定会在一次workLoop中执行完毕。scheduleUpdateImpl中的异步优先级的任务在scheduleDeferredCallback中处理，我们看这个函数的类型：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scheduleDeferredCallback(
    callback: (deadline: Deadline) =&amp;gt; void,
  ): number | void,
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;deadline出现了！所以异步任务的deadline是在被scheduleDeferredCallback调用时传入的。&lt;/p&gt;
&lt;h4 id=&quot;scheduleDeferredCallback&quot;&gt;&lt;a href=&quot;#scheduleDeferredCallback&quot; class=&quot;headerlink&quot; title=&quot;scheduleDeferredCallback&quot;&gt;&lt;/a&gt;scheduleDeferredCallback&lt;/h4&gt;&lt;p&gt;让我们来看看&lt;code&gt;scheduleDeferredCallback&lt;/code&gt;这个函数。全局搜索一番，我们发现这个函数是在renderer初始化时被注入的。&lt;/p&gt;
&lt;p&gt;React 16抽象出了一个叫&lt;code&gt;ReactFiberReconciler&lt;/code&gt;的工厂函数。这个函数接收一个&lt;code&gt;HostConfig&lt;/code&gt;类型的参数，返回一个Reconciler。每个renderer初始化时需要传入当前平台相关的配置，也就是一个&lt;code&gt;HostConfig&lt;/code&gt;实例，才能拿到一个自定义的Reconciler。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里说一点题外话，React抽象出这个工厂函数意味着React标准化了自定义Renderer的接口。Renderer通过&lt;code&gt;ReactFiberReconciler&lt;/code&gt;这个API就可以将自定义Renderer接入FiberReconciler。&lt;a href=&quot;https://github.com/nitin42/Making-a-custom-React-renderer&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Making-a-custom-React-renderer&lt;/a&gt;就利用了这个函数来打造自定义Renderer。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;HostConfig&lt;/code&gt;的类型签名是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export type HostConfig&amp;lt;T, P, I, TI, PI, C, CX, PL&amp;gt; = {
  getRootHostContext(rootContainerInstance: C): CX,
  getChildHostContext(parentHostContext: CX, type: T, instance: C): CX,
  getPublicInstance(instance: I | TI): PI,

  createInstance(
    type: T,
    props: P,
    rootContainerInstance: C,
    hostContext: CX,
    internalInstanceHandle: OpaqueHandle,
  ): I,
  appendInitialChild(parentInstance: I, child: I | TI): void,
  finalizeInitialChildren(
    parentInstance: I,
    type: T,
    props: P,
    rootContainerInstance: C,
  ): boolean,

  prepareUpdate(
    instance: I,
    type: T,
    oldProps: P,
    newProps: P,
    rootContainerInstance: C,
    hostContext: CX,
  ): null | PL,
  commitUpdate(
    instance: I,
    updatePayload: PL,
    type: T,
    oldProps: P,
    newProps: P,
    internalInstanceHandle: OpaqueHandle,
  ): void,
  commitMount(
    instance: I,
    type: T,
    newProps: P,
    internalInstanceHandle: OpaqueHandle,
  ): void,

  shouldSetTextContent(type: T, props: P): boolean,
  resetTextContent(instance: I): void,
  shouldDeprioritizeSubtree(type: T, props: P): boolean,

  createTextInstance(
    text: string,
    rootContainerInstance: C,
    hostContext: CX,
    internalInstanceHandle: OpaqueHandle,
  ): TI,
  commitTextUpdate(textInstance: TI, oldText: string, newText: string): void,

  appendChild(parentInstance: I, child: I | TI): void,
  appendChildToContainer(container: C, child: I | TI): void,
  insertBefore(parentInstance: I, child: I | TI, beforeChild: I | TI): void,
  insertInContainerBefore(
    container: C,
    child: I | TI,
    beforeChild: I | TI,
  ): void,
  removeChild(parentInstance: I, child: I | TI): void,
  removeChildFromContainer(container: C, child: I | TI): void,

  scheduleDeferredCallback(
    callback: (deadline: Deadline) =&amp;gt; void,
  ): number | void,

  prepareForCommit(): void,
  resetAfterCommit(): void,

  // Optional hydration
  canHydrateInstance?: (instance: I | TI, type: T, props: P) =&amp;gt; boolean,
  canHydrateTextInstance?: (instance: I | TI, text: string) =&amp;gt; boolean,
  getNextHydratableSibling?: (instance: I | TI) =&amp;gt; null | I | TI,
  getFirstHydratableChild?: (parentInstance: I | C) =&amp;gt; null | I | TI,
  hydrateInstance?: (
    instance: I,
    type: T,
    props: P,
    rootContainerInstance: C,
    hostContext: CX,
    internalInstanceHandle: OpaqueHandle,
  ) =&amp;gt; null | PL,
  hydrateTextInstance?: (
    textInstance: TI,
    text: string,
    internalInstanceHandle: OpaqueHandle,
  ) =&amp;gt; boolean,
  didNotHydrateInstance?: (parentInstance: I | C, instance: I | TI) =&amp;gt; void,
  didNotFindHydratableInstance?: (
    parentInstance: I | C,
    type: T,
    props: P,
  ) =&amp;gt; void,
  didNotFindHydratableTextInstance?: (
    parentInstance: I | C,
    text: string,
  ) =&amp;gt; void,

  useSyncScheduling?: boolean,
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里主要包括一些平台相关的代码，比如节点的操作（&lt;code&gt;insertBefore&lt;/code&gt;和&lt;code&gt;appendChild&lt;/code&gt;等等），还有一些配置项，比如&lt;code&gt;useSyncScheduling&lt;/code&gt;。我们看到&lt;code&gt;scheduleDeferredCallback&lt;/code&gt;就在其中。我们来看看renderer初始化的代码：&lt;/p&gt;
&lt;p&gt;在React DOM的入口中：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scheduleDeferredCallback: ReactDOMFrameScheduling.rIC,
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在React Native的入口中：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scheduleDeferredCallback: global.requestIdleCallback,
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们可以看到&lt;code&gt;scheduleDeferredCallback&lt;/code&gt;的实现和平台相关。在Native环境下，它是React Native的js runtime提供的&lt;code&gt;global.requestIdleCallback&lt;/code&gt;，在浏览器环境下，它是&lt;code&gt;ReactDOMFrameScheduling.rIC&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&quot;Cooperative-Scheduling-amp-amp-requestIdleCallback&quot;&gt;&lt;a href=&quot;#Cooperative-Scheduling-amp-amp-requestIdleCallback&quot; class=&quot;headerlink&quot; title=&quot;Cooperative Scheduling &amp;amp;&amp;amp; requestIdleCallback&quot;&gt;&lt;/a&gt;Cooperative Scheduling &amp;amp;&amp;amp; requestIdleCallback&lt;/h4&gt;&lt;p&gt;&lt;code&gt;window.requestIdleCallback&lt;/code&gt;的函数签名和&lt;code&gt;scheduleDeferredCallback&lt;/code&gt;是一模一样的。requestIdleCallback的callback接收一个&lt;code&gt;IdleDeadline&lt;/code&gt;类型的参数。这个&lt;code&gt;IdleDeadline&lt;/code&gt;和React中的&lt;code&gt;deadline&lt;/code&gt;都有一个&lt;code&gt;timeRemaining&lt;/code&gt;方法。&lt;/p&gt;
&lt;p&gt;requestIdleCallback的W3C规范叫Cooperative Scheduling of Background Tasks。React官方在介绍fiber时也提到了Cooperative Scheduling这种技术。从源码来看，React主要利用了浏览器提供的requestIdleCallback API来实现这一特性。&lt;/p&gt;
&lt;p&gt;相比于利用setTimout这样的API实现task scheduling，requestIdleCallback带来的Cooperative Scheduling让开发者让浏览器在空闲时间调用callback，并且在callback中可以获取到当前帧剩余的时间。利用这个信息我们可以合理的安排当前帧需要做的工作，如果工作太多而时间不够，就再调用requestIdleCallback来做剩余的工作。&lt;/p&gt;
&lt;p&gt;requestIdleCallback的回调具体执行的时间点是在一帧开始，JavaScript执行完，浏览器执行渲染流程之后，到这帧结束之前。图示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcgy1fkc7kiv42qj20kh03vq3a.jpg&quot; alt=&quot;idleCallback&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;deadline&lt;/code&gt;中的&lt;code&gt;timeRemaining&lt;/code&gt;的最大值是50ms，以免浏览器长期空闲时，callback的任务一直执行，使得UI不能及时响应用户输入。&lt;/p&gt;
&lt;h4 id=&quot;ReactDOMFrameScheduling-rIC&quot;&gt;&lt;a href=&quot;#ReactDOMFrameScheduling-rIC&quot; class=&quot;headerlink&quot; title=&quot;ReactDOMFrameScheduling.rIC&quot;&gt;&lt;/a&gt;ReactDOMFrameScheduling.rIC&lt;/h4&gt;&lt;p&gt;&lt;code&gt;ReactDOMFrameScheduling.rIC&lt;/code&gt;的逻辑是，如果浏览器实现了requestIdleCallback，就返回原生API。如果没有实现，就返回一个polyfill。这个polyfill的实现非常有趣，可以学到很多有意思的黑科技。&lt;/p&gt;
&lt;p&gt;我们来看看&lt;code&gt;ReactDOMFrameScheduling.rIC&lt;/code&gt;的实现：&lt;/p&gt;
&lt;p&gt;虽然Chrome和Firefox都已经实现了requestIdleCallback，但某些浏览器还是需要polyfill，所以我们重点关注一下requestIdleCallback的polyfill的实现。&lt;/p&gt;
&lt;p&gt;预估一个比较低的frame rate。requestAnimationFrame获取一帧开始，时间戳，触发一个message事件，postMessage在layout paint和composite之后被调用。deadline通过frame rate - rafTime可以得到&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;| frame start time                                      deadline |
[requestAnimationFrame] [layout] [paint] [composite] [postMessage]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过requestAnimationFrame直接的时间差获取过去两帧的准确frame rate，动态调整当前帧的frame rate。&lt;/p&gt;
&lt;h4 id=&quot;默认优先级&quot;&gt;&lt;a href=&quot;#默认优先级&quot; class=&quot;headerlink&quot; title=&quot;默认优先级&quot;&gt;&lt;/a&gt;默认优先级&lt;/h4&gt;&lt;p&gt;既然一次更新是同步还是异步是由优先级决定的，那我们在用户代码中通过&lt;code&gt;setState&lt;/code&gt;来schedule的一次update的优先级是多少呢？&lt;/p&gt;
&lt;p&gt;我们回顾一下&lt;code&gt;enqueueSetState&lt;/code&gt;的代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fk1m7by675j20ch06tjsg.jpg&quot; alt=&quot;enqueueSetState&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;addUpdate&lt;/code&gt;和&lt;code&gt;scheduleUpdate&lt;/code&gt;的&lt;code&gt;priorityLevel&lt;/code&gt;是通过&lt;code&gt;getPriorityContext(fiber, false)&lt;/code&gt;获取的。&lt;/p&gt;
&lt;p&gt;我们来看看&lt;code&gt;getPriorityContext&lt;/code&gt;的实现：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fkd4vrvbycj20ox0ian05.jpg&quot; alt=&quot;getPriorityContext&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以我们得出了一个重要的结论。在React 16中，&lt;strong&gt;异步渲染默认是关闭的&lt;/strong&gt;。用户代码的优先级是同步的。&lt;/p&gt;
&lt;h4 id=&quot;performUnitOfWork&quot;&gt;&lt;a href=&quot;#performUnitOfWork&quot; class=&quot;headerlink&quot; title=&quot;performUnitOfWork&quot;&gt;&lt;/a&gt;performUnitOfWork&lt;/h4&gt;&lt;p&gt;讲完了deadline对象的由来，我们回到workLoop，看看React是的reconcilation是如何进行的。我们可以看到首先被调用的是performUnitOfWork，这个函数做的就是所谓的reconcilation阶段的工作了。然后React将调用commitAllWork进入commit阶段，将reconcilation结果真正应用到DOM中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcgy1fkc84mx1vij20fa0gq7af.jpg&quot; alt=&quot;performUnitOfWork&quot;&gt;&lt;/p&gt;
&lt;p&gt;React 16保持了之前版本的事务风格，一个“work”会被分解为begin和complete两个阶段来完成。我们先关注beginWork&lt;/p&gt;
&lt;h4 id=&quot;beginWork&quot;&gt;&lt;a href=&quot;#beginWork&quot; class=&quot;headerlink&quot; title=&quot;beginWork&quot;&gt;&lt;/a&gt;beginWork&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fk6jdy25scj20wq1kvqdw.jpg&quot; alt=&quot;beginWOrk&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;beginWork&lt;/code&gt;函数根据fiber节点不同的tag，调用对应的update方法。可以说是一个入口函数。真正的逻辑要看update开头的这一些了函数。&lt;/p&gt;
&lt;h4 id=&quot;updateClassComponent-amp-amp-updateHostComponent&quot;&gt;&lt;a href=&quot;#updateClassComponent-amp-amp-updateHostComponent&quot; class=&quot;headerlink&quot; title=&quot;updateClassComponent &amp;amp;&amp;amp; updateHostComponent&quot;&gt;&lt;/a&gt;updateClassComponent &amp;amp;&amp;amp; updateHostComponent&lt;/h4&gt;&lt;p&gt;上一节中讲到，&lt;code&gt;beginWork&lt;/code&gt;中不同tag的元素有不同的update系列方法，我们重点关注的是对ClassComponent和HostComponent两种component的更新方法。ClassComponent对应的是React组件实例，HostComponent对应的是一个视图层节点，在浏览器环境中就等于DOM节点。&lt;/p&gt;
&lt;p&gt;我们先关注&lt;code&gt;updateClassComponent&lt;/code&gt;函数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fkq4dx9ljkj20ox0jyn2j.jpg&quot; alt=&quot;updateClassComponent&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;updateHostComponent&lt;/code&gt;这里就不再详细分析了。因此HostComponent没有生命周期钩子需要处理，这个函数主要做的就是调用&lt;code&gt;reconcileChildren&lt;/code&gt;对子节点进行diff。&lt;/p&gt;
&lt;h4 id=&quot;reconcileChildren&quot;&gt;&lt;a href=&quot;#reconcileChildren&quot; class=&quot;headerlink&quot; title=&quot;reconcileChildren&quot;&gt;&lt;/a&gt;reconcileChildren&lt;/h4&gt;&lt;p&gt;&lt;code&gt;reconcileChildren&lt;/code&gt;实现的就是江湖上广为流传的Virtul DOM diff。这年头人人都看过一两个Virtul DOM diff的实现，那React 16的diff是如何实现的呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcgy1fkurhf1dgwj20p60sy44v.jpg&quot; alt=&quot;reconcileChildren&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reconcileChildren&lt;/code&gt;这个函数里调用了三个功能相似的函数：&lt;code&gt;mountChildFibersInPlace&lt;/code&gt;、&lt;code&gt;reconcileChildFibers&lt;/code&gt;和&lt;code&gt;reconcileChildFibersInPlace&lt;/code&gt;。在源码中我们发现，这三个函数其实是同一个函数，通过传入不同的参数“重载”而来的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;exports.reconcileChildFibers = ChildReconciler(true, true);

exports.reconcileChildFibersInPlace = ChildReconciler(false, true);

exports.mountChildFibersInPlace = ChildReconciler(false, false);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ChildReconciler是一个工厂函数，它接收shouldClone, shouldTrackSideEffects两个参数。reconcileChildFibers函数的目的是产出effect list，所以shouldClone, shouldTrackSideEffects两个参数都是true。mountChildFibersInPlace是组件初始化时用的，所以不用clone fiber来diff，也不用产出effect list。reconcileChildFibersInPlace是在之前reconcile被中断的fiber树上继续工作，因此shouldClone参数为false。&lt;/p&gt;
&lt;p&gt;ChildReconciler内部有很多helper函数，最终返回的函数叫reconcileChildFibers，这个函数实现了对子fiber节点的reconciliation。下面我们关注reconcileChildFibers函数的实现。&lt;/p&gt;
&lt;h4 id=&quot;reconcileChildFibers&quot;&gt;&lt;a href=&quot;#reconcileChildFibers&quot; class=&quot;headerlink&quot; title=&quot;reconcileChildFibers&quot;&gt;&lt;/a&gt;reconcileChildFibers&lt;/h4&gt;&lt;p&gt;图的注释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;总的，这个函数根据newChild的类型调用不同的方法。newChild可能是一个元素，也可能是一个数组（React16新特性）&lt;/li&gt;
&lt;li&gt;如果是reconcile单个元素，以reconcileSingleElement为例比较key和type，如果相同，复用fiber，删除多余的元素（currentFirstChild的sibling），如果不同，调用createFiberFromElement，返回新创建的。&lt;/li&gt;
&lt;li&gt;如果是string，reconcileSingleTextNode&lt;/li&gt;
&lt;li&gt;如果是array，reconcileChildrenArray&lt;/li&gt;
&lt;li&gt;如果是空，deleteRemainingChildren删除老的子元素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;React的reconcile算法采用的是层次遍历，这种算法是建立在一个节点的插入、删除、移动等操作都是在&lt;strong&gt;节点树的同一层级中进行&lt;/strong&gt;这个假设下的。所以reconcile算法的核心就是如何diff两个子节点数组。&lt;/p&gt;
&lt;h4 id=&quot;reconcileChildrenArray&quot;&gt;&lt;a href=&quot;#reconcileChildrenArray&quot; class=&quot;headerlink&quot; title=&quot;reconcileChildrenArray&quot;&gt;&lt;/a&gt;reconcileChildrenArray&lt;/h4&gt;&lt;p&gt;React16的diff算法采用和来自社区的两端同时比较法同样结构的算法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;关于diff算法演化历史可以看司徒正美的&lt;a href=&quot;https://segmentfault.com/a/1190000011235844&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这篇博客&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因为fiber树是单链表结构，没有子节点数组这样的数据结构。也就没有可以供两端同时比较的尾部游标。所以React的这个算法是一个简化的两端比较法，只从头部开始比较。&lt;/p&gt;
&lt;p&gt;下面我们来看一下代码：&lt;/p&gt;
&lt;p&gt;图片&lt;/p&gt;
&lt;p&gt;从头部遍历。第一次遍历新数组，对上了，新老index都++，比较新老数组哪些元素是一样的，（通过updateSlot，比较key），如果是同样的就update。第一次遍历玩了，如果新数组遍历完了，那就可以把老数组中剩余的fiber删除了。&lt;/p&gt;
&lt;p&gt;如果老数组完了新数组还没完，那就把新数组剩下的都插入。&lt;/p&gt;
&lt;p&gt;如果这些情况都不是，就把所有老数组元素按key放map里，然后遍历新数组，插入老数组的元素，这是移动的情况。&lt;/p&gt;
&lt;p&gt;最后再删除没有被上述情况涉及的元素（也就是老数组中有新数组中无的元素，上面的删除只是fast path，特殊情况）&lt;/p&gt;
&lt;h4 id=&quot;completeUnitOfWork&quot;&gt;&lt;a href=&quot;#completeUnitOfWork&quot; class=&quot;headerlink&quot; title=&quot;completeUnitOfWork&quot;&gt;&lt;/a&gt;completeUnitOfWork&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;注：这里effect list链表插入的想法只是猜测，需要进一步确认。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;completeUnitOfWork&lt;/code&gt;是complete阶段的入口。complete阶段的作用就是在一个节点diff完成之后，对它进行一些收尾工作，主要是更新props和调用生命周期方法等等。&lt;code&gt;completeUnitOfWork&lt;/code&gt;主要的逻辑是调用&lt;code&gt;completeWork&lt;/code&gt;完成收尾，然后将当前子树的effect list插入到HostRoot的effect list中。具体的让我们来看代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcgy1fks860npkqj20p41foalg.jpg&quot; alt=&quot;completeUnitOfWork&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;completeWork&quot;&gt;&lt;a href=&quot;#completeWork&quot; class=&quot;headerlink&quot; title=&quot;completeWork&quot;&gt;&lt;/a&gt;completeWork&lt;/h4&gt;&lt;p&gt;complete阶段主要工作都是在&lt;code&gt;completeWork&lt;/code&gt;中完成的。这个函数很长，需要仔细梳理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fkurhf2r9jj20ou3c9x1u.jpg&quot; alt=&quot;completeWork&quot;&gt;&lt;/p&gt;
&lt;p&gt;可见completeWork主要是完成reconciliation阶段的扫尾工作，重点是对HostComponent的props进行diff，并标记更新。&lt;/p&gt;
&lt;p&gt;到这里，我们就讲完了reconciliation阶段。这个阶段主要负责产出effect list。所以可以说reconcile的过程相当于是一个纯函数，输入是fiber节点，输出一个effect list。side-effects是在commit阶段被应用到UI中的，这样就将side-effects从reconciliation中隔离开了。因为纯函数的可预测性，让我们可以随时中断reconciliation阶段的执行，而不用担心side-effects给让组件状态和实际UI产生不一致。&lt;/p&gt;
&lt;p&gt;commit这个阶段有点像Git的commit概念。在缓冲区中的代码改动只有在commit之后才会被添加到Git的Object store中。&lt;/p&gt;
&lt;p&gt;下面我们就来关注commit阶段的实现。看看effect list是如何被“提交”到UI中的。&lt;/p&gt;
&lt;h4 id=&quot;commitAllWork&quot;&gt;&lt;a href=&quot;#commitAllWork&quot; class=&quot;headerlink&quot; title=&quot;commitAllWork&quot;&gt;&lt;/a&gt;commitAllWork&lt;/h4&gt;&lt;p&gt;reconciliation阶段结束之后，我们需要将effect list更新到UI中。这就是commit节点的工作。commit阶段的入口是&lt;code&gt;commitAllWork&lt;/code&gt;函数，我们来看看它的实现：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcgy1fkorwi0836j20oz2f71b8.jpg&quot; alt=&quot;commitAllWork&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里需要注意的是，React 16中的生命周期方法是在reconciliation和commit两个阶段中被调用的，commit阶段的&lt;code&gt;commitAllLifeCycles&lt;/code&gt;函数中的生命周期方法包括&lt;code&gt;componentDidMount&lt;/code&gt;、&lt;code&gt;componentDidUpdate&lt;/code&gt;和&lt;code&gt;componentWillUnmount&lt;/code&gt;三个。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fknn7fnubmj20eb08wjt7.jpg&quot; alt=&quot;lifeCycle&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;reconciliation-commit流程总结&quot;&gt;&lt;a href=&quot;#reconciliation-commit流程总结&quot; class=&quot;headerlink&quot; title=&quot;reconciliation+commit流程总结&quot;&gt;&lt;/a&gt;reconciliation+commit流程总结&lt;/h4&gt;&lt;p&gt;经过上述对reconciliation和commit两个阶段的源码分析，是不是觉得有些混乱？我总结了一张reconciliation+commit过程中的函数调用图，希望可以帮助你理清这两个阶段的函数调用流程。从图中我们可以看出，&lt;code&gt;workLoop&lt;/code&gt;中调用了&lt;code&gt;performUnitOfWork&lt;/code&gt;和&lt;code&gt;commitAllWork&lt;/code&gt;，分别作为reconciliation和commit两个阶段的入口。&lt;code&gt;performUnitOfWork&lt;/code&gt;中又分为begin和complete两个阶段来处理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcgy1fkota00kyhj20o402ydg3.jpg&quot; alt=&quot;callStack&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;展望-amp-amp-结语&quot;&gt;&lt;a href=&quot;#展望-amp-amp-结语&quot; class=&quot;headerlink&quot; title=&quot;展望&amp;amp;&amp;amp;结语&quot;&gt;&lt;/a&gt;展望&amp;amp;&amp;amp;结语&lt;/h3&gt;&lt;h4 id=&quot;潜伏的大招——异步渲染&quot;&gt;&lt;a href=&quot;#潜伏的大招——异步渲染&quot; class=&quot;headerlink&quot; title=&quot;潜伏的大招——异步渲染&quot;&gt;&lt;/a&gt;潜伏的大招——异步渲染&lt;/h4&gt;&lt;p&gt;在上文中，我们知道，React 16中默认没有开启异步渲染。用户的setState都是和React 15一样，在一个tick内完成的。fiber可以解决的问题，比如将优先级低的任务分散在多个帧中完成，在每一帧中留足够的时间给响应用户输入和渲染这样优先级高的任务。在默认不开启异步渲染的情况下，是不能做到的。因此我们期待未来版本的React可以开启这个杀手特性。&lt;/p&gt;
&lt;p&gt;我们在阅读源码的过程中，看到了一些没有被文档记录的组件类型，比如CoroutineComponent和YieldComponent。这也许意味着未来React会把渲染的时机掌控权交给用户。我们可以定义一个CoroutineComponent，在reconcile完成后交出控制权给用户。由用户主动调用commit来让组件继续渲染。因为React将组件的渲染分为reconcile和commit两个阶段，reconcile又是没有副作用的，由多个院子操作组成。因此这样的设想是完全可行的。以上只是笔者的推测，丢一个A Clark的链接。&lt;/p&gt;
&lt;h4 id=&quot;React-16的设计给前端框架带来的思考&quot;&gt;&lt;a href=&quot;#React-16的设计给前端框架带来的思考&quot; class=&quot;headerlink&quot; title=&quot;React 16的设计给前端框架带来的思考&quot;&gt;&lt;/a&gt;React 16的设计给前端框架带来的思考&lt;/h4&gt;&lt;p&gt;这次React更新核心架构，让我们看到Facebook的工程师再次用技术推进了用户体验的极限。淘宝FED的口号是用技术为体验提供无限可能，笔者觉得这句话用来形容React也是很合适的。在React上，我们看到了一些借鉴自操作系统中的设计。Fiber可以被比作是一个轻量级线程。有自己的数据，也有优先级的分别。React的作用就是调度fiber，使得优先级高的任务优先执行，同时也保证低优先级的任务会在未来一段时间执行完毕。在diff算法的设计上，React借鉴了社区的经验，这是对社区的一种认可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;React 16在近期发布了。除了将备受争议的BSD+Patents协议改为MIT协议之外，React 16还带来了许多新特性，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;允许在render函数中返回节点数组和字符串。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;render() {
  // 再也不用在外面套一个父节点了
  return [
    // 别忘了加上key
    &amp;lt;li key=&amp;quot;A&amp;quot;&amp;gt;First item&amp;lt;/li&amp;gt;,
    &amp;lt;li key=&amp;quot;B&amp;quot;&amp;gt;Second item&amp;lt;/li&amp;gt;,
    &amp;lt;li key=&amp;quot;C&amp;quot;&amp;gt;Third item&amp;lt;/li&amp;gt;,
  ];
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;提供更好的错误处理。&lt;/li&gt;
&lt;li&gt;支持自定义DOM属性。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Table组件中slot内容的跨级传递</title>
    <link href="http://yoursite.com/2017/09/19/table-component-slot-passing/"/>
    <id>http://yoursite.com/2017/09/19/table-component-slot-passing/</id>
    <published>2017-09-19T07:00:09.000Z</published>
    <updated>2017-09-19T07:02:08.000Z</updated>
    
    <content type="html">&lt;p&gt;在开发MUI的&lt;a href=&quot;https://github.com/Muxi-Studio/MUI/tree/dev/src/components/table&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Table组件&lt;/a&gt;时，我们遇到了一个问题。用户在顶层组件中嵌套的内容，需要被保存到组件的数据中，并且在表格内部渲染出来。&lt;/p&gt;
&lt;p&gt;通常，Vue内嵌内容是使用slot进行渲染的。在父组件的模板中，在子组件的标签中嵌入模板，然后在子组件的内部，使用&lt;code&gt;&amp;lt;slot/&amp;gt;&lt;/code&gt;标签进行渲染。但现在我们的需求是非父子组件的slot渲染，这就要求我们换一种思路去保存和调用slot。&lt;/p&gt;
&lt;p&gt;要理解以下的内容，&lt;strong&gt;请确保你阅读了&lt;a href=&quot;https://vuejs.org/v2/guide/render-function.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Render Functions &amp;amp; JSX&lt;/a&gt;，理解了Vue的VNode、render function、模板等概念以及这些概念之间的关系&lt;/strong&gt;。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;slot方案&quot;&gt;&lt;a href=&quot;#slot方案&quot; class=&quot;headerlink&quot; title=&quot;slot方案&quot;&gt;&lt;/a&gt;slot方案&lt;/h3&gt;&lt;p&gt;首先要明确一个点，所谓的slot就指的是一个组件在声明时候的内嵌内容。Vue的模板都会被编译成VNode节点树，slot指的是一个VNode的&lt;code&gt;children&lt;/code&gt;属性这个数组里包含的VNode节点集合，这些内容由组件声明时的内嵌内容编译而来。&lt;/p&gt;
&lt;p&gt;我们可以通过&lt;code&gt;this.$slots.default&lt;/code&gt;拿到默认的子VNode列表。如果内嵌内容上没有声明&lt;code&gt;name&lt;/code&gt;属性，那这些内容都归属于&lt;code&gt;default&lt;/code&gt;这个属性。&lt;/p&gt;
&lt;p&gt;所以Slot其实就是一个VNode数组，我们可以把这个数组作为&lt;code&gt;prop&lt;/code&gt;传入子节点进行渲染。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;&lt;/code&gt;这种语法会把vnode作为一个对象去序列化，这不是我们所期望的。所以我们需要用&lt;code&gt;v-bind&lt;/code&gt;去传递VNodes的引用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;想要渲染slot，可以使用&lt;code&gt;render function&lt;/code&gt;。之前讲过，slot其实就是VNode的children，所以我们在&lt;code&gt;render function&lt;/code&gt;中&lt;code&gt;createElement&lt;/code&gt;的时候把slot的引用作为children传入就可以了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;render(createElement) {
        return createElement(&amp;#39;div&amp;#39;, this.content)
    }
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;在组件初始化时给this.$slots赋值，然后在模板中使用slot渲染或许也是一种办法，但不一定行的通，也比较hacky。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但我们发现这样不能达到目的。VNode是Vue中对一个DOM节点的内部表示，VNode是有状态的，一个VNode同时只能渲染出一个DOM节点实例。也就是说一个VNode在渲染之后不能再次渲染，除非先把这个VNode从文档中移除，然后才可以再次渲染。&lt;/p&gt;
&lt;p&gt;所以，因为我们的表格中的VNodes是会被每一个row复用的，现在这种用法只能渲染第一行的slot内容。&lt;/p&gt;
&lt;p&gt;解决方案就是，用一个&lt;code&gt;deepClone&lt;/code&gt;函数clone VNode，在每次渲染时初始化新的VNodes实例。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;render(createElement) {
        return createElement(&amp;#39;div&amp;#39;, deepClone(this.content, createElement))
    }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;scopedSlots方案&quot;&gt;&lt;a href=&quot;#scopedSlots方案&quot; class=&quot;headerlink&quot; title=&quot;scopedSlots方案&quot;&gt;&lt;/a&gt;scopedSlots方案&lt;/h3&gt;&lt;p&gt;这样似乎就可以解决问题了，但我们发现Table的自定义内容常常是一个按钮这样的可以交互的组件，会有事件绑定，如果我们要在子组件中给slot动态传入属性，这是办不到的。&lt;/p&gt;
&lt;p&gt;所以slot就不能满足我们的需求了，更好的解决方案就是scopedSlots。&lt;/p&gt;
&lt;p&gt;要了解什么是scopedSlots，我们首先将scopedSlots的模板：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;template scoped=&amp;quot;prop&amp;quot;&amp;gt;
  &amp;lt;div&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;进行编译，结果是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function anonymous() {
  with(this){return _c(&amp;#39;div&amp;#39;,{scopedSlots:_u([{key:&amp;quot;default&amp;quot;,fn:function(prop){return [_c(&amp;#39;div&amp;#39;)]}}])})}
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这种形式是我们之前没有遇到过的，scopedSlots被编译后，生成了一个函数，而且scopedSlot是被存放在VNode的&lt;code&gt;data&lt;/code&gt;属性中，而不是在&lt;code&gt;children&lt;/code&gt;中。&lt;/p&gt;
&lt;p&gt;仔细观察这个函数，这个函数接收一个参数，然后返回一个VNode，这个VNode的属性是从这个参数中获取的。那scopedSlots的原理就很清楚了，&lt;strong&gt;scopedSlots就是一个lazy evaluation的函数，在需要渲染的时候，接收scope对象，然后渲染。这样就可以达到一个类似动态作用域的效果&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;既然scopedSlots是一个函数，我们在render function里面只要调用这个函数，并且传入对应的scope对象作为参数就可以了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;render(createElement) {
        const prop = {
            index: this.id
        }
        return createElement(&amp;#39;div&amp;#39;, [
            this.content.call(this, prop)
        ])
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这种形式顺便解决了之前slot无法重复利用VNode的问题，&lt;strong&gt;因为scopedSlots函数每次返回的都是一个新的VNode节点&lt;/strong&gt;。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在开发MUI的&lt;a href=&quot;https://github.com/Muxi-Studio/MUI/tree/dev/src/components/table&quot;&gt;Table组件&lt;/a&gt;时，我们遇到了一个问题。用户在顶层组件中嵌套的内容，需要被保存到组件的数据中，并且在表格内部渲染出来。&lt;/p&gt;
&lt;p&gt;通常，Vue内嵌内容是使用slot进行渲染的。在父组件的模板中，在子组件的标签中嵌入模板，然后在子组件的内部，使用&lt;code&gt;&amp;lt;slot/&amp;gt;&lt;/code&gt;标签进行渲染。但现在我们的需求是非父子组件的slot渲染，这就要求我们换一种思路去保存和调用slot。&lt;/p&gt;
&lt;p&gt;要理解以下的内容，&lt;strong&gt;请确保你阅读了&lt;a href=&quot;https://vuejs.org/v2/guide/render-function.html&quot;&gt;Render Functions &amp;amp; JSX&lt;/a&gt;，理解了Vue的VNode、render function、模板等概念以及这些概念之间的关系&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>简单的前端网络层Service封装</title>
    <link href="http://yoursite.com/2017/08/16/fe-model-service/"/>
    <id>http://yoursite.com/2017/08/16/fe-model-service/</id>
    <published>2017-08-16T06:01:31.000Z</published>
    <updated>2017-09-06T07:42:12.000Z</updated>
    
    <content type="html">&lt;p&gt;我们编写前端组件时，常常需要拉取数据。最原始的办法就是在组件中调用网络库去请求数据。但这样有一些问题：发送请求的一些代码需要&lt;strong&gt;重复的编写&lt;/strong&gt;。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;比如fetch的&lt;code&gt;json()&lt;/code&gt;方法，拿到返回数据之后进行错误处理的代码。一个典型的使用场景是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fetch(&amp;#39;/api/v2.0&amp;#39; + this.Url + &amp;#39;/?page=&amp;#39; + this.page_num)
  .then(res =&amp;gt; {
    return res.json()
  })
  .then(res =&amp;gt; {
    if (res.code === 200) {
      this.items = res.blogs
      this.pages_count = res.pages_count
      this.page_num = res.page
      this.blog_num = res.blog_num
    }else {
      util.message(&amp;quot;Error:&amp;quot;, res.message)
    }
  })
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;而且在发送请求这个操作中，带有请求的URL等等和组件业务逻辑无关系不大的数据，我们希望可以集中管理这些请求的路由，并且集中处理错误。&lt;/p&gt;
&lt;p&gt;下面就介绍一种最简单的前端网络层封装，我将其称为Service。&lt;/p&gt;
&lt;h3 id=&quot;简单的Fetch封装&quot;&gt;&lt;a href=&quot;#简单的Fetch封装&quot; class=&quot;headerlink&quot; title=&quot;简单的Fetch封装&quot;&gt;&lt;/a&gt;简单的Fetch封装&lt;/h3&gt;&lt;p&gt;为了避免在每次调用fetch时都要设置各种header和参数，我们可以对fetch做一个简单的封装：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function Fetch(url, opt = {}) { 

 // 设置请求方法
 opt.method = opt.method || &amp;#39;GET&amp;#39;;

 // 处理要发送的数据
 if (opt.data) {
    if (/GET/i.test(opt.method)) {
      url = `${url}&amp;amp;${obj2query(opt.data)}`;
    } else {
      opt.headers = {
        &amp;#39;Accept&amp;#39;: &amp;#39;application/json&amp;#39;,
        &amp;#39;Content-Type&amp;#39;: &amp;#39;application/json&amp;#39;,
      };
      opt.body = JSON.stringify(opt.data);
    }
  }

  return fetch(url, opt)
    .then(response =&amp;gt; {  
      return response.json();
    })
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用示例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Fetch(&amp;#39;/api/dash/message/list&amp;#39;, {
   method: &amp;#39;GET&amp;#39;,
   data
})
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面演示的封装只处理了json格式的body和URL参数。在平时的开发中，我们会遇到更复杂的情况，比如需要特殊的header，或者是需要上传文件等等。我们可以通过给&lt;code&gt;Fetch&lt;/code&gt;函数传入不同的&lt;code&gt;opt.type&lt;/code&gt;来达到差异化的处理。有同学会说，在这个函数里根据不同的type写死业务逻辑，是不是不够解耦？其实不是，&lt;code&gt;Fetch&lt;/code&gt;在这里已经是一个业务逻辑的封装了。&lt;/p&gt;
&lt;h3 id=&quot;错误处理&quot;&gt;&lt;a href=&quot;#错误处理&quot; class=&quot;headerlink&quot; title=&quot;错误处理&quot;&gt;&lt;/a&gt;错误处理&lt;/h3&gt;&lt;p&gt;API请求的错误处理是一个很重要的话题，我们希望在服务端返回错误代码时，前端应用可以优雅的提示这个错误，而不是让应用直接报错。换句话说，我们希望catch这个错误，并且进行处理。&lt;/p&gt;
&lt;p&gt;这个错误处理的逻辑如果写在每个&lt;code&gt;Fetch&lt;/code&gt;请求返回的Promise后面，无疑是不现实的。因为这样会造成大量代码的重复。所以进行错误处理的最佳场所就是刚才我们封装的&lt;code&gt;Fetch&lt;/code&gt;函数了。&lt;/p&gt;
&lt;p&gt;我们在拿到&lt;code&gt;response&lt;/code&gt;之后先进行判断，然后再返回结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Fetch的json返回时，对状态码进行判断，做不同的处理。
// 比如在服务端错误时使用alert或者notification组件进行全局提示。
return response.json().then((json) =&amp;gt; { 
  switch (json.code) {
    case 200:
      return json.result;
    case 502:
      util.message(json.message, &amp;#39;err&amp;#39;);
      throw json.message;
  }
}）
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Service层封装&quot;&gt;&lt;a href=&quot;#Service层封装&quot; class=&quot;headerlink&quot; title=&quot;Service层封装&quot;&gt;&lt;/a&gt;Service层封装&lt;/h3&gt;&lt;p&gt;&lt;code&gt;Fetch&lt;/code&gt;其实还是一个比较底层的封装，Service才是前端组件之间调用的逻辑。这个Service类似传统MVC架构中的Model。提供接口并返回数据。一个Service是一组相关业务逻辑接口的集合。&lt;/p&gt;
&lt;p&gt;比如一个新闻应用，那首页的feed流是一个Service。单篇文章相关的接口可以放到一个Service。用户相关的接口可以放到一个Serivce。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let service = {
  getNews(nid) {
        return fetch(`/api/news/`, {
            method: &amp;#39;GET&amp;#39;,
            data: {
                id: nid,
            }
        });
  },

  getNewsList() {
        return fetch(`/api/news/all/`, {
            method: &amp;#39;GET&amp;#39;
        });
  },

  getComment( nid ) {
        return fetch(`/api/news/${nid}/comment/`, {
            method: &amp;#39;GET&amp;#39;
        })
    },

  sendComment( data ) {
      return fetch(`/api/news/${data.nid}/comment/`, {
          method: &amp;#39;POST&amp;#39;,
          data: data
      })
  },
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在组件代码中调用Service（如果应用引入了单独的Model层，那就可以在Model层中调用Service）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import NewsService from &amp;#39;../services/news&amp;#39;

module.export = {
  mounted() {
    NewsService.getNews(this.id)
      .then( (result) =&amp;gt; {
        this.news = result;
      })
  }
}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;我们编写前端组件时，常常需要拉取数据。最原始的办法就是在组件中调用网络库去请求数据。但这样有一些问题：发送请求的一些代码需要&lt;strong&gt;重复的编写&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>现代前端MVVM组件开发的基本理论</title>
    <link href="http://yoursite.com/2017/08/16/i-have-a-theory/"/>
    <id>http://yoursite.com/2017/08/16/i-have-a-theory/</id>
    <published>2017-08-16T01:54:53.000Z</published>
    <updated>2017-09-11T13:09:08.000Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;此文在写作中。这篇文章意在整理自己目前对MVVM组件开发的理解。在写作过程中我发现，我自以为已经形成了对组件开发的一套理论，但其实这套理论还有很多不完善的地方。最近又翻到了波神分享-&lt;em&gt;漫谈Web前端的『组件化』&lt;/em&gt;的&lt;a href=&quot;http://leeluolee.github.io/fequan-netease/#/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;PPT&lt;/a&gt;，深感要形成理论，还是需要数年的积累才行。所以这篇文章就作为我阶段性的成果，不具有太大的参考价值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;如果要给前端开发下一个定义，那就是在浏览器环境下面向对象的GUI客户端程序开发。&lt;/p&gt;
&lt;p&gt;既然是基于面向对象的，那就要有类和对象。在Web前端开发中，最基本的类就是组件的基类（比如Vue和React的构造函数），所有的组件都是基类的一个实例。基类有属性和方法，同时还有一些生命周期钩子函数（其实就是基类上定义的一些方法，会在基类初始化的特定时刻被调用，并且允许实例重载这个方法）。&lt;/p&gt;
&lt;p&gt;既然是GUI客户端程序开发，那Web开发中自然有着MVC之类的分层。MVC、MVP、MVVM都是经典的GUI客户端程序的设计模式&lt;a href=&quot;https://github.com/livoras/blog/issues/11&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;[1]&lt;/a&gt;。目前Web开发中最流行的架构就是MVVM，MVVM已经成为了Web前端开发的一个事实标准。&lt;/p&gt;
&lt;p&gt;谈到事实标准，客户端的开发，比如Android、iOS和Windows，都需要使用系统自带的原生UI组件为基础，配合相关的库，进行开发。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcgy1fj9wd4ul2mj21kw17n4ch.jpg&quot; alt=&quot;iOS丰富的组件&quot;&gt;&lt;br&gt;&lt;em&gt;iOS丰富的原生组件&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在GUI开发领域，&lt;strong&gt;组件&lt;/strong&gt;是一种独立的、可复用的交互元素的封装。&lt;/p&gt;
&lt;p&gt;Web开发最大的特点就是，因为历史原因，Web前端当初是作为展示文档的一种渠道来设计的，所以Web前端只有非常少数的几个原生组件，比如表单组件，可以使用。其他的组件都是需要开发者自行封装的。历史上出现过基于jQuery和Backbone等等框架/库的组件。这些组件在当时起到了很重要的作用。在Web标准大幅发展的今天，Web平台（浏览器）有没有提供标准的组件API呢？&lt;/p&gt;
&lt;p&gt;答案是肯定的。目前Web前端组件的官方标准就是&lt;strong&gt;Web Components&lt;/strong&gt;。Web Components标准由Custom Elements、HTML Templates、Shadow DOM和HTML Imports四部分组成。Web Components解决了&lt;strong&gt;组件的封装、组合以及复用&lt;/strong&gt;问题。&lt;/p&gt;
&lt;p&gt;但在组件的逻辑编写上，随着Web应用越来越复杂，jQuery为代表的命令式编程范式已经不能满足开发的需要。Knockout、ember、angular等MVVM框架出现后，使得声明式的编程范式成为可能。这些框架也渐渐成为了前端开发中的主流。&lt;/p&gt;
&lt;p&gt;Web Components解决了组件的封装和复用问题，但Web Components的逻辑依然是命令式的。而且Web Components目前的浏览器兼容性还不太好，不能直接用于生产。&lt;/p&gt;
&lt;p&gt;当前主流的Web前端框架/库Vue、React和Angular在某种程度上都提供了&lt;strong&gt;组件封装&lt;/strong&gt;和&lt;strong&gt;声明式编程范式&lt;/strong&gt;两个重要特性。这些框架都有自己的组件封装标准，都遵循数据驱动的范式。值得注意的是Web Components标准在某种程度上对这些框架的组件封装和组合方式有一定的影响，特别是Vuejs，在很多地方参考了Web Components，并实现了Web Components中的slot特性。在未来Web Components标准真正落地时，这些框架都可以和Web Components实现无缝的整合。&lt;/p&gt;
&lt;p&gt;因此我们可以说，实现了声明式编程范式和组件封装、复用和组合的现代MVVM组件框架，就是目前Web前端开发的&lt;strong&gt;事实标准&lt;/strong&gt;。并且这个标准在未来很长一段时间内都会持续保持稳定。&lt;/p&gt;
&lt;p&gt;Web前端没有一套官方的原生UI组件（这里指的是官方提供的组件实现，比如日期选择组件、ListView组件等待，不是指Web Components这样的底层标准），以后也不会有，因为Web是一个开放的平台，不像其他的客户端程序的操作系统由一家公司所控制。但目前在我们的开发中，已经可以总结出一套成熟的组件。比如&lt;a href=&quot;https://ant.design/docs/react/introduce&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ant Design&lt;/a&gt;中的众多组件。这些组件都是基于MVVM前端框架开发的。&lt;/p&gt;
&lt;p&gt;前端这么多年的发展，到现在已经进入了一个比较成熟的时期了。有了成熟的模块标准和包管理系统，也有了通用的组件模型。所以假设Web也有一个官方的组件标准，那融合了Web Components和声明式编程的MVVM组件已经非常接近了。一个技术想要被称为工业级，只有形成统一的标准。Web前端的组件，虽然不会有统一的标准，但如果在MVVM组件作为事实的标准的前提下去开发，会减少很多不必要的麻烦。&lt;/p&gt;
&lt;p&gt;写这篇博客，也是因为想总结一下目前这个时期的Web开发中的一些事实标准。相比于客户端，前端的门槛其实要更高一些，因为我们要使用堪称刀耕火种的方式去应对日益复杂的业务场景。但在当下，对于刚刚进入前端领域的同学来说，可以把一些范式作为前端的标准来学习，形成对现代前端开发的理解。在现在这个时间点进入前端行业的同学，已经没有必要再了解jQuery时代的开发范式了。&lt;/p&gt;
&lt;p&gt;本文的题目是&lt;em&gt;现代前端MVVM组件开发的基本理论&lt;/em&gt;，下面就分别介绍MVVM组件开发中几个关键的理论。&lt;/p&gt;
&lt;h2 id=&quot;MVVM&quot;&gt;&lt;a href=&quot;#MVVM&quot; class=&quot;headerlink&quot; title=&quot;MVVM&quot;&gt;&lt;/a&gt;MVVM&lt;/h2&gt;&lt;p&gt;Web Components并没有规定开发者应该如何去给一个组件的逻辑分层。一个组件里可能包含数据、表现（UI）和业务逻辑。在编写组件时，这些部分都需要被严格的解耦，并且规定各个部分之间的通信方式。&lt;/p&gt;
&lt;p&gt;MVVM下，组件由如下部分构成：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;组件 = 视图 + 数据 + 业务逻辑&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;MVVM分为View、Model和ViewModel三个部分。分别对应视图、数据和业务逻辑三部分。拿Vue举例，Vue的模板和样式属于View层。Vue的组件实例属于ViewModel，Vue的Model层，在没有引入全局Model层的情况下，就是Vue的data属性中的内容。如果开发者引入了全局的Model层，比如Redux或者MobX，那Model就是一个和Vue组件脱离的对象。&lt;/p&gt;
&lt;p&gt;MVVM中，各个部分的关系是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fjfvsl1r13j20es08074q.jpg&quot; alt=&quot;mvvm&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;组件的生命周期&quot;&gt;&lt;a href=&quot;#组件的生命周期&quot; class=&quot;headerlink&quot; title=&quot;组件的生命周期&quot;&gt;&lt;/a&gt;组件的生命周期&lt;/h2&gt;&lt;p&gt;客户端的组件会有生命周期函数，比如iOS的ViewController就有&lt;code&gt;viewDidLoad&lt;/code&gt;、&lt;code&gt;viewWillDisappear&lt;/code&gt;等等声明周期钩子。前端组件和客户端的的组件一样，都有着生命周期。一个前端组件在应用中，会首先初始化（创建一个新的组件实例），接着加载数据并首次渲染，然后进入一个响应数据变化并重新渲染的循环，最后如果这个组件要从应用中移除，那么组件就会被销毁。&lt;/p&gt;
&lt;p&gt;组件在各个生命周期阶段会调用一些钩子函数，开发者如果想在组件特定的时刻执行一些逻辑，就可以在组件中实现这些钩子函数。&lt;/p&gt;
&lt;p&gt;接下去总结一下MVVM通常都会有的生命周期。&lt;br&gt;首先，组件进入&lt;strong&gt;初始化阶段&lt;/strong&gt;，在这个阶段主要就是创建组件实例，并调用init钩子函数。&lt;/p&gt;
&lt;p&gt;然后进入&lt;strong&gt;初始化数据并首次渲染阶段&lt;/strong&gt;，这个阶段，如果是Push类型的框架（关于Push和Pull在后文会提到），比如Vue，就需要对数据进行处理（对data进行递归遍历，修改getter和setter，然后调用Render Function进行依赖搜集），然后首次渲染（Vriual DOM patch）。如果是Pull类型的框架，Angular和Regular需要遍历View的AST，然后生成Watcher列表，然后进行首次的脏检查，随后View就被渲染到页面。React就启动一次渲染流程，包括调用Render Function和一次patch。最终达到的效果就是组件首次渲染到页面中。一般在此时也会有一个钩子函数被调用，开发者可以在此时执行一些需要确保UI已经渲染作为前提的逻辑。&lt;/p&gt;
&lt;p&gt;接着进入&lt;strong&gt;响应数据变化并渲染阶段&lt;/strong&gt;，这个阶段中，组件已经首次渲染了，接下来如果数据发生变化，那组件就会重新渲染，保持组件的UI和组件的状态保持同步。&lt;/p&gt;
&lt;p&gt;如果组件的销毁方法被调用，组件就进入&lt;strong&gt;销毁阶段&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;之所以要先说明这几个阶段，是因为理解组件的生命周期对于理解后文讲的数据侦测、渲染、模板等有着密不可分的关系。&lt;/p&gt;
&lt;h2 id=&quot;组合&quot;&gt;&lt;a href=&quot;#组合&quot; class=&quot;headerlink&quot; title=&quot;组合&quot;&gt;&lt;/a&gt;组合&lt;/h2&gt;&lt;p&gt;Composition over inheritence&lt;a href=&quot;&quot;&gt;[x]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在UI的开发中我们常常会复用一些代码。&lt;/p&gt;
&lt;h4 id=&quot;内嵌组件&quot;&gt;&lt;a href=&quot;#内嵌组件&quot; class=&quot;headerlink&quot; title=&quot;内嵌组件&quot;&gt;&lt;/a&gt;内嵌组件&lt;/h4&gt;&lt;h4 id=&quot;Mixin&quot;&gt;&lt;a href=&quot;#Mixin&quot; class=&quot;headerlink&quot; title=&quot;Mixin&quot;&gt;&lt;/a&gt;Mixin&lt;/h4&gt;&lt;h2 id=&quot;数据驱动&quot;&gt;&lt;a href=&quot;#数据驱动&quot; class=&quot;headerlink&quot; title=&quot;数据驱动&quot;&gt;&lt;/a&gt;数据驱动&lt;/h2&gt;&lt;p&gt;这里有必要解释一下这套MVVM中，各模块之间数据的流动。View不能直接通知Model更新，而是通知ViewModel用户的交互，由ViewModel来修改Model中的数据。Model的数据变化之后，会直接触发View的更新。&lt;/p&gt;
&lt;p&gt;此处应该有图。&lt;/p&gt;
&lt;p&gt;最关键的一点就是，&lt;strong&gt;ViewModel不应该直接对View进行操作，而是应该通过修改Model中的数据，让Model驱动View进行更新&lt;/strong&gt;。所以我们不提倡在ViewModel中进行DOM操作，因为DOM操作其实就是直接更新View层。并不是DOM操作有多低效。主要是因为既然我们采用了MVVM的范式，就应该去遵守这个范式，才能发挥出这个范式的威力。&lt;/p&gt;
&lt;h2 id=&quot;数据变化侦测机制：Pull-vs-Push&quot;&gt;&lt;a href=&quot;#数据变化侦测机制：Pull-vs-Push&quot; class=&quot;headerlink&quot; title=&quot;数据变化侦测机制：Pull vs Push&quot;&gt;&lt;/a&gt;数据变化侦测机制：Pull vs Push&lt;/h2&gt;&lt;p&gt;这部分的内容我个人认为是非常精辟的。用Pull和Push两种方式准确的分类了现在主流的几个前端框架使用的数据变化侦测机制。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这部分的内容我第一次是听波神和我讲的，后来看了尤雨溪dotJS的演讲，也有类似的内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;Pull类：脏检查&quot;&gt;&lt;a href=&quot;#Pull类：脏检查&quot; class=&quot;headerlink&quot; title=&quot;Pull类：脏检查&quot;&gt;&lt;/a&gt;Pull类：脏检查&lt;/h4&gt;&lt;p&gt;Angular和Regular的数据变化侦测机制属于是数据层的脏检查，React则是View层脏检查。&lt;/p&gt;
&lt;h4 id=&quot;Push类：依赖搜集&quot;&gt;&lt;a href=&quot;#Push类：依赖搜集&quot; class=&quot;headerlink&quot; title=&quot;Push类：依赖搜集&quot;&gt;&lt;/a&gt;Push类：依赖搜集&lt;/h4&gt;&lt;p&gt;Vue的Model记录了各个数据和不同部分View的对应关系。在ViewModel修改Model之后，Model会自动通知需要更新的View进行更新。&lt;/p&gt;
&lt;h4 id=&quot;Pull和Push的理解&quot;&gt;&lt;a href=&quot;#Pull和Push的理解&quot; class=&quot;headerlink&quot; title=&quot;Pull和Push的理解&quot;&gt;&lt;/a&gt;Pull和Push的理解&lt;/h4&gt;&lt;p&gt;至于Pull和Push的形象理解，Pull可以理解为从需要更新的整个组件树中&lt;strong&gt;拉取&lt;/strong&gt;所有的状态，和旧状态进行比对，然后去更新。Push可以理解为，框架已经知道了变化的数据，然后将更新的信号&lt;strong&gt;推送&lt;/strong&gt;给需要更新的组件。&lt;/p&gt;
&lt;p&gt;也不用太纠结Pull和Push的字面意思，总之数据变化侦测机制的区别就在于脏检查机制不知道哪些数据变了，所以需要进行数据的对比。而依赖搜集机制在数据变化那一刻就知道哪些数据变化了，也知道哪些组件依赖这些数据。&lt;/p&gt;
&lt;h3 id=&quot;模板技术&quot;&gt;&lt;a href=&quot;#模板技术&quot; class=&quot;headerlink&quot; title=&quot;模板技术&quot;&gt;&lt;/a&gt;模板技术&lt;/h3&gt;&lt;p&gt;波神对模板技术有一篇很全面的总结&lt;a href=&quot;http://leeluolee.github.io/2014/10/10/template-engine/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;[x]&lt;/a&gt;。模板的表达能力来看，可以分为基于DSL（包括HTML）的，或者基于JavaScript的。Regular的模板是自己的DSL。Vue和React最终都是使用Render Function来生成View的AST的。也就是说Vue和React可以让开发者直接编写View结构的AST。Vue在Render Function之外提供了基于HTML的模板。这个模板的表达能力和传统的DOM based的模板是一样的。可以说是Render Function能力的一个子集。Vue让开发者自行选择使用何种技术。React的JSX因为是直接写在Render Function中的，所以很难称为是模板，只能说是一种语法糖。React只允许开发者直接编写Render Function。&lt;/p&gt;
&lt;h3 id=&quot;渲染&quot;&gt;&lt;a href=&quot;#渲染&quot; class=&quot;headerlink&quot; title=&quot;渲染&quot;&gt;&lt;/a&gt;渲染&lt;/h3&gt;&lt;p&gt;在Web开发中，UI一般是用DOM或者Canvas这样的底层机制来实现的。组件的View层，实际上就是一个树结构，里面的节点是对View中元素的抽象表示。一个节点可能代表一个DOM节点，也可能代表一个组件的根节点。如果组件的View是由自定义的DSL表示的，那可能还会有其他带有语义的元素，比如if和list等等流程控制节点。&lt;/p&gt;
&lt;p&gt;现在最流行的抽象方式是将View的结构表示为Virtual DOM树。Virtual DOM是对DOM节点的轻量级抽象表示。Render Function中可能会有一些逻辑，Virtual DOM将组件的状态传入Render Function后得到的一个树结构。所以我们就得到了那个著名的等式：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;UI = f(state)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这里的UI就可以类比为Virtual DOM，函数f就是Render Function。&lt;/p&gt;
&lt;h3 id=&quot;组件通信方式&quot;&gt;&lt;a href=&quot;#组件通信方式&quot; class=&quot;headerlink&quot; title=&quot;组件通信方式&quot;&gt;&lt;/a&gt;组件通信方式&lt;/h3&gt;&lt;h4 id=&quot;父子组件通信&quot;&gt;&lt;a href=&quot;#父子组件通信&quot; class=&quot;headerlink&quot; title=&quot;父子组件通信&quot;&gt;&lt;/a&gt;父子组件通信&lt;/h4&gt;&lt;p&gt;父组件到子组件 props&lt;br&gt;子组件到父组件，emit event或者父组件传callback到子组件。&lt;/p&gt;
&lt;h4 id=&quot;非相邻组件通信&quot;&gt;&lt;a href=&quot;#非相邻组件通信&quot; class=&quot;headerlink&quot; title=&quot;非相邻组件通信&quot;&gt;&lt;/a&gt;非相邻组件通信&lt;/h4&gt;&lt;p&gt;使用一个event bus。&lt;/p&gt;
&lt;h2 id=&quot;数据层解决方案&quot;&gt;&lt;a href=&quot;#数据层解决方案&quot; class=&quot;headerlink&quot; title=&quot;数据层解决方案&quot;&gt;&lt;/a&gt;数据层解决方案&lt;/h2&gt;&lt;h2 id=&quot;路由&quot;&gt;&lt;a href=&quot;#路由&quot; class=&quot;headerlink&quot; title=&quot;路由&quot;&gt;&lt;/a&gt;路由&lt;/h2&gt;&lt;p&gt;// todo &lt;/p&gt;
&lt;h2 id=&quot;提问时间&quot;&gt;&lt;a href=&quot;#提问时间&quot; class=&quot;headerlink&quot; title=&quot;提问时间&quot;&gt;&lt;/a&gt;提问时间&lt;/h2&gt;&lt;p&gt;在这篇文章中，我主要是讲了现代前端MVVM组件开发中一些重要的话题，并且对于每个话题我都对当前几个主流框架在这些方面的实现做了分类。我认为，这些可以说是目前前端开发的一个事实标准了。有了这方面的系统的知识，我们就可以回答下面的问题。我个人觉得，问一些对比类型的问题，更可以看出一个人是否有思考过自己使用的技术方案。对于市场上各个技术方案的对比和总结，就是得出一个技术体系的方法。&lt;/p&gt;
&lt;p&gt;Q：Web Components解决了什么问题？和现代的前端框架相比有什么不同？&lt;/p&gt;
&lt;p&gt;A:&lt;/p&gt;
&lt;p&gt;Q：如何实现一个基于脏检查的数据绑定方案？&lt;/p&gt;
&lt;p&gt;A：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24990192&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;双向绑定的简单实现——基于“脏检测”
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Q：如何实现一个Virtul DOM算法？&lt;/p&gt;
&lt;p&gt;A：&lt;a href=&quot;https://github.com/livoras/blog/issues/13&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;深度剖析：如何实现一个 Virtual DOM 算法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Q：如何实现一个基于依赖搜集的数据绑定方案？&lt;/p&gt;
&lt;p&gt;A： &lt;a href=&quot;https://zhuanlan.zhihu.com/p/24475845&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;250行实现一个简单的MVVM&lt;/a&gt;和&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25003235&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;数据动态绑定的简单实现——基于ES5对象的getter/setter机制&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Q：Vue的模板有哪些局限？如何解决？&lt;/p&gt;
&lt;p&gt;A：HTML模板的表达能力不足，可以手写Render Function&lt;a href=&quot;&quot;&gt;[x]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Q：React-Redux这样的connector具体实现了什么？&lt;/p&gt;
&lt;p&gt;A：订阅store变化，注册回调，回调中调用mapState函数。&lt;/p&gt;
&lt;p&gt;Q：如何实现两个不相邻组件的通信？&lt;/p&gt;
&lt;p&gt;A：&lt;/p&gt;
&lt;p&gt;Q：JSX是模板技术吗？它和传统模板技术的区别是什么？&lt;/p&gt;
&lt;p&gt;A：&lt;/p&gt;
&lt;p&gt;Q：Vue和React的区别在什么地方？&lt;/p&gt;
&lt;p&gt;A：&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;此文在写作中。这篇文章意在整理自己目前对MVVM组件开发的理解。在写作过程中我发现，我自以为已经形成了对组件开发的一套理论，但其实这套理论还有很多不完善的地方。最近又翻到了波神分享-&lt;em&gt;漫谈Web前端的『组件化』&lt;/em&gt;的&lt;a href=&quot;http://leeluolee.github.io/fequan-netease/#/&quot;&gt;PPT&lt;/a&gt;，深感要形成理论，还是需要数年的积累才行。所以这篇文章就作为我阶段性的成果，不具有太大的参考价值。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>聊聊UI组件设计-Modal</title>
    <link href="http://yoursite.com/2017/08/14/component-talk-modal/"/>
    <id>http://yoursite.com/2017/08/14/component-talk-modal/</id>
    <published>2017-08-14T11:23:20.000Z</published>
    <updated>2017-08-30T14:46:24.000Z</updated>
    
    <content type="html">&lt;p&gt;在人机交互中，有一个概念叫做&lt;a href=&quot;https://en.wikipedia.org/wiki/Modality_(human–computer_interaction&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Modality&lt;/a&gt;)，中文叫模态。模态，顾名思义，就是模拟。计算机可以模拟人通过各种通道接收的信息，比如视觉、听觉、触觉等等通道。视觉就通过显示器输出，听觉通过音响、触觉通过振动。同理，人也可以模拟计算机接收到的电信号，人可以通过键盘、触摸板等待设备来模拟0/1信号。&lt;/p&gt;
&lt;p&gt;模态可以是但通道的，也可以是多通道的（比如玩游戏时有声音、视觉、和振动反馈）。今天我们要将的计算机软件中的Modal组件，就是计算机向人建立的单通道信息交互方式。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;Modal在交互设计中的作用&quot;&gt;&lt;a href=&quot;#Modal在交互设计中的作用&quot; class=&quot;headerlink&quot; title=&quot;Modal在交互设计中的作用&quot;&gt;&lt;/a&gt;Modal在交互设计中的作用&lt;/h3&gt;&lt;p&gt;具体到产品的交互设计中（交互设计和人机交互不是一回事，准确的说两者有交叉），Modal这个组件是很常用的，那么Modal在交互上的意义是什么呢？&lt;/p&gt;
&lt;p&gt;Modal的弹出，其实就是计算机和人之间建立了一个信息传递的通道，这个通道是独占的，在关闭这个通道之前，不能进行其他的交互。计算机程序建立这个通道，为的是传递一些信息。但传递信息有很多的方式，为什么要使用独占通道的Modal来传达呢？&lt;/p&gt;
&lt;p&gt;因为Modal传递的信息，是为了让用户&lt;strong&gt;提供关键信息&lt;/strong&gt;，这个信息的回复（Modal的输入）可以是是一个true or false的选择，也可以是较为复杂的数据结构。Modal是一个浮层，所以用户在Modal弹出时，不能再点击应用的其他部分。用户必须要做出决定，是输入信息，或者取消（关闭Modal）。因此，Modal会中断用户当前的工作流。&lt;/p&gt;
&lt;h3 id=&quot;实现：Modal组件的特点&quot;&gt;&lt;a href=&quot;#实现：Modal组件的特点&quot; class=&quot;headerlink&quot; title=&quot;实现：Modal组件的特点&quot;&gt;&lt;/a&gt;实现：Modal组件的特点&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;全局一般只能显示一个Modal，因为Modal显示时会需要用户做出决定后再消失（点击取消也是一种决定，即为对操作的否定）。&lt;/li&gt;
&lt;li&gt;Modal一般提供确定和取消两个按钮。&lt;/li&gt;
&lt;li&gt;Modal中标题和底部按钮直接的内容，一般是可以自由组合的。一种特殊情况是Modal中组合了input，那这种Modal类型被称为prompt。&lt;/li&gt;
&lt;li&gt;Modal如果涉及异步的操作，则需要有一个confirm loading状态。这个状态下用户不能再次点击confirm。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里推荐一篇很好的总结文章&lt;a href=&quot;http://www.ui.cn/detail/224467.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;覆盖层设计(上)-对话框&amp;amp;浮层&lt;/a&gt;来自网易UEDC。系统的总结了交互设计中浮层相关的设计。&lt;/p&gt;
&lt;h3 id=&quot;不同UI库的Modal设计&quot;&gt;&lt;a href=&quot;#不同UI库的Modal设计&quot; class=&quot;headerlink&quot; title=&quot;不同UI库的Modal设计&quot;&gt;&lt;/a&gt;不同UI库的Modal设计&lt;/h3&gt;&lt;p&gt;下面讲讲正题，Modal作为一个Web前端组件的设计方式。&lt;/p&gt;
&lt;p&gt;根据Modal在前端代码中的调用方式，可以分为声明式和命令式两种。Modal的声明式使用是指在前端模板中声明Modal。命令式则是在前端代码中调用一个函数，来显式的调用Modal。&lt;/p&gt;
&lt;h4 id=&quot;声明式&quot;&gt;&lt;a href=&quot;#声明式&quot; class=&quot;headerlink&quot; title=&quot;声明式&quot;&gt;&lt;/a&gt;声明式&lt;/h4&gt;&lt;p&gt;Ant Design中的&lt;a href=&quot;https://ant.design/components/modal/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Modal&lt;/a&gt;是典型的声明式组件。Modal被声明在模板中，在父组件初始化之时便存在了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;render() {
    return (
      &amp;lt;div&amp;gt;
        &amp;lt;Modal
          title=&amp;quot;Basic Modal&amp;quot;
          visible={this.state.visible}
          onOk={this.handleOk}
          onCancel={this.handleCancel}
        &amp;gt;
          &amp;lt;p&amp;gt;Some contents...&amp;lt;/p&amp;gt;
          &amp;lt;p&amp;gt;Some contents...&amp;lt;/p&amp;gt;
          &amp;lt;p&amp;gt;Some contents...&amp;lt;/p&amp;gt;
        &amp;lt;/Modal&amp;gt;
      &amp;lt;/div&amp;gt;
    );
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Modal出现时只是visible这个flag被设置为&lt;code&gt;true&lt;/code&gt;。而不是在那个时候初始化Modal组件。要在Modal中组合内嵌内容，只要在模板中的Modal标签中组合内容即可。在用户点击Modal的取消时，只要将visible设为&lt;code&gt;false&lt;/code&gt;。所以这里不涉及Modal的销毁问题。Modal的回收是和父组件一起的。&lt;/p&gt;
&lt;h4 id=&quot;命令式&quot;&gt;&lt;a href=&quot;#命令式&quot; class=&quot;headerlink&quot; title=&quot;命令式&quot;&gt;&lt;/a&gt;命令式&lt;/h4&gt;&lt;p&gt;Ant Design中的Modal组件也提供了几个静态的方法，用于在组件中手动初始化一个Modal，并且提供了&lt;code&gt;destroy&lt;/code&gt;方法来手动销毁。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; const modal = Modal.success({
    title: &amp;#39;This is a notification message&amp;#39;,
    content: &amp;#39;This modal will be destroyed after 1 second&amp;#39;,
 });
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Element UI中的Modal组件的API则是标准的命令式。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;this.$prompt(&amp;#39;请输入邮箱&amp;#39;, &amp;#39;提示&amp;#39;, {
          confirmButtonText: &amp;#39;确定&amp;#39;,
          cancelButtonText: &amp;#39;取消&amp;#39;,
          inputPattern: /[\w!#$%&amp;amp;&amp;#39;*+/=?^_`{|}~-]+(?:\.[\w!#$%&amp;amp;&amp;#39;*+/=?^_`{|}~-]+)*@(?:[\w](?:[\w-]*[\w])?\.)+[\w](?:[\w-]*[\w])?/,
          inputErrorMessage: &amp;#39;邮箱格式不正确&amp;#39;
        }).then(({ value }) =&amp;gt; {
          this.$message({
            type: &amp;#39;success&amp;#39;,
            message: &amp;#39;你的邮箱是: &amp;#39; + value
          });
        }).catch(() =&amp;gt; {
          this.$message({
            type: &amp;#39;info&amp;#39;,
            message: &amp;#39;取消输入&amp;#39;
          });       
        });
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Element UI的Modal API设计很有特色，首先调用创建Modal的方法后返回的是一个Promise。如果用户点击确定，那Promise就resolve。如果用户点击取消，那Promise就reject。我们可以在创建Modal的API调用之后链式的编写逻辑。&lt;/p&gt;
&lt;h4 id=&quot;自定义属性&quot;&gt;&lt;a href=&quot;#自定义属性&quot; class=&quot;headerlink&quot; title=&quot;自定义属性&quot;&gt;&lt;/a&gt;自定义属性&lt;/h4&gt;&lt;p&gt;Modal的属性中比较重要的就是内嵌的内容。在声明式定义的Modal的内嵌内容可以声明式的写在模板中。命令式的Modal则需要将内嵌内容作为初始化的属性传入。相比之下声明式的要更自然一些。&lt;/p&gt;
&lt;p&gt;至于Modal另一组重要的属性，确认回调和取消回调。命令式的API在这方面更自然一些。特别是Element UI的基于Promise的调用。声明式的API则是在模板中声明属性，在View Controller中声明方法。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在人机交互中，有一个概念叫做&lt;a href=&quot;https://en.wikipedia.org/wiki/Modality_(human–computer_interaction&quot;&gt;Modality&lt;/a&gt;)，中文叫模态。模态，顾名思义，就是模拟。计算机可以模拟人通过各种通道接收的信息，比如视觉、听觉、触觉等等通道。视觉就通过显示器输出，听觉通过音响、触觉通过振动。同理，人也可以模拟计算机接收到的电信号，人可以通过键盘、触摸板等待设备来模拟0/1信号。&lt;/p&gt;
&lt;p&gt;模态可以是但通道的，也可以是多通道的（比如玩游戏时有声音、视觉、和振动反馈）。今天我们要将的计算机软件中的Modal组件，就是计算机向人建立的单通道信息交互方式。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Headless Chrome截图服务实战</title>
    <link href="http://yoursite.com/2017/08/03/headlesschrome/"/>
    <id>http://yoursite.com/2017/08/03/headlesschrome/</id>
    <published>2017-08-03T01:26:25.000Z</published>
    <updated>2017-08-03T06:59:21.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;TL-DR&quot;&gt;&lt;a href=&quot;#TL-DR&quot; class=&quot;headerlink&quot; title=&quot;TL;DR&quot;&gt;&lt;/a&gt;TL;DR&lt;/h3&gt;&lt;p&gt;给太长不看同学的内容速览：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Headless是Chrome 59中加入的一种新的运行模式&lt;/li&gt;
&lt;li&gt;Headless Chrome可以替代PhantomJS，并且更加强大&lt;/li&gt;
&lt;li&gt;可以通过Chrome DevTools Protocol这个协议对远程的Chrome浏览器进行调试&lt;/li&gt;
&lt;li&gt;chrome-remote-interface是Nodejs下Chrome DevTools Protocol的封装&lt;/li&gt;
&lt;li&gt;可以使用&lt;code&gt;Emulation.setVisibleSize&lt;/code&gt;对&lt;strong&gt;整个页面&lt;/strong&gt;进行截屏&lt;/li&gt;
&lt;/ul&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;PhantomJS的问题&quot;&gt;&lt;a href=&quot;#PhantomJS的问题&quot; class=&quot;headerlink&quot; title=&quot;PhantomJS的问题&quot;&gt;&lt;/a&gt;PhantomJS的问题&lt;/h3&gt;&lt;p&gt;之前有数报表的导出图片功能是用PhantomJS做的。PhantomJS有两个很大的问题：第一是，它的渲染引擎和JavaScript引擎基于Qt5，版本不是很高，所以渲染的时候会有一些兼容问题，而且JavaScript引擎也相对比较古老（最新的PhantomJS release是2.1版，这个版本基于Qt5.5。Qt5.5使用的Chromium内核版本是40，Chromium现在最新版本是62）。第二，PhantomJS现在已经处于一种维护不多的状态（Github上有1901个open issues）。&lt;/p&gt;
&lt;p&gt;作为一个个人项目，PhantomJS在各种自动化测试以及页面自动化操作中被广泛使用，达到了很高的高度。但因为以上两个缺点，使用PhantomJS将不会是长久之计。&lt;/p&gt;
&lt;h3 id=&quot;Chrome的Headless模式&quot;&gt;&lt;a href=&quot;#Chrome的Headless模式&quot; class=&quot;headerlink&quot; title=&quot;Chrome的Headless模式&quot;&gt;&lt;/a&gt;Chrome的Headless模式&lt;/h3&gt;&lt;p&gt;Headless Chrome其实不是一个全新的工具，而是普通的Chrome浏览器的headless模式。headless就是指Chrome的UI部分是不运行的。&lt;/p&gt;
&lt;p&gt;所以只要你的机器上安装了Chrome 59+，你就可以使用Headless Chrome。相比之前&lt;code&gt;npm install&lt;/code&gt;时经常要从bitbucket下载PhantomJS binary的麻烦事，Headless Chrome要方便不少，毕竟Web开发者一般都安装了Chrome。&lt;/p&gt;
&lt;p&gt;你可以在命令行中用headless模式启动Chrome：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chrome \
  --headless \                   # Runs Chrome in headless mode.
  --disable-gpu \                # Temporarily needed for now.
  --remote-debugging-port=9222 \
  https://www.chromestatus.com   # URL to open. Defaults to about:blank.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们可以直接在Chrome的CLI中进行一些操作，比如截屏：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chrome --headless --disable-gpu --screenshot --window-size=1280,1696 https://www.chromestatus.com/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但一般我们很少会这样直接使用Headless Chrome。对这部分有兴趣的同学可以看&lt;a href=&quot;https://developers.google.com/web/updates/2017/04/headless-chrome&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官方文档&lt;/a&gt;，这里就不多说了。&lt;/p&gt;
&lt;p&gt;Headless Chrome的最大的优点就是，它就是Chrome，所以可以保持Evergreen，也就是持续的更新。并且我们可以在Headless模式使用Chrome带来的所有的现代Web平台的特性。所以Headless Chrome就成为了PhantomJS的完美升级版替代品。&lt;/p&gt;
&lt;h3 id=&quot;强大的Chrome-DevTools-Protocol&quot;&gt;&lt;a href=&quot;#强大的Chrome-DevTools-Protocol&quot; class=&quot;headerlink&quot; title=&quot;强大的Chrome DevTools Protocol&quot;&gt;&lt;/a&gt;强大的Chrome DevTools Protocol&lt;/h3&gt;&lt;p&gt;要在脚本中和Chrome进行交互，需要用Chrome DevTools Protocol这个协议。所以这里首先介绍一下这个协议。&lt;/p&gt;
&lt;p&gt;简单的说，我们可以在启动Chrome的时候开启一个用于远程调试的端口。然后我们可以在浏览器或者其他客户端中和Chrome建立socket连接，并使用Chrome DevTools Protocol进行通信。&lt;/p&gt;
&lt;p&gt;Chrome DevTools Protocol通信的格式是JSON。比如我们想截屏，就可以发一个消息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    id:30,
    method:&amp;quot;Page.captureScreenshot&amp;quot;,
    params: {
        format:&amp;quot;png&amp;quot;,
        quality:100
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;返回的消息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    id:30,
    data:&amp;quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIA...&amp;quot;    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;具体的API可以参考&lt;a href=&quot;https://chromedevtools.github.io/devtools-protocol/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文档&lt;/a&gt;，我们从文档里可以看到，Chrome DevTools Protocol包含的范围非常广。简单的说，我们平时在Chrome DevTool里面可以做到的事情，能获取的数据，我们使用Chrome DevTools Protocol都可以做到。因为Chrome DevTool其实就是基于这个协议进行开发的一个B/S架构的工具。当然这个协议也应该是随着Chrome DevTool的开发，被标准化。现在不仅仅是Chrome，其他浏览器也支持部分Chrome DevTools Protocol。&lt;/p&gt;
&lt;p&gt;我们在Chrome的拓展里也可以调用这一套API。所以Chrome拓展的潜力是很大的。可以通过合理使用Chrome DevTools Protocol获得更接近自带DevTool的debug体验。也可以对内存、DOM、渲染等数据进行二次的分析和利用。&lt;/p&gt;
&lt;h3 id=&quot;Nodejs服务&quot;&gt;&lt;a href=&quot;#Nodejs服务&quot; class=&quot;headerlink&quot; title=&quot;Nodejs服务&quot;&gt;&lt;/a&gt;Nodejs服务&lt;/h3&gt;&lt;p&gt;直接使用Chrome DevTools Protocol还是比较麻烦的。社区已经有了封装好的Nodejs包&lt;a href=&quot;https://github.com/cyrus-and/chrome-remote-interface&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;chrome-remote-interface&lt;/a&gt;可以直接使用。我们可以直接像调用JavaScript API那样来和Chrome进行通信。&lt;/p&gt;
&lt;p&gt;下面就演示一下如何在Node中进行Chrome的截屏：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const CDP = require(&amp;#39;chrome-remote-interface&amp;#39;);
const Koa = require(&amp;#39;koa&amp;#39;);
const app = new Koa();

const viewportWidth = 1440;
const viewportHeight = 900;
const delay = 500;

app.use(async ctx =&amp;gt; {
  ctx.body = await capture(ctx.request.query.url);
});

app.listen(3000);

const capture = function (url) {
  return new Promise((resolve, reject) =&amp;gt; {
    CDP.New().then((target) =&amp;gt; {
      return CDP({ target });
    }).then(async (client) =&amp;gt; {

      const { Page } = client;
      await Page.enable();
      await Page.navigate({ url: url });

      Page.loadEventFired(() =&amp;gt; {
        setTimeout(async () =&amp;gt; {
          const { data } = await Page.captureScreenshot();
          resolve(Buffer.from(data, &amp;#39;base64&amp;#39;));
          const id = client.target.id;
          client.close();
          CDP.Close({ id });
        }, delay);
      });
    }).catch((err) =&amp;gt; {
      console.error(err);
    });
  })
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;chrome-remote-interface将一个socket通信的来回封装成了一个异步的函数调用，返回一个Promise。在Node7.8+的环境，我们可以用async/await来轻松的进行流程控制。这里是具体的&lt;a href=&quot;https://github.com/cyrus-and/chrome-remote-interface/wiki&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Demo&lt;/a&gt;和&lt;a href=&quot;https://github.com/cyrus-and/chrome-remote-interface#api&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;API文档&lt;/a&gt;，基本和Chrome DevTools Protocol里的接口是一一对应的。&lt;/p&gt;
&lt;p&gt;这个服务监听3000端口，在请求中拿到url参数，调用&lt;code&gt;capture&lt;/code&gt;函数截屏。我们这里默认Chrome的调试端口是127.0.0.1:9222。如果需要调整，可以在初始化CDP实例的时候传入参数。&lt;/p&gt;
&lt;p&gt;我们调用&lt;code&gt;CDP.New()&lt;/code&gt;初始化一个新的Tab，等待Page加载完成，打开url，然后等待页面的加载事件触发之后执行回调，在回调里调用截屏API并且获取数据。最后我们关闭这个Tab。整个截图的流程就是这样。&lt;/p&gt;
&lt;h3 id=&quot;Tip：截取整个页面&quot;&gt;&lt;a href=&quot;#Tip：截取整个页面&quot; class=&quot;headerlink&quot; title=&quot;Tip：截取整个页面&quot;&gt;&lt;/a&gt;Tip：截取整个页面&lt;/h3&gt;&lt;p&gt;我遇到的一个很大的问题就是，页面比较长，我希望截取的图片的高度就是页面的高度，也就是说我希望给整个页面截屏。&lt;/p&gt;
&lt;p&gt;一开始我截屏的结果是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fi6ilca424j20ct08y0t3.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这和想象的不一样啊，下面的大半截都没有了 &lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcgy1fi6if8s30uj203d023q2q.jpg&quot; alt=&quot;xiaohuangji&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以要如何截取整个页面的呢？我在chrome-remote-interface的wiki里看到了一篇&lt;a href=&quot;https://medium.com/@dschnr/using-headless-chrome-as-an-automated-screenshot-tool-4b07dffba79a?1&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文章&lt;/a&gt;。然而截屏的时候报错，说&lt;code&gt;Emulation.forceViewport&lt;/code&gt;不存在.原来这个API已经在新版的Chrome中被废弃了。&lt;/p&gt;
&lt;p&gt;最终我找到了一篇&lt;a href=&quot;https://jonathanmh.com/taking-full-page-screenshots-headless-chrome/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;神奇的博客&lt;/a&gt;，完美的解决了我的问题，核心代码是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Page.loadEventFired(async() =&amp;gt; {
    if (fullPage) {
      const {root: {nodeId: documentNodeId}} = await DOM.getDocument();
      const {nodeId: bodyNodeId} = await DOM.querySelector({
        selector: &amp;#39;body&amp;#39;,
        nodeId: documentNodeId,
      });

      const {model: {height}} = await DOM.getBoxModel({nodeId: bodyNodeId});
      await Emulation.setVisibleSize({width: device.width, height: height});
      await Emulation.setDeviceMetricsOverride({width: device.width, height:height, screenWidth: device.width, screenHeight: height, deviceScaleFactor: 1, fitWindow: false, mobile: false});
      await Emulation.setPageScaleFactor({pageScaleFactor:1});
    }
  });

  setTimeout(async function() {
    const screenshot = await Page.captureScreenshot({format: &amp;quot;png&amp;quot;, fromSurface: true});
    const buffer = new Buffer(screenshot.data, &amp;#39;base64&amp;#39;);
    fs.writeFile(&amp;#39;desktop.png&amp;#39;, buffer, &amp;#39;base64&amp;#39;, function(err) {
      if (err) {
        console.error(err);
      } else {
        console.log(&amp;#39;Screenshot saved&amp;#39;);
      }
    });
      client.close();
  }, screenshotDelay);

}).on(&amp;#39;error&amp;#39;, err =&amp;gt; {
  console.error(&amp;#39;Cannot connect to browser:&amp;#39;, err);
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;原理就是用Emulation这个API，去调整页面的一些属性。其中核心的方法是&lt;code&gt;Emulation.setVisibleSize&lt;/code&gt;，文档里对这个方法的说明是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Resizes the frame/viewport of the page. Note that this does not affect the frame’s container (e.g. browser window). Can be used to produce screenshots of the specified size.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后我们就可以愉快的给整个页面截屏了，比如这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcgy1fi6i22r84kj21402hdjux.jpg&quot; alt=&quot;full image&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Docker镜像&quot;&gt;&lt;a href=&quot;#Docker镜像&quot; class=&quot;headerlink&quot; title=&quot;Docker镜像&quot;&gt;&lt;/a&gt;Docker镜像&lt;/h3&gt;&lt;p&gt;最后我们需要部署这两个服务，社区里有自制的Headless Chrome的Docker镜像，比如&lt;a href=&quot;https://github.com/yukinying/chrome-headless-browser-docker&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;yukinying/chrome-headless-browser-docker&lt;/a&gt;。注意如果我们需要调整Chrome的默认window大小，可以修改&lt;a href=&quot;https://github.com/yukinying/chrome-headless-browser-docker/blob/master/chrome/Dockerfile&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Dockerfile&lt;/a&gt;然后自行build镜像。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ENTRYPOINT [&amp;quot;/usr/bin/dumb-init&amp;quot;, &amp;quot;--&amp;quot;, \
            &amp;quot;/usr/bin/google-chrome-unstable&amp;quot;, \
            &amp;quot;--disable-gpu&amp;quot;, \
            &amp;quot;--window-size=1440,900&amp;quot;  # 在ENTRYPOINT命令参数中加上window-size
            &amp;quot;--headless&amp;quot;, \
            &amp;quot;--remote-debugging-address=0.0.0.0&amp;quot;, \
            &amp;quot;--remote-debugging-port=9222&amp;quot;, \
            &amp;quot;--user-data-dir=/data&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Node服务的镜像就比较简单了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM node:latest
# Create app directory
RUN mkdir -p /usr/src/app
WORKDIR /usr/src/app
COPY . /usr/src/app

RUN npm install koa chrome-remote-interface
EXPOSE 3000
CMD [ &amp;quot;node&amp;quot;, &amp;quot;index.js&amp;quot; ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;生产中应该用pm2这样的Process Manager来保持进程的运行。依赖也应该写在package.json里。&lt;/p&gt;
&lt;p&gt;服务之间的关系如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcgy1fi6j3jqs0cj20fj07saaf.jpg&quot; alt=&quot;service&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Links&quot;&gt;&lt;a href=&quot;#Links&quot; class=&quot;headerlink&quot; title=&quot;Links&quot;&gt;&lt;/a&gt;Links&lt;/h3&gt;&lt;p&gt;如果大家想使用Headless Chrome的话，最好还是去浏览一下相关的文档，因为这些内容都属于比较新的东西，变化也比较快。本文主要是简单的介绍一下这方面实现的可行性。下面是相关的链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://developers.google.com/web/updates/2017/04/headless-chrome&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Getting Started with Headless Chrome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://chromedevtools.github.io/devtools-protocol/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Chrome DevTools Protocol Viewer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/cyrus-and/chrome-remote-interface&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;chrome-remote-interface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://jonathanmh.com/taking-full-page-screenshots-headless-chrome/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Taking Full Page Screenshots with Headless Chrome&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;TL-DR&quot;&gt;&lt;a href=&quot;#TL-DR&quot; class=&quot;headerlink&quot; title=&quot;TL;DR&quot;&gt;&lt;/a&gt;TL;DR&lt;/h3&gt;&lt;p&gt;给太长不看同学的内容速览：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Headless是Chrome 59中加入的一种新的运行模式&lt;/li&gt;
&lt;li&gt;Headless Chrome可以替代PhantomJS，并且更加强大&lt;/li&gt;
&lt;li&gt;可以通过Chrome DevTools Protocol这个协议对远程的Chrome浏览器进行调试&lt;/li&gt;
&lt;li&gt;chrome-remote-interface是Nodejs下Chrome DevTools Protocol的封装&lt;/li&gt;
&lt;li&gt;可以使用&lt;code&gt;Emulation.setVisibleSize&lt;/code&gt;对&lt;strong&gt;整个页面&lt;/strong&gt;进行截屏&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>前端微服务实践-以木犀通行证为例</title>
    <link href="http://yoursite.com/2017/06/05/fe-microservice/"/>
    <id>http://yoursite.com/2017/06/05/fe-microservice/</id>
    <published>2017-06-05T07:01:58.000Z</published>
    <updated>2017-06-19T04:04:00.000Z</updated>
    
    <content type="html">&lt;p&gt;在前端，长期以来困扰我们的一个问题就是，如何分发部署我们的前端代码？之前我们的前端代码是放在后端容器中部署的，因此如果需要更新就需要后端工程师去重启容器，更新代码。现在我们采取的方法是，将前端作为一个单独的服务，使用容器来部署。这样前端代码的部署和其他的代码就没有区别了。前端工程师可以自由的控制前端代码的部署，整个部署流程也变的非常标准化。前端微服务让前端部署变成了一件让人享受的事情。下面就以&lt;a href=&quot;https://github.com/Muxi-Studio/MuxiAuth-fe&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;木犀通行证&lt;/a&gt;为例来讲讲具体的实现。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;Nodejs服务&quot;&gt;&lt;a href=&quot;#Nodejs服务&quot; class=&quot;headerlink&quot; title=&quot;Nodejs服务&quot;&gt;&lt;/a&gt;Nodejs服务&lt;/h3&gt;&lt;p&gt;如果只是在容器中放一些前端的静态文件，那不能叫前端微服务。前端微服务是指用Nodejs实现的View层。包括了同步路由以及前端模板。静态文件可以放在前端容器中分发，也可以上传到CDN分发。&lt;/p&gt;
&lt;p&gt;Nodejs实现的这个View层（传统后端MVC中的View），主要负责渲染同步路由的模板。API服务则是由其他的服务提供，大家各司其职。前端接管View层有很多好处，前端渲染以及各种网络应用层的优化，都可以由前端自己来控制。目前Nodejs在大公司中早已频繁被用在服务最前端的那一层中了（后端一般是Java）。&lt;/p&gt;
&lt;p&gt;具体实现来说，我们选用koa2作为Web框架，大致实现是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const send = require(&amp;#39;koa-send&amp;#39;);
const Koa = require(&amp;#39;koa&amp;#39;);
const Router = require(&amp;#39;koa-router&amp;#39;);
const userAgent = require(&amp;#39;koa-useragent&amp;#39;);
const path = require(&amp;#39;path&amp;#39;)
const swig = require(&amp;#39;swig&amp;#39;);
const router = new Router();
const app = new Koa();

const templateRoot = path.join(__dirname, &amp;quot;../dist/template/main&amp;quot;)

app.use(userAgent);

router.get(&amp;#39;/&amp;#39;, function(ctx, next){
    if (!ctx.userAgent.isMobile) {
        let template = swig.compileFile(path.resolve(templateRoot, &amp;quot;auth.html&amp;quot;));
        ctx.body = template({})
    } else {
        let template = swig.compileFile(path.resolve(templateRoot, &amp;quot;auth_phone.html&amp;quot;));
        ctx.body = template({})
    }
});

router.get(/^\/static(?:\/|$)/, async (ctx) =&amp;gt; {
     await send(ctx, ctx.path, {
         root: path.join(__dirname, &amp;quot;../dist&amp;quot;)
     });
})

app
    .use(router.routes())
    .use(router.allowedMethods());

app.listen(3000);
console.log(&amp;#39;listening on port 3000&amp;#39;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用&lt;code&gt;koa-router&lt;/code&gt;来写同步路由，路由中返回对应模板（这里的路由还对移动端或者桌面端流量进行了区分）。然后这里还对静态文件路由做了处理，如果用的是CDN分发静态文件，这里就不需要处理了。&lt;/p&gt;
&lt;h3 id=&quot;Dockerfile&quot;&gt;&lt;a href=&quot;#Dockerfile&quot; class=&quot;headerlink&quot; title=&quot;Dockerfile&quot;&gt;&lt;/a&gt;Dockerfile&lt;/h3&gt;&lt;p&gt;&lt;code&gt;Dockerfile&lt;/code&gt;是Docker的配置文件。我们要把这个Nodejs服务build成Docker镜像进行部署，因此要写一个&lt;code&gt;Dockerfile&lt;/code&gt;，大致是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM node:latest

# Create app directory
RUN mkdir -p /usr/src/app
WORKDIR /usr/src/app
COPY . /usr/src/app

# Build static file
RUN npm install
RUN npm run build

WORKDIR /usr/src/app/server

# Bundle app source
EXPOSE 3000
CMD [ &amp;quot;npm&amp;quot;, &amp;quot;start&amp;quot; ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Dockerfile具体的写法可以看官方文档和这篇博客。木犀通行证中的Dockerfile主要是，构建了静态文件，然后启动了node服务进程。这样只要在任何有Docker的环境下&lt;code&gt;docker run&lt;/code&gt;这个镜像，就可以运行这个服务了。&lt;/p&gt;
&lt;h3 id=&quot;在阿里云镜像仓库Build镜像&quot;&gt;&lt;a href=&quot;#在阿里云镜像仓库Build镜像&quot; class=&quot;headerlink&quot; title=&quot;在阿里云镜像仓库Build镜像&quot;&gt;&lt;/a&gt;在阿里云镜像仓库Build镜像&lt;/h3&gt;&lt;p&gt;镜像仓库类似是Github，是分发镜像的一个工具。阿里云的镜像仓库可以从Github仓库进行镜像构建，然后我们就可以拿到一个仓库的URL。在构建时我们可以指定版本号（和Git里的tag对应）。这样在部署时就可以部署这个镜像的某个版本。&lt;/p&gt;
&lt;p&gt;阿里云的镜像仓库的用法这里就不详细说了。可以自己去阿里云上尝试一下。&lt;/p&gt;
&lt;h3 id=&quot;在Kubernetes部署&quot;&gt;&lt;a href=&quot;#在Kubernetes部署&quot; class=&quot;headerlink&quot; title=&quot;在Kubernetes部署&quot;&gt;&lt;/a&gt;在Kubernetes部署&lt;/h3&gt;&lt;p&gt;&lt;em&gt;MAE发布后本节需要更新&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;目前这一步是由专门的系统管理员来负责的。开发者只要将镜像仓库的地址和tag告诉系统管理员就可以了。管理员会在集群上更新并部署新版本。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;这个新的部署流程和之前相比，不同的地方主要是现在需要写Nodejs，一个View层服务。需要写Dockerfile。最终交付部署的是Docker镜像。希望大家在实践的过程中能有自己的思考。同时也对云计算时代的软件分发和部署有更多的了解。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在前端，长期以来困扰我们的一个问题就是，如何分发部署我们的前端代码？之前我们的前端代码是放在后端容器中部署的，因此如果需要更新就需要后端工程师去重启容器，更新代码。现在我们采取的方法是，将前端作为一个单独的服务，使用容器来部署。这样前端代码的部署和其他的代码就没有区别了。前端工程师可以自由的控制前端代码的部署，整个部署流程也变的非常标准化。前端微服务让前端部署变成了一件让人享受的事情。下面就以&lt;a href=&quot;https://github.com/Muxi-Studio/MuxiAuth-fe&quot;&gt;木犀通行证&lt;/a&gt;为例来讲讲具体的实现。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>木犀后端开发工作流（2017年6月版）</title>
    <link href="http://yoursite.com/2017/06/05/muxi-be-workflow/"/>
    <id>http://yoursite.com/2017/06/05/muxi-be-workflow/</id>
    <published>2017-06-05T07:01:43.000Z</published>
    <updated>2017-06-19T04:01:09.000Z</updated>
    
    <content type="html">&lt;p&gt;木犀后端的技术经历了一个不断演进的过程，从最初的LNMP式的简单直接的部署方式，到Docker容器部署，到现在的Kubernetes集群部署。相比当年艰难的调试由于操作系统环境不同而导致的各种部署问题，现在的部署流程可以说是相当简单而且可靠的。这也要求我们有一套标准化的开发部署流程。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;三个环境&quot;&gt;&lt;a href=&quot;#三个环境&quot; class=&quot;headerlink&quot; title=&quot;三个环境&quot;&gt;&lt;/a&gt;三个环境&lt;/h3&gt;&lt;p&gt;在互联网公司，一个产品一般都部署了好几个版本，比如开发、测试、预发布等等。不同的版本对应开发周期不同时间点的产品状态。QA一般就是在部署好的这些环境中进行发布前测试的。&lt;/p&gt;
&lt;p&gt;我们对环境的要求没有那么高，只要有本地、测试、线上三个环境就可以了。下面分别讲讲从本地开发，到部署测试版本，到新版本上线过程中一系列的标准流程。&lt;/p&gt;
&lt;h3 id=&quot;开发分支与Pull-Request&quot;&gt;&lt;a href=&quot;#开发分支与Pull-Request&quot; class=&quot;headerlink&quot; title=&quot;开发分支与Pull Request&quot;&gt;&lt;/a&gt;开发分支与Pull Request&lt;/h3&gt;&lt;p&gt;本地开发其实没有太多的限制，一般就直接在本地运行代码进行开发。需要注意的是我们的仓库中一般有主分支和开发分支，这个开发分支可以是按版本号，每次新版本时从主分支checkout出来。或者是一个持续使用的开发分支。所有人都&lt;strong&gt;不能直接&lt;/strong&gt;向主分支提交代码。但可以直接向开发分支提交代码。&lt;/p&gt;
&lt;p&gt;如果想讲开发分支中的代码合并到主分支，就要发起一个&lt;strong&gt;Pull Request&lt;/strong&gt;。Pull Request在负责人code review（看情况）以及&lt;strong&gt;CI测试通过&lt;/strong&gt;之后才能merge。&lt;/p&gt;
&lt;h3 id=&quot;单元测试与CI&quot;&gt;&lt;a href=&quot;#单元测试与CI&quot; class=&quot;headerlink&quot; title=&quot;单元测试与CI&quot;&gt;&lt;/a&gt;单元测试与CI&lt;/h3&gt;&lt;p&gt;对于有明确输入输出的后端API来说，单元测试是必要的软件质量保障。也是协助开发的一个手段。&lt;/p&gt;
&lt;p&gt;大家在本地提交代码之前先自己跑过测试，通过之后再提交。Pull Request时还会跑一遍CI，来确保代码功能的正确。比如这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcly1fgqdkad2a4j213u02mq37.jpg&quot; alt=&quot;CI pass&quot;&gt;&lt;/p&gt;
&lt;p&gt;Github上使用的比较多的是Travis CI。Docker based的项目可以参考&lt;a href=&quot;https://github.com/Muxi-X/muxi_site/blob/dev-branch/.travis.yml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这个CI配置&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里简单介绍一下CI。CI指持续集成，我们说的CI一般是指云端的CI runner。Travis CI本质上其实就是一个云服务。提供了一个虚拟环境来运行你指定的脚本。Travis支持很多语言环境，但最近Travis支持了Docker，所以环境也就不是问题了。要注意我们写测试时要写清进程exit时的状态码，非0的状态码代表非正常退出。Travis就是根据这个来判断测试或者其他错误是否发生的。这决定了这次CI运行是否成功。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;测试环境的具体配置&quot;&gt;&lt;a href=&quot;#测试环境的具体配置&quot; class=&quot;headerlink&quot; title=&quot;测试环境的具体配置&quot;&gt;&lt;/a&gt;测试环境的具体配置&lt;/h3&gt;&lt;p&gt;在开发基本完成，代码merge到主分支之后，我们就可以尝试部署一个测试版本了。测试环境和线上的环境差别不大。测试环境部署在我们的测试集群（几台专有网络阿里云学生机）。&lt;/p&gt;
&lt;p&gt;大家可以随意选一台机器然后部署。部署的时候，除了数据库之外的一般都用Docker部署。如果有多个容器需要部署，我们一般用Docker-compose来一键build&amp;amp;run。&lt;/p&gt;
&lt;p&gt;数据库一般就使用某台机器上直接安装的数据库。在初次部署时大家要记得在容器中执行初始化数据库和用户角色命令（当然也可以写成脚本）。&lt;/p&gt;
&lt;p&gt;测试环境有几个用处，首先是给前端提供联调的API。然后是给产品经理和设计师提供一个线上版本来进行初步测试。因此我们需要给测试环境配置一个域名。但如果直接在DnsPod等等线上解析，要解析的域名数量会很大，很不方便。所以我们采用修改本地hosts文件的办法。&lt;/p&gt;
&lt;p&gt;比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;120.77.8.149 test.share.muxixyz.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意域名是&lt;code&gt;muxixyz.com&lt;/code&gt;的子域名&lt;/strong&gt;，因为阿里云会检测DNS解析的域名是否备案。如果随便写一个域名是不行的（当然理论上你用baidu.com或者其他知名的域名也行）。&lt;/p&gt;
&lt;p&gt;这个hosts文件的配置要写在Github文档中。Tower项目里最好也写一个操作指南文档给设计师和PM看。&lt;/p&gt;
&lt;h3 id=&quot;上线&quot;&gt;&lt;a href=&quot;#上线&quot; class=&quot;headerlink&quot; title=&quot;上线&quot;&gt;&lt;/a&gt;上线&lt;/h3&gt;&lt;p&gt;&lt;em&gt;MAE发布后本节需要更新&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;上线一个版本，比如1.2版。首先在主分支打上这个tag。然后在阿里云的镜像仓库里build这个tag的镜像。&lt;/p&gt;
&lt;p&gt;最后由负责部署的同学，SSH到集群更新Deployment配置文件中的image版本号。升级Deployment即可。&lt;/p&gt;
&lt;p&gt;这一步在将来会由开发应用的同学自行在MAE上操作完成。目前暂时还是需要有人在服务器上部署。开发的同学只要交付镜像就可以了。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;相比于之前的工作流，目前的工作流不同的地方主要是，需要写单元测试，PR需要CI通过才能merge，大型的应用必须要部署测试环境并用本地DNS解析访问，进行部署时是用Docker镜像而不是在服务器build。这套工作流需要大家用&lt;strong&gt;微服务&lt;/strong&gt;的观点去看待将来的开发。随着时间的推移，这套工作流也会不断的变化，大致还是朝Cloud Native的方向发展。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;木犀后端的技术经历了一个不断演进的过程，从最初的LNMP式的简单直接的部署方式，到Docker容器部署，到现在的Kubernetes集群部署。相比当年艰难的调试由于操作系统环境不同而导致的各种部署问题，现在的部署流程可以说是相当简单而且可靠的。这也要求我们有一套标准化的开发部署流程。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>云端木犀-MAE初步构想</title>
    <link href="http://yoursite.com/2017/05/27/mae/"/>
    <id>http://yoursite.com/2017/05/27/mae/</id>
    <published>2017-05-27T13:29:43.000Z</published>
    <updated>2017-05-28T01:49:49.000Z</updated>
    
    <content type="html">&lt;p&gt;Muxi App Engine，简称MAE，是木犀的私有PaaS方案，也是木犀云的重要组成部分。MAE主要基于Docker和Kubernetes，为木犀所有应用的构建、部署、监控和扩容提供了一个统一的入口，让我们能专注于服务本身的开发。同时MAE也为木犀提供了一套标准化的运维流程，使得团队开发中的工程化程度进一步提高。&lt;/p&gt;
&lt;p&gt;说的这么厉害，那如果你是一个技术小白，我应该如何来解释MAE呢？&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;TD-LR&quot;&gt;&lt;a href=&quot;#TD-LR&quot; class=&quot;headerlink&quot; title=&quot;TD;LR&quot;&gt;&lt;/a&gt;TD;LR&lt;/h3&gt;&lt;p&gt;比如我们有一个应用，华师匣子。华师匣子是由很多的服务构成的，比如成绩服务，课表服务，图书馆服务等等。每个服务都实现了对应的接口。我们使用Docker来运行这些服务。Docker是一种容器技术。我们可以简单的理解为一种沙盒环境。这些容器的存在，已经很大程度上方便了我们的部署。因为容器可以实现系统资源的隔离，使得服务器上可以同时运行很多不同的服务，而相互不打扰。&lt;/p&gt;
&lt;p&gt;但手动部署容器，还是太复杂了。我们要登录服务器手动部署容器。容器如果出现问题，我们也需要亲自去重启。如果我们需要横向拓展，部署多个相同的容器以应对高负载，也需要一个个去手动部署。这个时候就需要一个调度者来帮我们自动完成这个任务。&lt;/p&gt;
&lt;p&gt;我们可以把MAE理解为容器的调度者。我们在MAE中新建一个应用和下属的服务，填写相关的信息。比如我们只要提供Docker镜像的地址，就可以一键部署。MAE会帮我们将容器部署到合适的服务器上。如果容器因为某些原因崩溃了，MAE会自动重启容器。如果我们需要横向拓展，那只要在控制台里填写一下需要拓展的数量就可以了。如果需要更新代码，我们只需要提供镜像的新版本号，MAE会自动终止旧版本的容器，新建新版本的容器。一切都是这么简单。可以自动化的事情，我们都会做到自动化。&lt;/p&gt;
&lt;p&gt;MAE提供Web UI和CLI。Web UI主要用于日常的使用以及查看监控数据。CLI适合在shell脚本等自动化环境下使用。&lt;/p&gt;
&lt;p&gt;MAE带来的最大变革是，今后我们的应用从一开始就应该按Cloud Native的思路去编写。要拥抱云计算，我们必须编写Cloud Native的应用，具体的说，使用微服务架构，写无状态的功能单元，容器技术，将数据库等等持久化的组件作为单独的部分等等，都是Cloud Native的体现。只有这样，我们的应用才能和目前公有云和私有云的基础设施完美结合。&lt;/p&gt;
&lt;p&gt;下面就是纯粹的技术讨论了，请耐心阅读。&lt;/p&gt;
&lt;h3 id=&quot;MAE的技术选型&quot;&gt;&lt;a href=&quot;#MAE的技术选型&quot; class=&quot;headerlink&quot; title=&quot;MAE的技术选型&quot;&gt;&lt;/a&gt;MAE的技术选型&lt;/h3&gt;&lt;p&gt;简单的说，就是Docker和Kubernetes。Docker是容器技术的实现，Kubernetes主要提供了容器编排管理的功能。上一节中说到的大部分自动化功能，都是Kubernetes实现的。MAE中需要我们研发的主要是MAE API服务、Web UI还有CLI程序。除了这些，还有就是在MAE中实现一套最适合我们的&lt;strong&gt;对应用的抽象&lt;/strong&gt;。这套抽象是非常重要的。Kubernetes的概念并不是所有人都可以理解的，也没有必要对使用者暴露最底层的概念。PaaS的用户是从是应用和服务这些逻辑上的概念去看待问题的。所以MAE就提供了针对应用和服务的抽象，并且和Kubernetes整合起来。&lt;/p&gt;
&lt;h3 id=&quot;MAE的组成部分&quot;&gt;&lt;a href=&quot;#MAE的组成部分&quot; class=&quot;headerlink&quot; title=&quot;MAE的组成部分&quot;&gt;&lt;/a&gt;MAE的组成部分&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://wx2.sinaimg.cn/large/64c45edcly1fg0dnygziij212a0ue4e7.jpg&quot; alt=&quot;mae parts&quot;&gt;&lt;/p&gt;
&lt;p&gt;MAE的组成，从上到下，大致有三层：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MAE服务层&lt;/strong&gt; MAE服务层是暴露给用户的一些服务。MAE API Server是MAE是中枢。负责和底层的集群通信，保存应用配置等等。MAE Web UI提供了一个Web界面，用户可以通过Web UI对MAE发出指令，查看监控数据。MAE CLI是一个命令行程序，提供了从命令行和API Server通信的渠道。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;逻辑应用层&lt;/strong&gt; 这一层是抽象的应用层。也就是我们概念上的应用。因为实际的集群中是没有应用概念的（当然Kubernetes的Services+Namespace已经非常接近了），所以我们需要在这里提供对应的抽象。我们可以在MAE中新建应用，然后配置这个应用对应的服务。MAE中的服务（以后简称MAE服务，区别于Kubernetes Service），其实就对应一个微服务。一个应用由至少一个微服务构成。MAE服务是用户可以控制的部署的最小单元。我们可以对某个MAE服务单独进行拓展。比较特殊的MAE服务就是Nginx入口服务，这个服务为所有应用提供反向代理，同时也作为一个MAE下的服务，被MAE部署。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes层&lt;/strong&gt; Kubernetes这层就是底层的实现层了。包括了Service，Deployment和Pods。其中Service和Deployment在上层共同支撑了MAE服务。Pods则属于最底层的调度单元。在MAE层是完全不可见的。一个Pod由至少一个容器构成。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;MAE的流量分发&quot;&gt;&lt;a href=&quot;#MAE的流量分发&quot; class=&quot;headerlink&quot; title=&quot;MAE的流量分发&quot;&gt;&lt;/a&gt;MAE的流量分发&lt;/h3&gt;&lt;p&gt;那么作为一个分布式系统，一个用户的请求究竟是经过怎样的路径，到达最底层的Kubernetes Pod的呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx4.sinaimg.cn/large/64c45edcly1fg0etf4yg9j20ku0r4k1f.jpg&quot; alt=&quot;mae request&quot;&gt;&lt;/p&gt;
&lt;p&gt;首先DNS把域名解析到Kubernetes的Master节点的公网IP上，然后部署在Master节点上的Nginx入口服务接管，Nginx根据MAE应用设置的域名和URL规则，将这个请求转发到对应应用的某个服务上。Kubernetes的服务都是可以通过&lt;code&gt;&amp;lt;Master内网IP&amp;gt;:&amp;lt;Service Port&amp;gt;&lt;/code&gt;来进行访问的。然后Kubernetes proxy用iptables规则，将请求转发到某个节点上的Pod。&lt;/p&gt;
&lt;p&gt;由于Kubernetes proxy提供了均衡负载，我们不用再操心如何分配流量到服务下属的多个Pod中的某一个这样的问题。今后可以做的优化是，实现Kubernetes Master节点的高可用，也就是同时部署多个Master节点。这样的话就需要在Master节点之上再实现一个均衡负载。&lt;/p&gt;
&lt;h3 id=&quot;MAE的实现细节&quot;&gt;&lt;a href=&quot;#MAE的实现细节&quot; class=&quot;headerlink&quot; title=&quot;MAE的实现细节&quot;&gt;&lt;/a&gt;MAE的实现细节&lt;/h3&gt;&lt;p&gt;MAE做的抽象，一个是应用，应用之下是服务。对于这两个抽象，应该各自保存一些什么样的数据，这属于MAE的实现细节。&lt;/p&gt;
&lt;p&gt;每个应用需要的信息有，应用名，域名，Nginx转发规则，应用下属的服务列表。&lt;/p&gt;
&lt;p&gt;每个服务需要的信息有：服务名，当前镜像版本，镜像仓库地址，Github仓库地址，Kubernetes Service和Deployment需要的全部信息，当前服务属于哪个应用，授权管理当前服务的用户列表。&lt;/p&gt;
&lt;p&gt;因为服务是部署的最小单元，因此相对来说服务是MAE中比较核心的一个部分。MAE需要将数据库中保存的服务信息，自动转化为Kubernetes需要的&lt;code&gt;.yaml&lt;/code&gt;文件。将数据库中保存的应用信息，自动转化为nginx的配置文件。这是实现上需要去考虑的一个问题。&lt;/p&gt;
&lt;p&gt;另外，现在还需要仔细考虑的一点，&lt;strong&gt;MAE在全局/应用/服务这几个层面分别需要哪些监控数据&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;MAE时代的部署工作流&quot;&gt;&lt;a href=&quot;#MAE时代的部署工作流&quot; class=&quot;headerlink&quot; title=&quot;MAE时代的部署工作流&quot;&gt;&lt;/a&gt;MAE时代的部署工作流&lt;/h3&gt;&lt;p&gt;部署服务之前，首先我们要构建镜像（构建之前可以引入CI，测试通过才可以构建镜像）。给镜像打上版本号，然后发布到云端的镜像仓库（可以用阿里云/蜂巢/Daocloud）。之后我们就可以在MAE中为某个服务新建一次部署了，填上新的版本号，点击部署，就启动了一次部署了。得益于Kubernetes超强的部署能力，我们可以回滚、暂停、继续每一次部署。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcly1fg0era6a66j214q0mmwoc.jpg&quot; alt=&quot;mae deployment&quot;&gt;&lt;/p&gt;
&lt;p&gt;MAE的API Server把服务目前的配置转换为&lt;code&gt;.yaml&lt;/code&gt;格式，向Kubernetes API Server发送请求。然后Kubernetes会进行相应的处理。和Service相关的就调整Service，和Deployment相关的就调整Deployment。最终服务更新到目标状态，部署完成。&lt;/p&gt;
&lt;h3 id=&quot;MAE的物理节点组成&quot;&gt;&lt;a href=&quot;#MAE的物理节点组成&quot; class=&quot;headerlink&quot; title=&quot;MAE的物理节点组成&quot;&gt;&lt;/a&gt;MAE的物理节点组成&lt;/h3&gt;&lt;p&gt;MAE的逻辑组成已经介绍了，那MAE和具体的云主机之间是什么关系呢。请看下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx3.sinaimg.cn/large/64c45edcly1fg0ftnkesej213a0o07g6.jpg&quot; alt=&quot;mae nodes&quot;&gt;&lt;/p&gt;
&lt;p&gt;图中的一个框对应一台云主机。其中Master节点目前只打算部署在一台机器上。今后会做高可用（具体要看kubeadm的支持情况，自己部署HA也是可以的，参见&lt;a href=&quot;http://tonybai.com/2017/05/15/setup-a-ha-kubernetes-cluster-based-on-kubeadm-part1/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这篇博客&lt;/a&gt;）。Kubernetes Node是负载Pod调度的机器，也就是分布式系统主从节点中的Slave节点。Kubernetes的Pod可能会被调度到其中任意一台机器上。因此应用在物理上运行在哪个节点，在MAE中并没有太多的意义。&lt;/p&gt;
&lt;p&gt;MAE的Server在理论上会单独部署在一台服务器上，MAE Server如果出现问题，其实并不影响当前集群的正常运转。Kubernetes的Master节点才是真正负责调度和管理的，因此才会有做高可用的打算。&lt;/p&gt;
&lt;h3 id=&quot;MAE时代的前端服务化&quot;&gt;&lt;a href=&quot;#MAE时代的前端服务化&quot; class=&quot;headerlink&quot; title=&quot;MAE时代的前端服务化&quot;&gt;&lt;/a&gt;MAE时代的前端服务化&lt;/h3&gt;&lt;p&gt;MAE要求一个应用由几个服务构成。这给了我们一个机会，去改进目前的前端代码部署流程。目前的前端代码是放在后端容器中部署的。每次部署需要后端工程师参与，或者使用配置复杂的Webhook。前端代码部署时需要重启后端容器，因此无法实现无副作用的前端部署。MAE架构下，我们将前端作为一个单独的服务。这个服务主要接受的是从Nginx入口服务转发而来的需要返回HTML的请求，也就是我们一般所说的View层，或者说同步路由层。技术上我们选用Nodejs来实现前端的服务。&lt;/p&gt;
&lt;p&gt;所以今后前端工程师的产出就是前端代码以及Nodejs服务端代码（主要是路由）。两者在同一个仓库中，部署在同一个容器中。&lt;/p&gt;
&lt;p&gt;这样的好处是，前端代码部署时只需要构建前端服务的镜像，然后在MAE单独部署就可以了。和后端完全解耦。前端工程师也可以借助MAE提供的强大的运维能力，来优化自己的工作流。&lt;/p&gt;
&lt;p&gt;前端工程师接管View层，给我们的应用带来了更大的可能性。服务端渲染前端组件变成了非常自然的选择。前端工程师控制的范围扩大，提供了更多发挥的空间。比如前端工程师可以对静态资源缓存，CSRF等等进行更好的控制。&lt;/p&gt;
&lt;h3 id=&quot;MAE的主要API以及CLI工具命令&quot;&gt;&lt;a href=&quot;#MAE的主要API以及CLI工具命令&quot; class=&quot;headerlink&quot; title=&quot;MAE的主要API以及CLI工具命令&quot;&gt;&lt;/a&gt;MAE的主要API以及CLI工具命令&lt;/h3&gt;&lt;p&gt;API在Web UI框架确定之后就可以比较清楚的写成文档了，这里只列一下主要的API。&lt;/p&gt;
&lt;h4 id=&quot;应用层API&quot;&gt;&lt;a href=&quot;#应用层API&quot; class=&quot;headerlink&quot; title=&quot;应用层API&quot;&gt;&lt;/a&gt;应用层API&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;应用列表/信息&lt;/li&gt;
&lt;li&gt;应用网络配置更新&lt;/li&gt;
&lt;li&gt;监控信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;服务层API&quot;&gt;&lt;a href=&quot;#服务层API&quot; class=&quot;headerlink&quot; title=&quot;服务层API&quot;&gt;&lt;/a&gt;服务层API&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;服务列表/信息&lt;/li&gt;
&lt;li&gt;部署服务新版本&lt;/li&gt;
&lt;li&gt;横向拓展服务&lt;/li&gt;
&lt;li&gt;回滚、暂停部署&lt;/li&gt;
&lt;li&gt;监控信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;CLI&quot;&gt;&lt;a href=&quot;#CLI&quot; class=&quot;headerlink&quot; title=&quot;CLI&quot;&gt;&lt;/a&gt;CLI&lt;/h4&gt;&lt;p&gt;CLI提供了和主要API对应的命令。命令需要验证的话，可以通过&lt;code&gt;mae login&lt;/code&gt;这样的命令来进行。&lt;/p&gt;
&lt;h3 id=&quot;木犀云的其他产品展望&quot;&gt;&lt;a href=&quot;#木犀云的其他产品展望&quot; class=&quot;headerlink&quot; title=&quot;木犀云的其他产品展望&quot;&gt;&lt;/a&gt;木犀云的其他产品展望&lt;/h3&gt;&lt;h4 id=&quot;Muxi-Database-Service-MDS&quot;&gt;&lt;a href=&quot;#Muxi-Database-Service-MDS&quot; class=&quot;headerlink&quot; title=&quot;Muxi Database Service(MDS)&quot;&gt;&lt;/a&gt;Muxi Database Service(MDS)&lt;/h4&gt;&lt;p&gt;提供Mongo，Redis等云数据库服务。实现了数据自动备份，多节点高可用等特性。&lt;/p&gt;
&lt;h4 id=&quot;Muxi-Storage-Service-MSS&quot;&gt;&lt;a href=&quot;#Muxi-Storage-Service-MSS&quot; class=&quot;headerlink&quot; title=&quot;Muxi Storage Service(MSS)&quot;&gt;&lt;/a&gt;Muxi Storage Service(MSS)&lt;/h4&gt;&lt;p&gt;基于Ceph的分布式对象存储。负责大文件的存储。比如图片、文档等。&lt;/p&gt;
&lt;h4 id=&quot;鹊桥&quot;&gt;&lt;a href=&quot;#鹊桥&quot; class=&quot;headerlink&quot; title=&quot;鹊桥&quot;&gt;&lt;/a&gt;鹊桥&lt;/h4&gt;&lt;p&gt;木犀接口管理平台。提供了接口的云端管理和Mock服务。&lt;/p&gt;
&lt;h4 id=&quot;Muxi-UI-MUI&quot;&gt;&lt;a href=&quot;#Muxi-UI-MUI&quot; class=&quot;headerlink&quot; title=&quot;Muxi UI(MUI)&quot;&gt;&lt;/a&gt;Muxi UI(MUI)&lt;/h4&gt;&lt;p&gt;基于Vuejs的UI组件库。适用于中后台前端应用的快速开发。&lt;/p&gt;
&lt;h3 id=&quot;写在最后-Why-Cloud&quot;&gt;&lt;a href=&quot;#写在最后-Why-Cloud&quot; class=&quot;headerlink&quot; title=&quot;写在最后: Why Cloud?&quot;&gt;&lt;/a&gt;写在最后: Why Cloud?&lt;/h3&gt;&lt;p&gt;为什么木犀要拥抱云计算？为什么我们要自建私有PaaS平台？&lt;/p&gt;
&lt;p&gt;首先，在当下，计算能力，已经和水电煤一样，成为了一种基础设施。作为小团队，使用现成的基础设施，从成本上以及灵活性上都是最佳的。&lt;/p&gt;
&lt;p&gt;虽然我们使用了IaaS服务，但我们还是可以把云主机当做物理主机来使用，我们完全可以实施云计算出现之前时代的传统运维。运维工程师负责服务器的环境，开发工程师把代码交给运维工程师部署。数据库等服务和业务逻辑部署在同一台机器上，等等等等。很明显，坚持这种做法，将云计算理解为虚拟主机，是非常不明智的。&lt;/p&gt;
&lt;p&gt;既然已经用上了IaaS，那就要利用现有的微服务理论和Docker等等容器技术，打造更加原生的云端体验。我们将代码拆成一个一个单元，将有状态和无状态的服务分离。部署时容器让我们不用在意服务端的环境隔离。Kubernetes让我们不用手动管理容器的生命周期。&lt;/p&gt;
&lt;p&gt;开发MAE是为了解决目前团队部署流程中存在的问题。自建的PaaS平台可以最大程度提供个性化的使用体验。也给我们机会去对Kubernetes等开源技术进行探索和研究，并且用到生产环境之中。&lt;/p&gt;
&lt;p&gt;围绕木犀云而进行的一系列的研究，是木犀拥抱云计算的最好方式。我们不仅要享受云计算的好处，同时也要参与其中，深入的理解技术细节。相信未来我们在云计算上的发展会有无限的可能。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Muxi App Engine，简称MAE，是木犀的私有PaaS方案，也是木犀云的重要组成部分。MAE主要基于Docker和Kubernetes，为木犀所有应用的构建、部署、监控和扩容提供了一个统一的入口，让我们能专注于服务本身的开发。同时MAE也为木犀提供了一套标准化的运维流程，使得团队开发中的工程化程度进一步提高。&lt;/p&gt;
&lt;p&gt;说的这么厉害，那如果你是一个技术小白，我应该如何来解释MAE呢？&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>使用Kubeadm 1.6部署Kubernetes</title>
    <link href="http://yoursite.com/2017/05/24/k8s-setup/"/>
    <id>http://yoursite.com/2017/05/24/k8s-setup/</id>
    <published>2017-05-24T11:52:27.000Z</published>
    <updated>2017-06-10T18:05:54.000Z</updated>
    
    <content type="html">&lt;p&gt;本文介绍了如何用Kubeadm 1.6版在Ubuntu 16.04系统上快速部署一个Kubernetes集群。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h3&gt;&lt;p&gt;阿里云ECS 华南1 可用区A Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-63-generic x86_64) 专有网络&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;节点类型&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;配置&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;内网IP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;MASTER&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1 CPU 1GB RAM&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;172.18.214.46&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Node&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;1 CPU 2GB RAM&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;172.18.214.47&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;依赖安装-amp-amp-代理设置&quot;&gt;&lt;a href=&quot;#依赖安装-amp-amp-代理设置&quot; class=&quot;headerlink&quot; title=&quot;依赖安装&amp;amp;&amp;amp;代理设置&quot;&gt;&lt;/a&gt;依赖安装&amp;amp;&amp;amp;代理设置&lt;/h3&gt;&lt;p&gt;首先要在两个节点都安装Docker和Kubernetes相关的组件。因为相关的镜像都在墙外，所以这里需要挂代理或者自行寻找墙内的源。笔者选择的是挂代理的方案，给Ubuntu配置HTTP代理可以参考&lt;a href=&quot;http://dearmadman.com/2015/08/30/use-shadowsocks-in-ubuntu/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这篇博客&lt;/a&gt;。给Docker配置代理可以参考&lt;a href=&quot;https://docs.docker.com/engine/admin/systemd/#httphttps-proxy&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;安装的步骤是按照官网的文档&lt;a href=&quot;https://kubernetes.io/docs/getting-started-guides/kubeadm/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Installing Kubernetes on Linux with kubeadm&lt;/a&gt;来的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 升级包管理的镜像列表
apt-get update &amp;amp;&amp;amp; apt-get install -y apt-transport-https
# 将docker和kubernetes相关的镜像源加入列表
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update
# 安装docker和kubernetes相关组件
apt-get install -y docker-engine
apt-get install -y kubelet kubeadm kubectl kubernetes-cni
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;初始化&quot;&gt;&lt;a href=&quot;#初始化&quot; class=&quot;headerlink&quot; title=&quot;初始化&quot;&gt;&lt;/a&gt;初始化&lt;/h3&gt;&lt;p&gt;在MASTER节点运行：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubeadm init&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果一切正常，最后会有如下的输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular user):

  sudo cp /etc/kubernetes/admin.conf $HOME/
  sudo chown $(id -u):$(id -g) $HOME/admin.conf
  export KUBECONFIG=$HOME/admin.conf

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  http://kubernetes.io/docs/admin/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 67e1ac.eac65cabb7d2801c 172.18.214.46:6443
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;设置环境变量&quot;&gt;&lt;a href=&quot;#设置环境变量&quot; class=&quot;headerlink&quot; title=&quot;设置环境变量&quot;&gt;&lt;/a&gt;设置环境变量&lt;/h3&gt;&lt;p&gt;上一步中kubeadm会生成配置文件，输出的消息中要求我们设置环境变量&lt;code&gt;KUBECONFIG&lt;/code&gt;为配置文件的路径。以便后续的使用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo cp /etc/kubernetes/admin.conf $HOME/
sudo chown $(id -u):$(id -g) $HOME/admin.conf
export KUBECONFIG=$HOME/admin.conf
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Pod网络设置：weaver&quot;&gt;&lt;a href=&quot;#Pod网络设置：weaver&quot; class=&quot;headerlink&quot; title=&quot;Pod网络设置：weaver&quot;&gt;&lt;/a&gt;Pod网络设置：weaver&lt;/h3&gt;&lt;p&gt;到这里，我们已经初始化了一个单节点的Kubernetes集群。要想在集群中加入真正负载应用的Node，我们需要初始化一个Overlay Network。&lt;/p&gt;
&lt;p&gt;Overlay Network的选择有很多，比如Flannel和Calico。但经过我个人的踩坑和&lt;a href=&quot;http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;参考博客&lt;/a&gt;后，最终选择了weaver。&lt;/p&gt;
&lt;p&gt;在Master节点运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply -f https://git.io/weave-kube-1.6
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;稍候片刻，运行&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods -o wide --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看pods的运行情况：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NAMESPACE     NAME                                              READY     STATUS    RESTARTS   AGE       IP              NODE
kube-system   etcd-izwz9ap4sedl64wboiyh6cz                      1/1       Running   0          55m       172.18.214.46   izwz9ap4sedl64wboiyh6cz
kube-system   kube-apiserver-izwz9ap4sedl64wboiyh6cz            1/1       Running   0          54m       172.18.214.46   izwz9ap4sedl64wboiyh6cz
kube-system   kube-controller-manager-izwz9ap4sedl64wboiyh6cz   1/1       Running   0          55m       172.18.214.46   izwz9ap4sedl64wboiyh6cz
kube-system   kube-dns-3913472980-l8ghd                         3/3       Running   0          55m       10.32.0.2       izwz9ap4sedl64wboiyh6cz
kube-system   kube-proxy-n5332                                  1/1       Running   0          55m       172.18.214.46   izwz9ap4sedl64wboiyh6cz
kube-system   kube-scheduler-izwz9ap4sedl64wboiyh6cz            1/1       Running   0          54m       172.18.214.46   izwz9ap4sedl64wboiyh6cz
kube-system   weave-net-l86wx                                   2/2       Running   0          48m       172.18.214.46   izwz9ap4sedl64wboiyh6cz
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果weave-net和kube-dns这两个pod都处于Running的状态。说明网络初始化成功。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;weave-net如果出现CrashLoopBackOff的错误，可以参考&lt;a href=&quot;http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里&lt;/a&gt;的解决方案&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;加入Node&quot;&gt;&lt;a href=&quot;#加入Node&quot; class=&quot;headerlink&quot; title=&quot;加入Node&quot;&gt;&lt;/a&gt;加入Node&lt;/h3&gt;&lt;p&gt;在Node上运行之前Master上输出的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm join --token 67e1ac.eac65cabb7d2801c 172.18.214.46:6443
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;设置配置文件路径的环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export KUBECONFIG=/etc/kubernetes/kubelet.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;稍后，查看Node的运行情况：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get nodes

NAME                      STATUS    AGE       VERSION
izwz9972b5w4h8a4f1h9z7z   Ready     2h        v1.6.4
izwz9ap4sedl64wboiyh6cz   Ready     4h        v1.6.4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;两个节点都显示Ready，说明加入成功。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;默认情况Master是不承担负载的，如果要Master节点也参与Pod调度，可以运行&lt;code&gt;kubectl taint nodes --all node-role.kubernetes.io/master-&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;示例应用&quot;&gt;&lt;a href=&quot;#示例应用&quot; class=&quot;headerlink&quot; title=&quot;示例应用&quot;&gt;&lt;/a&gt;示例应用&lt;/h3&gt;&lt;p&gt;节点部署就绪，我们来试着部署一个应用吧：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create namespace sock-shop
kubectl apply -n sock-shop -f &amp;quot;https://github.com/microservices-demo/microservices-demo/blob/master/deploy/kubernetes/complete-demo.yaml?raw=true&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这两行命令会部署sock-shop相关的deployment和service。这些service共同组成了一个逻辑上的袜子商店网站。&lt;/p&gt;
&lt;p&gt;等所有Pods都是Running状态了，我们可以运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl -n sock-shop get svc front-end
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看front-end服务的端口：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NAME        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
front-end   10.103.179.228   &amp;lt;nodes&amp;gt;       80:30001/TCP   1h
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;端口是30001，然后我们就可以用&lt;code&gt;http://&amp;lt;MASTER_IP&amp;gt;:30001&lt;/code&gt;来访问服务了:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/large/64c45edcly1ffysdi2jjfj21kw0yhnpe.jpg&quot; alt=&quot;socks-shop&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;查看和升级部署&quot;&gt;&lt;a href=&quot;#查看和升级部署&quot; class=&quot;headerlink&quot; title=&quot;查看和升级部署&quot;&gt;&lt;/a&gt;查看和升级部署&lt;/h3&gt;&lt;p&gt;在任意节点运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get depolyment --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到当前的depolyment：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NAMESPACE     NAME           DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
kube-system   kube-dns       1         1         1            1           3h
sock-shop     carts          1         1         1            1           1h
sock-shop     carts-db       1         1         1            1           1h
sock-shop     catalogue      1         1         1            1           1h
sock-shop     catalogue-db   1         1         1            1           1h
sock-shop     front-end      1         1         1            1           1h
sock-shop     orders         1         1         1            1           1h
sock-shop     orders-db      1         1         1            1           1h
sock-shop     payment        1         1         1            1           1h
sock-shop     queue-master   1         1         1            1           1h
sock-shop     rabbitmq       1         1         1            1           1h
sock-shop     shipping       1         1         1            1           1h
sock-shop     user           1         1         1            1           1h
sock-shop     user-db        1         1         1            1           1h
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果我们想将其中一个服务横向拓展，比如payment服务，我们只需要：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl --namespace=sock-shop scale deployment payment --replicas 2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一个新的payment pod就被初始化，并被分配到合适的节点上运行。&lt;/p&gt;
&lt;p&gt;关于更多deployment相关的更新、回滚的信息请参考&lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&quot;一些思考&quot;&gt;&lt;a href=&quot;#一些思考&quot; class=&quot;headerlink&quot; title=&quot;一些思考&quot;&gt;&lt;/a&gt;一些思考&lt;/h3&gt;&lt;p&gt;Kubernetes相对来说还是很容易上手的一个容器集群管理方案。只要我们开发的时候是按cloud native的思路去写，部署就是一件非常简单的事情。可以说几个配置文件就搞定了。Kubernetes接管了部署的更新和回滚，让运维变的轻松、可靠。比如部署的时候不会在新容器没有启动之前就终止旧容器。如果部署出了问题需要回滚，也可以进行一键式的回滚。部署也可以暂定，继续。这样的一套方案相比于手动管理容器，简直就是鸟枪换炮式的升级。&lt;/p&gt;
&lt;p&gt;不仅仅是后端服务，我们的前端代码，也应该融入这套体系之中。前端作为一个单独的服务部署。这样可以更好的解耦。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文介绍了如何用Kubeadm 1.6版在Ubuntu 16.04系统上快速部署一个Kubernetes集群。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>基于Travis CI和Github的前端云构建</title>
    <link href="http://yoursite.com/2017/05/22/fe-cloud-building/"/>
    <id>http://yoursite.com/2017/05/22/fe-cloud-building/</id>
    <published>2017-05-22T08:04:00.000Z</published>
    <updated>2017-05-22T12:05:50.000Z</updated>
    
    <content type="html">&lt;p&gt;最近在思考团队里前端代码部署的问题，之前采用的方案是在本地构建，推到Github上一个专门放build后前端代码的仓库，然后Github的Webhook去触发后端的部署逻辑。代码就从这个仓库里拉取。&lt;/p&gt;
&lt;p&gt;这种方案看起来没什么大问题，但总觉得比较awkward。首先这套方案不够自动化，需要大量的人工操作。然后Github的Webhook其实并不是特别好用，如果后期要和我们内部的私有云平台对接起来，还要经过一些桥接才可以。&lt;/p&gt;
&lt;p&gt;本来呢，因为最近学了docker的缘故，我想写一个简单的Node服务，用来自动构建代码，然后通知服务端部署。每个应用就是一个单独的容器，这样环境就可以隔离。这个方案想来也不错。直到我仔细研究了一下Travis CI，才发现这个CI真是不简单。云端构建的任务用Travis CI就可以完美的实现。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;关于CI&quot;&gt;&lt;a href=&quot;#关于CI&quot; class=&quot;headerlink&quot; title=&quot;关于CI&quot;&gt;&lt;/a&gt;关于CI&lt;/h3&gt;&lt;p&gt;CI是持续集成的意思，持续集成里主要包括构建和测试代码。之前对Travis CI的印象是可以跑测试，仔细看了之后才发现Travis CI其实是一个云服务，提供了一个虚拟的Linux环境。你可以运行自定义的脚本。这个Linux环境的自由度还是非常大的。对于前端构建来说，Travis CI的网络环境可以快速安装npm包，这是一个非常大的优势。&lt;/p&gt;
&lt;h3 id=&quot;travis-yml文件&quot;&gt;&lt;a href=&quot;#travis-yml文件&quot; class=&quot;headerlink&quot; title=&quot;.travis.yml文件&quot;&gt;&lt;/a&gt;&lt;code&gt;.travis.yml&lt;/code&gt;文件&lt;/h3&gt;&lt;p&gt;Travis CI的配置文件其实就是让你写几个生命周期hook，内容一般是shell命令。比如&lt;code&gt;install&lt;/code&gt;这个hook里主要写一些安装依赖的逻辑，&lt;code&gt;script&lt;/code&gt;这个hook里主要是写测试和构建的逻辑，&lt;code&gt;deploy&lt;/code&gt;这个hook里是写部署的逻辑。另外这几个hook都有各自的&lt;code&gt;before&lt;/code&gt;和&lt;code&gt;after&lt;/code&gt;版本。总而言之自由度是很大的。&lt;/p&gt;
&lt;p&gt;一个示例&lt;code&gt;.travis.yml&lt;/code&gt;文件。虽然我们不能直接&lt;code&gt;.travis.yml&lt;/code&gt;中写逻辑，但我们可以运行任意的脚本，所以可以看出&lt;code&gt;.travis.yml&lt;/code&gt;的能力基本等价于shell脚本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;language: node_js
node_js:
  - &amp;quot;7&amp;quot;
install:
  - npm install
script:
  - npm run build
after_script:
  - tar -cvf bundle.tar ./dist
  - node deploy.js
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;云端构建&quot;&gt;&lt;a href=&quot;#云端构建&quot; class=&quot;headerlink&quot; title=&quot;云端构建&quot;&gt;&lt;/a&gt;云端构建&lt;/h3&gt;&lt;p&gt;在看过了上节的&lt;code&gt;.travis.yml&lt;/code&gt;文件之后，云端构建的大致逻辑应该已经非常清楚了。我们在Travis CI的虚拟机中安装node依赖，build代码，压缩代码，然后运行一个js脚本。这个脚本的内容就是将代码上传到CDN。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;deploy.js&lt;/code&gt;中还可以向后端的平台发送部署的请求，以达到自动部署的目的。如果后端是分布式的架构，向管理的节点发送请求即可。&lt;/p&gt;
&lt;h3 id=&quot;一些展望&quot;&gt;&lt;a href=&quot;#一些展望&quot; class=&quot;headerlink&quot; title=&quot;一些展望&quot;&gt;&lt;/a&gt;一些展望&lt;/h3&gt;&lt;p&gt;Travis CI的能力取决于这个虚拟机里提供了怎样的环境。Travis CI支持docker，因此我们可以用Travis CI进行docker镜像的构建和上传。Travis CI支持Nodejs，因此我们可以在虚拟机中安装hexo，进行博客的云端构建和自动部署。云端的构建，由于保证环境的隔离，因此稳定性会比本地高。以上都是Travis CI可能的用途。Travis CI作为一个云服务，在运维方面，还有无限的可能性等我们去探索&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近在思考团队里前端代码部署的问题，之前采用的方案是在本地构建，推到Github上一个专门放build后前端代码的仓库，然后Github的Webhook去触发后端的部署逻辑。代码就从这个仓库里拉取。&lt;/p&gt;
&lt;p&gt;这种方案看起来没什么大问题，但总觉得比较awkward。首先这套方案不够自动化，需要大量的人工操作。然后Github的Webhook其实并不是特别好用，如果后期要和我们内部的私有云平台对接起来，还要经过一些桥接才可以。&lt;/p&gt;
&lt;p&gt;本来呢，因为最近学了docker的缘故，我想写一个简单的Node服务，用来自动构建代码，然后通知服务端部署。每个应用就是一个单独的容器，这样环境就可以隔离。这个方案想来也不错。直到我仔细研究了一下Travis CI，才发现这个CI真是不简单。云端构建的任务用Travis CI就可以完美的实现。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>《编程语言实现模式》-阅读笔记</title>
    <link href="http://yoursite.com/2017/03/30/lip-notes/"/>
    <id>http://yoursite.com/2017/03/30/lip-notes/</id>
    <published>2017-03-30T13:34:59.000Z</published>
    <updated>2017-03-31T13:43:42.000Z</updated>
    
    <content type="html">&lt;p&gt;这里记录一下我阅读《编程语言实现模式》这本书的一些感受。一开始，对于编译原理，我的印象是这门课非常的艰深。在正式学习之前其实我已经看了很多编译相关的东西，比如V8，以及前端模板引擎等等。当时的感觉就是十分神奇。上了课之后首先接触的是形式文法、自动机和正规表达式等等。我的感觉就是，这些东西，是如何被前端大神们运用来写相关框架的呢，完全看不出门路嘛！&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;Jame Kyle的分享—&lt;a href=&quot;https://www.youtube.com/watch?v=Tar4WgAfMr4&amp;amp;t=9s&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《How to write a compiler》&lt;/a&gt;虽然很好，但是和有实际运用价值的编译技能还差的远呢。&lt;/p&gt;
&lt;p&gt;看龙书看的欲哭无泪，后来转而看《自制编程语言》，把crowbar的代码和流程大概了解了一下。最大的收获就是了解了yacc和lex。此前我对于Lexer和Parser还是抱有一定的恐惧心理的。&lt;/p&gt;
&lt;p&gt;最终让我认清门路的是戴嘉华的&lt;a href=&quot;https://github.com/livoras/blog/issues/14&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这篇博客&lt;/a&gt;。后来我去翻了翻编译原理课本，让我彻底搞清楚几个事情：&lt;/p&gt;
&lt;p&gt;第一点，虽然波神说的很对，最关键的是动手去写，但了解必要的理论是很重要的。问题就在于，编译这边理论很多，类似有限自动机和正规表达式的转换等等知识，后端代码生成和优化等等，会加重认知的负担。所以关键就是，对于一个普通的工程师来说，开发文本处理或者DSL相关程序需要掌握的编译原理知识是哪些。&lt;/p&gt;
&lt;p&gt;第二点，需要了解的概念有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主流编译器，解释器的流水线&lt;/li&gt;
&lt;li&gt;形式文法（EBNF）&lt;/li&gt;
&lt;li&gt;LL(1)文法，以及EBNF和LL(1)之间的转换&lt;/li&gt;
&lt;li&gt;根据LL(1)文法写递归下降Parser&lt;/li&gt;
&lt;li&gt;了解不同的AST类型，会设计AST&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;第二章-amp-amp-第三章&quot;&gt;&lt;a href=&quot;#第二章-amp-amp-第三章&quot; class=&quot;headerlink&quot; title=&quot;第二章&amp;amp;&amp;amp;第三章&quot;&gt;&lt;/a&gt;第二章&amp;amp;&amp;amp;第三章&lt;/h3&gt;&lt;p&gt;这章主要讲基于LL(1)的Tokenizing和Parsing。&lt;/p&gt;
&lt;p&gt;很妙的一点在于，在写关于形式文法的地方，这本书没有将BNF和乔姆斯基之类的科班教材中讲的，而是讲文法当成是一种DSL，这其实是非常正确的。Parser Generator的输入一般就是某种类似BNF的DSL。本书中的例子是ANTLR（一个parser generator）的DSL。&lt;/p&gt;
&lt;p&gt;这种务实的风格是延续在整个第二章中的，讲LL(1)的First和Follow集的时候，是这样说的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正规的定义中通常使用FIRST和FOLLOW两个运算来计算向前看集合，而实际使用时，这个问题可以等价于“哪些词法单元可能会出现在这个解析选项的开头”，这种思维方式更容易掌握，FIRST和严格定义就不在这里解释了，因为它比较复杂，而且这里也用不着其原理。如果有兴趣，可以在网上找到很多相关材料。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;First集合的数学定义是这样的：&lt;/p&gt;
&lt;p&gt;试想一下，如果初学者接触到的是严谨的数学定义，而不是一个相对直白的解释和代码演示的话，还是会有不少人打退堂鼓的。&lt;/p&gt;
&lt;p&gt;在实际的学习中，还是需要一些如上文中的“等价于”那样的解释。&lt;/p&gt;
&lt;p&gt;LL(1)的parser是最简单的。也是其余递归下降模式的基础框架。实现的方式就是为每一个规则写一个对应的函数，函数里按First集合来编写，规则里的运算符都可以转化为if或者while等到逻辑，如果是终结符就match，如果是非终结符就递归调用对应规则的函数。&lt;/p&gt;
&lt;p&gt;我看了Regularjs中parser的代码以及上文中vdom模板引擎的代码，结合书中的例子，大概搞懂了，接下来可以把书中的例子用js写一遍试试。&lt;/p&gt;
&lt;p&gt;第二章最后讲了LL(k)类型的parser。LL(k)就是任意k个token的lookup。LL(k)的需求，拿mcss来说，就是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mcss有点特殊，是个LL(n)的解释器，比如在设计中，函数在mcss是 First-class的，可以被返回或传入函数，并保持作用域信息，所以它是一种特殊的值，定义我设计与一般赋值一样。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$size = ($width, $height) { 
// ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里当你不读取到&lt;code&gt;{&lt;/code&gt; 是无法判断 &lt;code&gt;=&lt;/code&gt; 后面是函数定义 还是 普通css中的 compound&lt;br&gt;values  . 众所周知参数列表可能无限长，所以必须是LL(n)的Parser才能够解答。 &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有些语言语法里有很相似的语言结构，它们只在最后边才有区别。比如C++的函数定义和函数声明的前面都是一样的，直到;或{才能加以区别。&lt;/p&gt;
&lt;p&gt;所以想要能够写DSL解释器的话，LL(k)式的模式也是要懂的。LL(k)的问题就是要要预parse，如果条件满足，再真正parse一遍。这样带来的问题就是运行效率上比较慢。解决的办法是&lt;strong&gt;回溯法&lt;/strong&gt;，通过类似动态规划的空间换时间的方法，缓存parse的结果，加速parse的过程。&lt;/p&gt;
&lt;h3 id=&quot;第四章&quot;&gt;&lt;a href=&quot;#第四章&quot; class=&quot;headerlink&quot; title=&quot;第四章&quot;&gt;&lt;/a&gt;第四章&lt;/h3&gt;&lt;p&gt;Vue的AST。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这里记录一下我阅读《编程语言实现模式》这本书的一些感受。一开始，对于编译原理，我的印象是这门课非常的艰深。在正式学习之前其实我已经看了很多编译相关的东西，比如V8，以及前端模板引擎等等。当时的感觉就是十分神奇。上了课之后首先接触的是形式文法、自动机和正规表达式等等。我的感觉就是，这些东西，是如何被前端大神们运用来写相关框架的呢，完全看不出门路嘛！&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>crowbar-note-1</title>
    <link href="http://yoursite.com/2017/03/28/crowbar-note-1/"/>
    <id>http://yoursite.com/2017/03/28/crowbar-note-1/</id>
    <published>2017-03-28T10:52:55.000Z</published>
    <updated>2017-03-28T10:52:55.000Z</updated>
    
    <content type="html"></content>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>产品思维碎碎念</title>
    <link href="http://yoursite.com/2017/03/27/product-share-overview/"/>
    <id>http://yoursite.com/2017/03/27/product-share-overview/</id>
    <published>2017-03-27T04:35:28.000Z</published>
    <updated>2017-03-28T10:41:17.000Z</updated>
    
    <content type="html">&lt;p&gt;理论上来说，我们团队的成员都应该是对互联网有特殊热情的同学，或者是对手机里的各种App如数家珍，或者是对各大网站了如指掌。现在看来，之前有这方面的偏好，当然是好，但大多数人对互联网还没有那么深的认知。因此我觉得我们需要通过一系列的分享，来使得大家养成产品思维。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;互联网公司大局&quot;&gt;&lt;a href=&quot;#互联网公司大局&quot; class=&quot;headerlink&quot; title=&quot;互联网公司大局&quot;&gt;&lt;/a&gt;互联网公司大局&lt;/h3&gt;&lt;p&gt;截止目前（2017年3月28日），中国上市互联网公司的市值排名前五位的是：&lt;/p&gt;
&lt;p&gt;1 腾讯 2800亿美元&lt;br&gt;2 阿里巴巴 2668亿美元&lt;br&gt;3 百度 582亿美元&lt;br&gt;4 京东 445亿美元&lt;br&gt;5 网易 387亿美元  &lt;/p&gt;
&lt;p&gt;另外还有一些著名的上市互联网公司，比如微博、搜狐、携程等等。著名的非上市互联网公司有小米、美团和蚂蚁金服。独角兽公司（未上市，估值超过100亿美元的创业公司）有滴滴和今日头条。&lt;/p&gt;
&lt;p&gt;这些公司基本上占据了中国互联网的大部分版图。这些公司之间由合作也有竞争，并不是毫无关系的。腾讯和阿里两个巨无霸都想在竞争对手擅长的领域布局，比如腾讯投资了京东，在腾讯的应用中，会向京东导入流量，京东的支付也会优先支持微信支付。在O2O市场，阿里投资了饿了么，腾讯投资了美团大众点评。在社交方面，阿里投资了微博，目前微博盈利能力增强，但依然和阿里有着很深的合作关系。当然阿里也进行了很多直接的收购，比如优酷和UC等。&lt;/p&gt;
&lt;p&gt;大家要养成的能力就是，看到一家公司时，要能够说出这家公司的主流产品和所属的领域。比如阿里，大家可能觉得主要是电商，但其实阿里目前发展的比较快的还有云计算业务。了解一家公司服务的布局，最好的办法就是看公司的财报。比如大家如果看了网易的财报，就会很轻松的发现网易其实是一家游戏公司，发展的比较快的是跨境电商业务，其他就是广告收入，而其他的众多产品，在营收上贡献不大。公司毕竟是以盈利为目的的，因此盈利多的领域基本就可以认为是公司会主力经营的业务。后面我们会专门做一个《如何解读互联网公司财报》的分享。&lt;/p&gt;
&lt;p&gt;对国外的互联网公司也要了解。虽然因为国内的政治环境、基础设施、用户群体等等原因，国内的互联网世界和国外有很多不同之处，但不可否认的是国内互联网创业的模式大部分还是借鉴国外的。比如Uber和滴滴，Twitter和微博等等。国外互联网公司，主要是美国，主要就是Google、Facebook、Aamazon、Linkedin几家大公司和Twitter、Uber、Airbnb等等有名的创业公司。国外的互联网，在技术、商业、设计和产品上都是领先的，为了拓展自己的视野，大家就更要关注了。&lt;/p&gt;
&lt;h3 id=&quot;产品的分类&quot;&gt;&lt;a href=&quot;#产品的分类&quot; class=&quot;headerlink&quot; title=&quot;产品的分类&quot;&gt;&lt;/a&gt;产品的分类&lt;/h3&gt;&lt;p&gt;产品分类其实是一门玄学。因为分类的标准有很多种。你可以按产品的功能来分，那么自拍类产品应该属于摄影产品。但App Store里自拍相机类产品是分在社交这个分类下的，因为自拍产品最终产出的目的是为了在社交网络上展示。这是自拍产品的特有的属性。&lt;/p&gt;
&lt;p&gt;所以分类这个，因人而异。大家只要在自己脑海里建立一个体系，遇到产品能顺利的归类，就可以了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;社交&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主流的社交应用，包括很多类别，即时通讯类的主要就是微信和QQ，钉钉这样的办公应用也是这个类别。匿名社交的比如陌陌。&lt;/p&gt;
&lt;p&gt;早期的博客和论坛，有很强的社交属性，也有一定的内容属性，我们可以叫社区类产品，暂且归类到社交类下。如果你用论坛但是只是默默潜水，那就偏内容属性，所以这个还要看用户的使用。&lt;/p&gt;
&lt;p&gt;互联网发展早期的博客的论坛现在已经进化出了很多的形式，比如微博和贴吧。社交作为一种功能，现在也被广泛的集成到各种“主业”不是社交的应用中，比如天气App里面可以有一个简单的社区。&lt;/p&gt;
&lt;p&gt;因此社交类应用是指，主要功能是社交的应用。其他应用也可以集成社交功能，从而拥有社交属性，比如支付宝，但这样没法改变一个应用的本质属性。大家在分析App的时候，要注意这一点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;电商&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;电商应用的特征相对来说比较鲜明，当然里面也可以分为B2B的比如阿里巴巴，B2C的比如天猫和京东，C2C的比如淘宝和闲鱼。电商领域按售卖商品的类别，也可以细分为，跨境电商（考拉海购、小红书）、美妆电商（蘑菇街、美丽说、聚美优品）、生鲜电商等等各种细分的市场。我们一般把这些App成为垂直领域应用。意思就是这类App的目标用户只是针对某一类人。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;O2O&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;O2O（Online To Offline）类的应用，其实应该是电商下的一个子类，和B2C和C2C并列。但由于这块市场这几年的增长非常快，潜力很大，因此现在我们一般单独拿出来讨论。&lt;/p&gt;
&lt;p&gt;O2O主要涉及的是人的衣食住行以及吃喝玩乐，比如各种外卖（饿了么）、团购（美团大众点评）、出行（滴滴、Ofo）等等。将线下的生意和线上的在线支付和用户体系等等结合起来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摄影&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;之前说了，自拍应用在App Store中是放在社交类别下的。不管如何，摄影类的应用在手机自带相机质量越来越好，社交应用非常普及的今天，需求是非常大的。看一下图片社交应用Instagram的情况，就可以知道图片社交是目前社交网络中最主流的一种形式。&lt;/p&gt;
&lt;p&gt;这个市场的特点是基本没有一款应用能占据大部分份额，各家都有机会。这可能是因为用户对摄影的应用有着个性化的需求，也可能是因为大公司没有进入这一市场的缘故。国内在这方面做的大的是美图，现在已经在香港上市了。这一类的应用要发展，纯粹的工具属性是不够的，一般都需要借助社交平台之力。&lt;/p&gt;
&lt;p&gt;这里要提一下的是最近非常火的短视频应用。短视频应用其实算是一种视频社交应用，放到社交分类下讨论也是可以的，比如秒拍，快手等等。自建社区毕竟是一种高风险的决策，秒拍和微博合作，因此秒拍会的内容会嵌入微博的Feed流，借助了社交平台的力量，给秒拍带来了曝光。关于短视频应用，我们今后也会进行专题的讨论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;效率工具&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;效率类应用有笔记应用、Office类应用、todo类应用、日程规划应用、日记应用，还有一些番茄钟应用，用来协助用户提高工作效率。&lt;br&gt;其他的工具类应用则是五花八门了，天气应用，记账应用等等，这些在App Store里面是有专门的类别的。&lt;/p&gt;
&lt;p&gt;Workflow和Pin这种比较高端的效率App，一般都是由个人开发者开发，可以说是应用商店中的一股清流。这样的App也许是比较适合我们去尝试开发的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;旅行&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;旅行这个分类主要是从市场来看的，旅行类应用瞄准的是人们出行时的需求，机票、酒店、景区门票、攻略、行程安排等等。&lt;/p&gt;
&lt;p&gt;主要的玩家是携程去哪儿。最近Airbnb进入中国市场，Airbnb主要的竞争对手是酒店，Airbnb今后的目标是进军整个旅行市场。专注于旅行本身的有蚂蜂窝、蝉游记、面包旅行、氢气球旅行等等。当然携程这样的巨无霸App中也是集成了旅行相关的功能的。&lt;/p&gt;
&lt;p&gt;综上，旅行市场看起来还是比较简单的，酒店机票业务实际也属于O2O的范畴。最近Airbnb的兴起，应该会为这个市场带来一些变化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;教育&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在线教育这个市场，是近几年随着MOOC的发展而发展的一个市场。这个市场可以分为几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;职业培训（网易云课堂，特别是里面的微专业）&lt;/li&gt;
&lt;li&gt;K12教育（比如百度作业帮、小猿搜题）&lt;/li&gt;
&lt;li&gt;资格培训（各种托福雅思公务员驾照App，比如猿题库）&lt;/li&gt;
&lt;li&gt;MOOC（国内的有学堂在线、中国大学MOOC，当然也包括Coursera和edX等等老玩家）&lt;/li&gt;
&lt;li&gt;科教类（比如榫卯，烧杯以及各种以交互式的科普知识为目的的App）&lt;/li&gt;
&lt;li&gt;英语类（这类应用也属于广义的工具类应用，背单词是为考试服务的，因此也可以说是属于前面提到的几种类别，但因为需求最大，因此可以单独讨论，主流的比如英语流利说、扇贝单词和百词斩）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有部分应用会同时做职业培训、K12、K17（高考）等等方面，比如有道精品课。&lt;/p&gt;
&lt;p&gt;目前中国中产阶级越来越多，消费升级表现之一就是对于教育的投资。线下和线上的教育市场都会被拉动起来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;内容类&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;视频/音乐类&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;视频和音乐类应用的历史很悠久了，这里说的是提供视频和音乐服务的产品。视频方面有优酷土豆、PPTV、乐视、搜狐视频等。音乐方面有QQ音乐、网易云音乐和虾米音乐。&lt;/p&gt;
&lt;p&gt;互联网时代，中国的视频和音乐市场最关键是就是版权之争。10年前版权宽松的时代已经一去不复返了。现在的视频网站的资源主要来自版权的购买。&lt;/p&gt;
&lt;p&gt;除此之外，自制内容也是很火的。国外这方面最典型的就是Netflix。国内比较典型的就是乐视自制的《太子妃升职记》，还有之前在优酷上火的万合天宜系列的网剧。目前国内比较流行的模式就是拿一个IP（知识产权，比如畅销小说）改编网剧（因为国内IP不够优质，最近开始改编日剧，不过质量实在是惨不忍睹）。个人觉得目前来说国内的文化产业还是比较浮躁的，比较着急赚钱变现。&lt;/p&gt;
&lt;p&gt;音乐市场上，网易云音乐也希望能挖掘草根音乐人并与其达成合作，在残酷的版权竞争之外另辟蹊径。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;资讯类&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;资讯类包括了老牌门户网站新浪网易搜狐的新闻客户端，以及新秀今日头条和UC等。今日头条和主打的是个性化的推荐，UC则是用其独特的编辑风格，吸引了很多人的眼球。&lt;/p&gt;
&lt;p&gt;也有好奇心日报和一个这种垂直类的内容提供商。好奇心日报专注于报道互联网、快时尚、消费电子等行业的新闻，同时也有着独特的互动栏目，主要瞄准的是年轻人生活中的种种。一个可以理解为一个平台，培养一些在网络上受欢迎的“网红”作家。&lt;/p&gt;
&lt;p&gt;P.S. 网红这个词，比如网红作家，网红剧等，基本可以等同于，在90后左右的年轻人为主的社交网络中被广泛传播和讨论，有一定人气的意思。不仅仅是Papi酱这种传统意义的网红，知乎大V，甚至支付宝的微信公众号，只要是在社交网络上有很多Follower的，都称为网红。&lt;/p&gt;
&lt;p&gt;P.P.S 好奇心有一个栏目叫“好奇心词典”，专门解释在当前时代语境下的新鲜词汇。上面的解释大概就是这个模式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;游戏&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;游戏就不用多说了。国内手机游戏的巨头是腾讯，第二的是网易，但网易和腾讯之间的差距还是非常明显的。腾讯的游戏依托自身的流量平台，以及相对更平民化的研发策略，占据了大部分的市场。游戏这个市场的特点就是寡头瓜分市场，小公司很难生存。利润上来说游戏是互联网行业中最高的之一。&lt;/p&gt;
&lt;h3 id=&quot;产品的盈利模式&quot;&gt;&lt;a href=&quot;#产品的盈利模式&quot; class=&quot;headerlink&quot; title=&quot;产品的盈利模式&quot;&gt;&lt;/a&gt;产品的盈利模式&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;广告&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;广告是历史最悠久的互联网产品盈利模式了。互联网开山鼻祖Google一开始就是靠广告作为收入来源的。&lt;/p&gt;
&lt;p&gt;广告一般嵌入在应用的展示位中，按点击来进行收费。&lt;/p&gt;
&lt;p&gt;Google和Facebook这种掌握了大量流量的公司，会专门有部门来负责广告的投放，也会提供工具来让广告主对自己的广告进行管理和数据分析。&lt;/p&gt;
&lt;p&gt;甚至有Google Ads这种产品，提供给你一个广告平台，你把代码放到自己的产品中，通过用户的点击，获得收入。广告主只需要和Google Ads进行接触。&lt;/p&gt;
&lt;p&gt;除了搜索引擎和社交应用，内容类产品和工具类产品也可以用广告进行变现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;电商&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;电商是最容易理解的，因为电商的盈利模式和线下的零售业是很相似的。&lt;/p&gt;
&lt;p&gt;B2C的电商比如京东，可以从自营商品的销售中直接获利，而淘宝这样的C2C平台，是通过向店主收取服务费用进行盈利的，O2O的盈利模式也是一样的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;内购&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;游戏的内购，售卖的是虚拟道具。&lt;/p&gt;
&lt;p&gt;工具类产品的内购，售卖的是高级功能。本质上是将服务标价售卖。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;知识变现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;知识变现是最近比较火的一种新的盈利模式，当然本质上还是一种收费的服务。&lt;/p&gt;
&lt;p&gt;常见的知识变现有打赏、收费提问、Live、收费群等等。&lt;/p&gt;
&lt;p&gt;知乎Live售卖的是讲座的门票，小密圈售卖的是和圈主交流的机会。知识变现的本质是提供服务，通过这个服务，用户可以学习到知识。其实和我们熟悉的收费培训道理是一样的，只不过目前的知识变现侧重于碎片化的分享和交流，而不是体系化的培训。&lt;/p&gt;
&lt;h3 id=&quot;结语&quot;&gt;&lt;a href=&quot;#结语&quot; class=&quot;headerlink&quot; title=&quot;结语&quot;&gt;&lt;/a&gt;结语&lt;/h3&gt;&lt;p&gt;以上，总结了我个人认为对产品思维入门比较重要的三个点。还有很多地方没有谈到，比如在产品分类时没有提到直播应用（其实是直播应用比较复杂，有点难分类）。这是我心目中一个互联网从业者应该有的认知，在这个基础上，我们才能对具体的产品，具体的行业，进行更深入的研究和思考。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;理论上来说，我们团队的成员都应该是对互联网有特殊热情的同学，或者是对手机里的各种App如数家珍，或者是对各大网站了如指掌。现在看来，之前有这方面的偏好，当然是好，但大多数人对互联网还没有那么深的认知。因此我觉得我们需要通过一系列的分享，来使得大家养成产品思维。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>终端工具翻墙不完全指南</title>
    <link href="http://yoursite.com/2017/03/26/proxy-for-terminal/"/>
    <id>http://yoursite.com/2017/03/26/proxy-for-terminal/</id>
    <published>2017-03-26T14:10:22.000Z</published>
    <updated>2017-03-28T11:24:19.000Z</updated>
    
    <content type="html">&lt;p&gt;写这篇文章的动机是之前Github曾经短暂的被墙过，这样的话，如果终端没有翻墙，那就没法推代码了。之后几天国内访问Github也一直很慢，于是尝试了给终端翻墙。网上的文章很多，但没有特别满意的，因此决定自己写一篇。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;说是不完全指南，因为我这篇文章针对的是macOS下使用Shadowsocks翻墙的用户来说的。当然其他其他的系统，如果是使用Shadowsocks，道理应该差不多。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预备工作&lt;/strong&gt;：安装Shadowsocks客户端，配置好服务器。搞清楚Shadowsocks在本地运行的端口，一般是1080或者1086。&lt;/p&gt;
&lt;h3 id=&quot;Homebrew翻墙&quot;&gt;&lt;a href=&quot;#Homebrew翻墙&quot; class=&quot;headerlink&quot; title=&quot;Homebrew翻墙&quot;&gt;&lt;/a&gt;Homebrew翻墙&lt;/h3&gt;&lt;p&gt;macOS下装软件要用Homebrew，但Homebrew的源在国外，国内用是很慢的。首先我们要让Homebrew翻墙，才能顺利的往下进行其他工作。&lt;/p&gt;
&lt;p&gt;Homebrew下载用的是curl。因此我们只要配置curl使用代理就可以了。&lt;/p&gt;
&lt;p&gt;curl的代理在&lt;code&gt;~/.curlrc&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们在这里加一行：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;socks5 = “127.0.0.1:1080”&lt;/code&gt; &lt;/p&gt;
&lt;p&gt;1080是之前说的Shadowsocks的本地端口，下文就不再说明了。&lt;/p&gt;
&lt;h3 id=&quot;安装Polipo&quot;&gt;&lt;a href=&quot;#安装Polipo&quot; class=&quot;headerlink&quot; title=&quot;安装Polipo&quot;&gt;&lt;/a&gt;安装Polipo&lt;/h3&gt;&lt;p&gt;&lt;code&gt;brew install polipo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;装好后记得把之前加上的curl的代理删掉。&lt;/p&gt;
&lt;p&gt;然后配置polipo，修改&lt;code&gt;/usr/local/opt/polipo/homebrew.mxcl.polipo.plist&lt;/code&gt;设置&lt;code&gt;parentProxy&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-//Apple//DTD PLIST 1.0//EN&amp;quot; &amp;quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&amp;quot;&amp;gt;
&amp;lt;plist version=&amp;quot;1.0&amp;quot;&amp;gt;
  &amp;lt;dict&amp;gt;
    &amp;lt;key&amp;gt;Label&amp;lt;/key&amp;gt;
    &amp;lt;string&amp;gt;homebrew.mxcl.polipo&amp;lt;/string&amp;gt;
    &amp;lt;key&amp;gt;RunAtLoad&amp;lt;/key&amp;gt;
    &amp;lt;true/&amp;gt;
    &amp;lt;key&amp;gt;KeepAlive&amp;lt;/key&amp;gt;
    &amp;lt;true/&amp;gt;
    &amp;lt;key&amp;gt;ProgramArguments&amp;lt;/key&amp;gt;
    &amp;lt;array&amp;gt;
        &amp;lt;string&amp;gt;/usr/local/opt/polipo/bin/polipo&amp;lt;/string&amp;gt;
        &amp;lt;string&amp;gt;socksParentProxy=localhost:1080&amp;lt;/string&amp;gt;
    &amp;lt;/array&amp;gt;
    &amp;lt;!-- Set `ulimit -n 20480`. The default OS X limit is 256, that&amp;#39;s
         not enough for Polipo (displays &amp;#39;too many files open&amp;#39; errors).
         It seems like you have no reason to lower this limit
         (and unlikely will want to raise it). --&amp;gt;
    &amp;lt;key&amp;gt;SoftResourceLimits&amp;lt;/key&amp;gt;
    &amp;lt;dict&amp;gt;
      &amp;lt;key&amp;gt;NumberOfFiles&amp;lt;/key&amp;gt;
      &amp;lt;integer&amp;gt;20480&amp;lt;/integer&amp;gt;
    &amp;lt;/dict&amp;gt;
  &amp;lt;/dict&amp;gt;
&amp;lt;/plist&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;增加了&lt;code&gt;&amp;lt;string&amp;gt;socksParentProxy=localhost:1080&amp;lt;/string&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然后配置polipo开机自启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;launchctl unload ~/Library/LaunchAgents/homebrew.mxcl.polipo.plist
launchctl load ~/Library/LaunchAgents/homebrew.mxcl.polipo.plist
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样polipo就设置完成了，polipo的http代理默认在&lt;code&gt;localhost:8123&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;NPM翻墙&quot;&gt;&lt;a href=&quot;#NPM翻墙&quot; class=&quot;headerlink&quot; title=&quot;NPM翻墙&quot;&gt;&lt;/a&gt;NPM翻墙&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;npm config set proxy http://127.0.01:8123
npm config set https-proxy http://127.0.0.1:8123
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Git翻墙&quot;&gt;&lt;a href=&quot;#Git翻墙&quot; class=&quot;headerlink&quot; title=&quot;Git翻墙&quot;&gt;&lt;/a&gt;Git翻墙&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;git config --global http.proxy http://localhost:8123
git config --global https.proxy http://localhost:8123
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以用&lt;code&gt;git config --list&lt;/code&gt;查看是否设置成功。&lt;/p&gt;
&lt;h3 id=&quot;结语&quot;&gt;&lt;a href=&quot;#结语&quot; class=&quot;headerlink&quot; title=&quot;结语&quot;&gt;&lt;/a&gt;结语&lt;/h3&gt;&lt;p&gt;上面讲了NPM和Git的代理。其他工具的话，道理是一样的，如果直接支持socks5代理，那是最好。一般都支持Http代理，比如Genymotion。遇到工具网络请求很慢的情况，设置具体工具的代理就可以了。我之前以为在终端设置&lt;code&gt;export http_proxy=http://localhost:8123&lt;/code&gt;就可以。结果并不是这样，并不是所有的工具都走这个终端的代理。&lt;/p&gt;
&lt;p&gt;终端也有了代理，从此我们就可以愉快的进行开发了。妈妈再也不用担心我的cnpm出什么问题了，推代码到Github的心情也更轻松了，连更新博客都勤快了很多呢！&lt;/p&gt;
&lt;h3 id=&quot;参考链接&quot;&gt;&lt;a href=&quot;#参考链接&quot; class=&quot;headerlink&quot; title=&quot;参考链接&quot;&gt;&lt;/a&gt;参考链接&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://droidyue.com/blog/2016/04/04/set-shadowsocks-proxy-for-terminal/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;为终端设置Shadowsocks代理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;写这篇文章的动机是之前Github曾经短暂的被墙过，这样的话，如果终端没有翻墙，那就没法推代码了。之后几天国内访问Github也一直很慢，于是尝试了给终端翻墙。网上的文章很多，但没有特别满意的，因此决定自己写一篇。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>聊聊云计算</title>
    <link href="http://yoursite.com/2017/03/21/about-cloud/"/>
    <id>http://yoursite.com/2017/03/21/about-cloud/</id>
    <published>2017-03-21T07:17:18.000Z</published>
    <updated>2017-03-24T14:00:46.000Z</updated>
    
    <content type="html">&lt;p&gt;这篇文章主要是写我对团队在云计算方向上现状的一些思考。并没有什么关于云计算的干货，毕竟我在这方面还需要大量的实践才能有足够的发言权。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;IaaS&quot;&gt;&lt;a href=&quot;#IaaS&quot; class=&quot;headerlink&quot; title=&quot;IaaS&quot;&gt;&lt;/a&gt;IaaS&lt;/h3&gt;&lt;p&gt;我们用的最多的就是IaaS（Infrastructure as a Service）了。阿里云中的ECS和RDS就是典型的IaaS，另外阿里云OSS或者亚马逊S3那样的存储服务也是。&lt;/p&gt;
&lt;p&gt;IaaS，简单的理解就是，将计算资源，作为一种基础设施，提供给用户。用户可以像消费水和电一样来按需进行使用计算资源。&lt;/p&gt;
&lt;p&gt;IaaS是基于虚拟化和分布式技术来提供服务的。在云计算之前的时代，公司的网站是部署在一台台实体的服务器上的。一般来说，一家小公司，可能只需要一两台服务器就可以满足业务需求了。有服务器也自然有传统的运维人员，这种工程师精通硬件、网络和安全方面的知识，全权负责机房里服务器的正常运转和性能优化。&lt;/p&gt;
&lt;p&gt;然而维护一台实体服务器的成本是很高的，需要雇佣一个服务器运维人员，需要付出电费和购置服务器的费用，以及架设网络的成本。&lt;/p&gt;
&lt;p&gt;大公司会建立数据中心，其实就是有着大量服务器的厂房。大公司有着足够的人力去维护自有的服务器。&lt;/p&gt;
&lt;p&gt;在那个年代，后端工程师部署服务是直接部署在实体机器上的，在部署时需要和运维人员确定服务器的环境等，经常会有一些沟通上的问题。&lt;/p&gt;
&lt;p&gt;还有一个问题则是，那时的网站是很难动态伸缩的，一个应用往往同时部署在多台服务器上。然而，要使得一个服务能抗下更多的流量，就需要更多的服务器，如果不能在短时间内配置好新服务器，网站在压力之下往往会崩溃。&lt;/p&gt;
&lt;p&gt;云计算对于小公司的好处在于，消除了维护实体服务器需要的各种繁杂的成本。维护实体服务器的责任交给了云服务厂商。小公司只需要购买服务就可以。&lt;/p&gt;
&lt;p&gt;对于大公司来说，云计算可以动态扩容，一键部署，使得应用在压力之下可以弹性伸缩。将计算资源利用率最大化。&lt;/p&gt;
&lt;p&gt;我们使用的ECS其实并不对应一台实体的服务器，但我们在使用的时候可以将ECS当成一台完整的服务器来使用。这就是虚拟化技术的好处。我们可以按需使用计算资源（一台实体服务器往往是8核或者16核CPU这样的配置，我们用不到这么多的CPU）。&lt;/p&gt;
&lt;p&gt;我们也不用担心服务器会被攻击或者数据丢失。ECS提供了自动快照的服务。&lt;/p&gt;
&lt;p&gt;在我看来云计算是对计算资源做的一次抽象，将后端应用和实体的服务器硬件资源隔离了。使得基于硬件的备份和维护这些事情抽象出来，开发人员只用关注应用层面的逻辑就可以了。&lt;/p&gt;
&lt;p&gt;而RDS和OSS这些服务，也是同理。我们不用关心存储具体的物理位置在哪台服务器上，只需要调用这个服务就可以了。&lt;/p&gt;
&lt;p&gt;而RDS、ECS和OSS三个服务的分离，也是一种抽象。ECS只关心业务逻辑，OSS和RDS只关心数据存储。只有无状态的服务才能轻松实现横向的拓展。如果ECS上的应用和数据库一起部署的话，会对应用的可拓展性造成影响。&lt;/p&gt;
&lt;p&gt;具体说到我们团队，ECS和RDS我们使用阿里云的服务。对象存储我们则打算自建。一个是利用手上的物理服务器，降低一些成本，还有一个就是研究一下分布式存储相关的技术，加深团队在云计算方面的技术深度（Ceph这个开源的分布式存储框架已经非常强大了，我们目前打算先尝试Ceph）。&lt;/p&gt;
&lt;h3 id=&quot;PaaS&quot;&gt;&lt;a href=&quot;#PaaS&quot; class=&quot;headerlink&quot; title=&quot;PaaS&quot;&gt;&lt;/a&gt;PaaS&lt;/h3&gt;&lt;p&gt;PaaS（Platform as a Service）方面的服务的代表就是Google的App Engine（以下简称GAE）。在App Engine中你只需要写业务逻辑，不需要关心服务和数据的部署。GAE号称会根据你应用的流量实时拓展服务的部署。&lt;/p&gt;
&lt;p&gt;GAE带来的其实是更高的一层抽象。将基础设施的使用也屏蔽了。其实这个就将当于大家写了一个Flask应用，push到Github，写一个简单的配置文件，然后就可以访问了。你不用关心Nginx的配置，也不用关心部署多个实例以及均衡负载这些问题。It just works。&lt;/p&gt;
&lt;p&gt;另外你还可以在控制台用GUI控制你的应用，以及读取监控数据等等。&lt;/p&gt;
&lt;p&gt;我对此是非常感兴趣的，特别是Docker的出现，使得自动化的部署，环境的隔离以及标准化变成了一件比较简单的事情。&lt;/p&gt;
&lt;p&gt;我构想中的Muxi App Engine（以下简称MAE）是这样的：&lt;/p&gt;
&lt;p&gt;支持Python和Node两种环境，会根据ECS上的实时部署情况，自动将容器实例部署在最合适的ECS上，并且在流量变大时会自动伸缩。在MAE控制台上可以看到常规的Log统计。可以在MAE上用配置中的Git仓库和分支进行一键部署，前端代码也是一样的。&lt;/p&gt;
&lt;p&gt;MAE的目标是将一些应用公共的流程尽量标准化，目前我们的自动化部署还是需要自己写Webhook脚本的。统计的话也是需要手动去配置的。Nginx相关的一些配置也是手动的。&lt;/p&gt;
&lt;p&gt;MAE是一个单独的服务，部署在一台服务器上。MAE对可支配的ECS都有着记录，并且在对应的ECS上都运行着守护进程，和MAE服务通信。&lt;/p&gt;
&lt;p&gt;MAE时代的开发和目前并没有太大的区别，只是每个应用需要有一个MAE的配置文件，里面写了域名、Github仓库、Docker环境等等信息。&lt;/p&gt;
&lt;p&gt;我们在MAE上新建一个应用，然后点击部署，就可以部署了。&lt;/p&gt;
&lt;p&gt;对于我们的大部分，自己托管数据的应用（相比匣子这样需要实时爬取的应用），比如学而、桂声等等，MAE这样的模式可以很好的讲平台层的运维工作简单化、标准化。&lt;/p&gt;
&lt;p&gt;当然MAE如何和微服务结合这个也是一个问题，目前的应用其实是有分拆成服务的空间的，这样的话MAE其实应该是以服务为单位的。&lt;/p&gt;
&lt;h3 id=&quot;SaaS&quot;&gt;&lt;a href=&quot;#SaaS&quot; class=&quot;headerlink&quot; title=&quot;SaaS&quot;&gt;&lt;/a&gt;SaaS&lt;/h3&gt;&lt;p&gt;SaaS（Software as a Service）离普通用户最近的云计算形式。我们用Tower、百度云盘、石墨文档这些，都属于SaaS。&lt;/p&gt;
&lt;p&gt;我们日后推出的服务，比如云简历，或者是其他工具类的应用，都是以软件形式向用户提供了某种基于云计算的服务。&lt;/p&gt;
&lt;h3 id=&quot;结语&quot;&gt;&lt;a href=&quot;#结语&quot; class=&quot;headerlink&quot; title=&quot;结语&quot;&gt;&lt;/a&gt;结语&lt;/h3&gt;&lt;p&gt;基于综合的考虑，我认为云计算是目前最有用，也是最触手可及的前沿技术。&lt;/p&gt;
&lt;p&gt;目前后端技术这边，机器学习/人工智能、云计算、大数据，是几个比较火的领域。当然这几个领域目前有融合的趋势。&lt;/p&gt;
&lt;p&gt;对于我们来说，要构筑我们的技术壁垒，云计算是最好的突破口。在知识水平、业务体量等种种的不利因素下，云计算是可以深挖，并且&lt;strong&gt;实践&lt;/strong&gt;的一个领域。&lt;/p&gt;
&lt;p&gt;无论是对于我们内部服务的支持，或者是对于个人技术能力，就业市场竞争力的提升来说，这都是一个最优的方向。&lt;/p&gt;
&lt;p&gt;所以在接下来的很长一段时间，我希望大家能一起努力，在云计算上，达到一个不算太寒碜的水准。这需要所有同学的支持，包括前端、客户端和设计组的同学，因为转向云计算会对目前的开发流程产生很大的影响。然后在UI和品牌方面，自然也需要前端和设计师的配合。PM同学也需要理解这个战略。&lt;/p&gt;
&lt;p&gt;就写这么多吧。祝一切顺利。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章主要是写我对团队在云计算方向上现状的一些思考。并没有什么关于云计算的干货，毕竟我在这方面还需要大量的实践才能有足够的发言权。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>我的2016</title>
    <link href="http://yoursite.com/2016/12/26/my2016/"/>
    <id>http://yoursite.com/2016/12/26/my2016/</id>
    <published>2016-12-26T06:58:46.000Z</published>
    <updated>2017-01-01T08:40:08.000Z</updated>
    
    <content type="html">&lt;p&gt;2016对我来说当然是很神奇也很重要的一年。团队的进步很快，华师匣子终于上线。我也顺利的找到的工作。&lt;/p&gt;
&lt;p&gt;回想这一年，对于上半年的事情，现在只残存着一些依稀的回忆了。这一年我对前端的理解，有了很大的变化，这其实是一个日积月累的过程。所以Tower里的进度，对于我来说，就是一个非常好的备忘录。自己的学习的历程，在里面可以看到一个很清晰的脉络。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;回看我的进度，1月的时候我开始写简历生成器和学而的后台，那段时间我对于前端工程化很痴迷。把Dan Abramov的视频看了很多遍。主要用React写东西。&lt;/p&gt;
&lt;p&gt;寒假主要是写学而后台，写个人主页，看YDKJS和《JavaScript忍者秘籍》。寒假里面我发现了大批的电子书，对于JS的语言有了更深入的了解。也开始对公司和业务有一些自己的思考。我对于浏览器的探索也在那个时候开始了，主要是看了Mozilla工程师写的自制浏览器那一系列的博客。从进度上来看，那个时候真是热火朝天的学学学，新事物扑面而来，整个人还是很有干劲的。&lt;/p&gt;
&lt;p&gt;在找工作这问题上，当时我还是很没有底的。&lt;/p&gt;
&lt;p&gt;那段时间还在刷PAT，打算去参加春季的考试，但最后还是没有去，觉得没有准备好。&lt;/p&gt;
&lt;p&gt;接下来就是3月了，开学了，要上课要辅修，事情很多。学习的进度就没有那么快了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;3.14&lt;/p&gt;
&lt;p&gt;投简历+学而+团队+i华大 = 爆炸&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;后来就是接触简单的算法，去网易面试。&lt;/p&gt;
&lt;p&gt;4月学校的出版社实习期间开始看jQuery源码。&lt;/p&gt;
&lt;h3 id=&quot;找工作&quot;&gt;&lt;a href=&quot;#找工作&quot; class=&quot;headerlink&quot; title=&quot;找工作&quot;&gt;&lt;/a&gt;找工作&lt;/h3&gt;&lt;p&gt;3月开始面试，第一个面的是阿里，二面挂了，一些很简单的问题没有准备，比如正则和简单的DOM API。后来面了饿了么，过了。在面试网易的时候，饿了么表示如果不能确定offer那就算了，于是我就在没有保底offer的情况下，去网易面试了。&lt;/p&gt;
&lt;p&gt;去网易的面试算是我第一次很正式的面试。总的来说，其实很平稳，但对我来说，记忆犹新。最让我感到印象深刻的还是面试期间那种忐忑的心情。好在最后一切顺利。现在看来，觉得还是挺幸福的。&lt;/p&gt;
&lt;h3 id=&quot;团队&quot;&gt;&lt;a href=&quot;#团队&quot; class=&quot;headerlink&quot; title=&quot;团队&quot;&gt;&lt;/a&gt;团队&lt;/h3&gt;&lt;p&gt;5月份的时候，团队出了大事，主要就是工作室要装修。领导为了面子工程，把我们的304改成了展示厅。对当时的我来说这真是和晴天霹雳一般。&lt;/p&gt;
&lt;p&gt;匆忙的租了房子，其实最后也没起多大作用。这次搬家对我们来说，意味着很多。和过去告别。真正的成长，担起团队的责任。&lt;/p&gt;
&lt;p&gt;这个时候，我们确立了核心成员的概念。一个团队，只需要核心成员，不是核心成员的都可以离开了。一个团队的人数并不是关键，团队的凝聚力和战斗力才是最关键的。&lt;/p&gt;
&lt;p&gt;其他的话，其实从我进度里看，关于团队的很多。大部分都是一些消极的抱怨，还有一些思考。暑假的时候，和大家远程交流，开会。很困难，到最后其实很有多的摩擦。但无论如何，事情都算是过去了。&lt;/p&gt;
&lt;p&gt;在12月的时候，我决定从团队的日常事务中抽身，专心做自己的事情。经过这段时间来看，团队是可以自己正常运转的。很开心啊，像是自己的孩子长大了一样。&lt;/p&gt;
&lt;h3 id=&quot;在网易的三个月&quot;&gt;&lt;a href=&quot;#在网易的三个月&quot; class=&quot;headerlink&quot; title=&quot;在网易的三个月&quot;&gt;&lt;/a&gt;在网易的三个月&lt;/h3&gt;&lt;p&gt;在网易的实习经历，在业务上是比较平淡的。做的有数这个平台的确是很复杂的，但我加入的时候这个平台已经比较成熟了，所以也没有太多挑战性的东西。没有见证初期的技术选型和架构的选择，所以在这方面没有学到太多想学到的。在大公司，技术选型这个是一个多方博弈的结果，要考虑公司本身的基础设施，并不是简单的引入开源项目就可以的。&lt;/p&gt;
&lt;p&gt;在网易主要是写了一个Regular-devtool，其他的话就写了一些简单的业务。生活的话，可以说还是非常幸福的。环境这些都挺不错的。现在想来还挺怀念呢。&lt;/p&gt;
&lt;h3 id=&quot;华师匣子&quot;&gt;&lt;a href=&quot;#华师匣子&quot; class=&quot;headerlink&quot; title=&quot;华师匣子&quot;&gt;&lt;/a&gt;华师匣子&lt;/h3&gt;&lt;p&gt;这个可以直接看之前写的&lt;a href=&quot;https://zxc0328.github.io/2016/12/19/ios-story/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;华师匣子开发记&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;一些新的探索&quot;&gt;&lt;a href=&quot;#一些新的探索&quot; class=&quot;headerlink&quot; title=&quot;一些新的探索&quot;&gt;&lt;/a&gt;一些新的探索&lt;/h3&gt;&lt;p&gt;函数式编程，以及相关的一些，还有编译原理。这两个Topic是我下半年的核心。这是我最近觉得最感兴趣的方向。对这些方向只进行了一些初步的探索。&lt;/p&gt;
&lt;p&gt;前端工具上，7月我写了Ninja，在团队的项目中用了半年。说实话这个是我最自豪的事情。&lt;/p&gt;
&lt;p&gt;12月开始写Build your own Vuejs，希望能顺利写完。&lt;/p&gt;
&lt;h3 id=&quot;未来打算&quot;&gt;&lt;a href=&quot;#未来打算&quot; class=&quot;headerlink&quot; title=&quot;未来打算&quot;&gt;&lt;/a&gt;未来打算&lt;/h3&gt;&lt;p&gt;我现在的一个理念，就是，你想学什么，那就自己写一个。光用是不行的。比如像了解前端MVVM框架，就自己实现一个。想学编译原理，可以自己实现一个简单的编译器。我认为这是很有趣的事情，也是很了不起的事情。&lt;/p&gt;
&lt;p&gt;未来打算在前端工具和框架这个方向上深入的研究。然后正式学习函数式编程。以及DSL相关的知识。保持好奇心。保持对生活的热爱！&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;2016对我来说当然是很神奇也很重要的一年。团队的进步很快，华师匣子终于上线。我也顺利的找到的工作。&lt;/p&gt;
&lt;p&gt;回想这一年，对于上半年的事情，现在只残存着一些依稀的回忆了。这一年我对前端的理解，有了很大的变化，这其实是一个日积月累的过程。所以Tower里的进度，对于我来说，就是一个非常好的备忘录。自己的学习的历程，在里面可以看到一个很清晰的脉络。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
